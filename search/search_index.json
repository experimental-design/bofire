{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#introduction","title":"Introduction","text":"<p>BoFire is a framework to define and solve black-box optimization problems. These problems can arise in a number of closely related fields including experimental design, multi-objective optimization and active learning.</p> <p>BoFire problem specifications are json serializable for use in RESTful APIs and are to a large extent agnostic to the specific methods and frameworks in which the problems are solved.</p> <p>You can find code-examples in the Getting Started section of this document, as well as full worked-out examples of code-usage in the /tutorials section of this repository!</p>"},{"location":"#experimental-design","title":"Experimental design","text":"<p>In the context of experimental design BoFire allows to define a design space</p> \\[ \\mathbb{X} = x_1 \\otimes x_2 \\ldots \\otimes x_D \\] <p>where the design parameters may take values depending on their type and domain, e.g.</p> <ul> <li>continuous: \\(x_1 \\in [0, 1]\\)</li> <li>discrete: \\(x_2 \\in \\{1, 2, 5, 7.5\\}\\)</li> <li>categorical: \\(x_3 \\in \\{A, B, C\\}\\)</li> </ul> <p>and a set of equations define additional experimental constraints, e.g.</p> <ul> <li>linear equality: \\(\\sum x_i = 1\\)</li> <li>linear inequality: \\(2 x_1 \\leq x_2\\)</li> <li>non-linear inequality: \\(\\sum x_i^2 \\leq 1\\)</li> <li>n-choose-k: only \\(k\\) out of \\(n\\) parameters can take non-zero values.</li> </ul>"},{"location":"#multi-objective-optimization","title":"Multi-objective optimization","text":"<p>In the context of multi-objective optimization BoFire allows to define a vector-valued optimization problem</p> \\[ \\argmax_{x \\in \\mathbb{X}} s(y(x)) \\] <p>where</p> <ul> <li>\\(\\mathbb{X}\\) is again the experimental design space</li> <li>\\(y = \\{y_1, \\ldots y_M\\}\\) are known functions describing your experimental outputs and</li> <li>\\(s = \\{s_1, \\ldots s_M\\}\\) are the objectives to be maximized. For instance, \\(s_1\\) is the identity function if \\(y_1\\) is to be maximized.</li> </ul> <p>Since the objectives are usually conflicting, there is no point \\(x\\) that simultaneously optimizes all objectives. Instead the goal is to find the Pareto front of all optimal compromises.</p> <p>A decision maker can then explore these compromises to get a deep understanding of the problem and make the best informed decision.</p>"},{"location":"#bayesian-optimization","title":"Bayesian optimization","text":"<p>In the context of Bayesian optimization we want to simultaneously learn the unknown function \\(y(x)\\) (exploration), while focusing the experimental effort on promising regions (exploitation). This is done by using the experimental data to fit a probabilistic model \\(p(y|x, \\mathrm{data})\\) that estimates the distribution of possible outcomes for \\(y\\). An acquisition function \\(a\\) then formulates the desired trade-off between exploration and exploitation</p> \\[ \\argmax_{x \\in \\mathbb{X}} a(s(p_y(x))) \\] <p>and the maximizer \\(x_\\mathrm{opt}\\) of this acquisition function determines the next experiment \\(y(x)\\) to run.</p> <p>When there are multiple competing objectives, the task is again to find a suitable approximation of the Pareto front.</p>"},{"location":"#design-of-experiments","title":"Design of Experiments","text":"<p>BoFire can be used to generate optimal experimental designs with respect to various optimality criteria like D-optimality, A-optimality or uniform space filling.</p> <p>For this, the user specifies a design space and a model formula, then chooses an optimality criterion and the desired number of experiments in the design. The resulting optimization problem is then solved by IPOPT.</p> <p>The doe subpackage also supports a wide range of constraints on the design space including linear and nonlinear equalities and inequalities as well a (limited) use of NChooseK constraints. The user can provide fixed experiments that will be treated as part of the design but remain fixed during the optimization process. While some of the optimization algorithms support non-continuous design variables, the doe subpackage only supports those that are continuous.</p> <p>By default IPOPT uses the freely available linear solver MUMPS. For large models choosing a different linear solver (e.g. ma57 from Coin-HSL) can vastly reduce optimization time. A free academic license for Coin-HSL can be obtained here. Instructions on how to install additional linear solvers for IPOPT are given in the IPOPT documentation. For choosing a specific (HSL) linear solver in BoFire you can just pass the name of the solver to <code>find_local_max_ipopt()</code> with the <code>linear_solver</code> option together with the library's name in the option <code>hsllib</code>, e.g. <pre><code>find_local_max_ipopt(domain, \"fully-quadratic\", ipopt_options={\"linear_solver\":\"ma57\", \"hsllib\":\"libcoinhsl.so\"})\n</code></pre></p>"},{"location":"#reference","title":"Reference","text":"<p>We would love for you to use BoFire in your work! If you do, please cite our paper:</p> <pre><code>@misc{durholt2024bofire,\n  title={BoFire: Bayesian Optimization Framework Intended for Real Experiments},\n  author={Johannes P. D{\\\"{u}}rholt and Thomas S. Asche and Johanna Kleinekorte and Gabriel Mancino-Ball and Benjamin Schiller and Simon Sung and Julian Keupp and Aaron Osburg and Toby Boyne and Ruth Misener and Rosona Eldred and Wagner Steuer Costa and Chrysoula Kappatou and Robert M. Lee and Dominik Linzner and David Walz and Niklas Wulkow and Behrang Shafei},\n  year={2024},\n  eprint={2408.05040},\n  archivePrefix={arXiv},\n  primaryClass={cs.LG},\n  url={https://arxiv.org/abs/2408.05040},\n}\n</code></pre>"},{"location":"CONTRIBUTING/","title":"Contributing","text":"<p>Contributions to BoFire are highly welcome!</p>"},{"location":"CONTRIBUTING/#pull-requests","title":"Pull Requests","text":"<p>Pull requests are highly welcome:</p> <ol> <li>Create a fork from main.</li> <li>Add or adapt unit tests according to your change.</li> <li>Add doc-strings and update the documentation. You might consider contributing to the tutorials section.</li> <li>Make sure that the GitHub pipelines passes.</li> </ol>"},{"location":"CONTRIBUTING/#development-environment","title":"Development Environment","text":"<p>We recommend an editable installation. After cloning the repository via <pre><code>git clone https://github.com/experimental-design/bofire.git\n</code></pre> and cd <code>bofire</code>, you can proceed with <pre><code>pip install -e \".[all]\"\n</code></pre> Afterwards, you can check that the tests are successful via <pre><code>pytest tests/\n</code></pre></p>"},{"location":"CONTRIBUTING/#coding-style","title":"Coding Style","text":"<p>We use Ruff for linting, sorting and formatting of our code. Our doc-strings are in Google-style.</p> <p>In our CI/CD pipeline we check if contributions are compliant to Ruff. To make contributors' lives easier, we have pre-commit hooks for Ruff configured in the versions corresponding to the pipeline. They can be installed via</p> <p><pre><code>pip install pre-commit\npre-commit install\n</code></pre> in you local project root folder, if you want to use <code>pre-commit</code>.</p>"},{"location":"CONTRIBUTING/#type-checks","title":"Type checks","text":"<p>We make heavy use of Pydantic to enforce type checks during runtime. Further, we use Pyright for static type checking. We enforce Pyright type checks in our CI/CD pipeline.</p>"},{"location":"CONTRIBUTING/#tests","title":"Tests","text":"<p>If you add new functionality, make sure that it is tested properly and that it does not break existing code. Our tests run in our CI/CD pipeline. The test coverage is hidden from our Readme because it is not a very robust metric. However, you can find it in the outputs of our test-CI/CD-pipeline. See example.</p>"},{"location":"CONTRIBUTING/#documentation","title":"Documentation","text":"<p>We use MkDocs with material theme and deploy our documentation to https://experimental-design.github.io/bofire/. Thereby, an API description is extracted from the doc-strings. Additionally, we have tutorials and getting-started-sections.</p>"},{"location":"CONTRIBUTING/#license","title":"License","text":"<p>By contributing you agree that your contributions will be licensed under the same BSD 3-Clause License as BoFire.</p>"},{"location":"basic_examples/","title":"Basic Examples for the DoE Subpackage","text":"In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.ticker import FormatStrFormatter\n\nimport bofire.strategies.api as strategies\nfrom bofire.data_models.constraints.api import (\n    InterpointEqualityConstraint,\n    LinearEqualityConstraint,\n    LinearInequalityConstraint,\n    NonlinearEqualityConstraint,\n    NonlinearInequalityConstraint,\n)\nfrom bofire.data_models.domain.api import Domain\nfrom bofire.data_models.features.api import ContinuousInput, ContinuousOutput\nfrom bofire.data_models.strategies.api import DoEStrategy\nfrom bofire.data_models.strategies.doe import DOptimalityCriterion, IOptimalityCriterion\n</pre> import matplotlib.pyplot as plt import numpy as np from matplotlib.ticker import FormatStrFormatter  import bofire.strategies.api as strategies from bofire.data_models.constraints.api import (     InterpointEqualityConstraint,     LinearEqualityConstraint,     LinearInequalityConstraint,     NonlinearEqualityConstraint,     NonlinearInequalityConstraint, ) from bofire.data_models.domain.api import Domain from bofire.data_models.features.api import ContinuousInput, ContinuousOutput from bofire.data_models.strategies.api import DoEStrategy from bofire.data_models.strategies.doe import DOptimalityCriterion, IOptimalityCriterion In\u00a0[\u00a0]: Copied! <pre>domain = Domain(\n    inputs=[\n        ContinuousInput(key=\"x1\", bounds=(0, 1)),\n        ContinuousInput(key=\"x2\", bounds=(0.1, 1)),\n        ContinuousInput(key=\"x3\", bounds=(0, 0.6)),\n    ],\n    outputs=[ContinuousOutput(key=\"y\")],\n    constraints=[\n        LinearEqualityConstraint(\n            features=[\"x1\", \"x2\", \"x3\"],\n            coefficients=[1, 1, 1],\n            rhs=1,\n        ),\n        LinearInequalityConstraint(features=[\"x1\", \"x2\"], coefficients=[5, 4], rhs=3.9),\n        LinearInequalityConstraint(\n            features=[\"x1\", \"x2\"],\n            coefficients=[-20, 5],\n            rhs=-3,\n        ),\n    ],\n)\n\ndata_model = DoEStrategy(\n    domain=domain,\n    criterion=DOptimalityCriterion(formula=\"linear\"),\n    ipopt_options={\"print_level\": 0},\n)\nstrategy = strategies.map(data_model=data_model)\ncandidates = strategy.ask(candidate_count=12)\n</pre> domain = Domain(     inputs=[         ContinuousInput(key=\"x1\", bounds=(0, 1)),         ContinuousInput(key=\"x2\", bounds=(0.1, 1)),         ContinuousInput(key=\"x3\", bounds=(0, 0.6)),     ],     outputs=[ContinuousOutput(key=\"y\")],     constraints=[         LinearEqualityConstraint(             features=[\"x1\", \"x2\", \"x3\"],             coefficients=[1, 1, 1],             rhs=1,         ),         LinearInequalityConstraint(features=[\"x1\", \"x2\"], coefficients=[5, 4], rhs=3.9),         LinearInequalityConstraint(             features=[\"x1\", \"x2\"],             coefficients=[-20, 5],             rhs=-3,         ),     ], )  data_model = DoEStrategy(     domain=domain,     criterion=DOptimalityCriterion(formula=\"linear\"),     ipopt_options={\"print_level\": 0}, ) strategy = strategies.map(data_model=data_model) candidates = strategy.ask(candidate_count=12) <pre>Tried to set Option: disp. It is not a valid option. Please check the list of available options.\n</pre> <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[2], line 29\n     23 data_model = DoEStrategy(\n     24     domain=domain,\n     25     criterion=DOptimalityCriterion(formula=\"linear\"),\n     26     ipopt_options={\"disp\": 0},\n     27 )\n     28 strategy = strategies.map(data_model=data_model)\n---&gt; 29 candidates = strategy.ask(candidate_count=12)\n\nFile ~/Documents/temporary/bofire/bofire/strategies/strategy.py:128, in Strategy.ask(self, candidate_count, add_pending, raise_validation_error)\n    123 if not self.has_sufficient_experiments():\n    124     raise ValueError(\n    125         \"Not enough experiments available to execute the strategy.\",\n    126     )\n--&gt; 128 candidates = self._ask(candidate_count=candidate_count)\n    130 self.domain.validate_candidates(\n    131     candidates=candidates,\n    132     only_inputs=True,\n    133     raise_validation_error=raise_validation_error,\n    134 )\n    136 if candidate_count is not None:\n\nFile ~/Documents/temporary/bofire/bofire/strategies/doe_strategy.py:113, in DoEStrategy._ask(self, candidate_count)\n    103 num_discrete_vars = len(new_discretes)\n    104 if (\n    105     self.data_model.optimization_strategy == \"relaxed\"\n    106     or (num_binary_vars == 0 and num_discrete_vars == 0)\n   (...)\n    111     )\n    112 ):\n--&gt; 113     design = find_local_max_ipopt(\n    114         new_domain,\n    115         n_experiments=_candidate_count,\n    116         fixed_experiments=None,\n    117         partially_fixed_experiments=adapted_partially_fixed_candidates,\n    118         ipopt_options=self.data_model.ipopt_options,\n    119         criterion=self.data_model.criterion,\n    120         use_hessian=self.data_model.use_hessian,\n    121     )\n    122 # TODO adapt to when exhaustive search accepts discrete variables\n    123 elif (\n    124     self.data_model.optimization_strategy == \"exhaustive\"\n    125     and num_discrete_vars == 0\n    126 ):\n\nFile ~/Documents/temporary/bofire/bofire/strategies/doe/design.py:188, in find_local_max_ipopt(domain, n_experiments, criterion, ipopt_options, sampling, fixed_experiments, partially_fixed_experiments, use_hessian)\n    182     problem = FirstOrderDoEProblem(\n    183         doe_objective=objective_function,\n    184         bounds=bounds,\n    185         constraints=constraints,\n    186     )\n    187 for key in _ipopt_options.keys():\n--&gt; 188     problem.add_option(key, _ipopt_options[key])\n    190 x, info = problem.solve(x0)\n    192 design = pd.DataFrame(\n    193     x.reshape(n_experiments, len(domain.inputs)),\n    194     columns=domain.inputs.get_keys(),\n    195     index=[f\"exp{i}\" for i in range(n_experiments)],\n    196 )\n\nFile ~/anaconda3/envs/bofire/lib/python3.11/site-packages/cyipopt/cython/ipopt_wrapper.pyx:495, in ipopt_wrapper.Problem.add_option()\n\nTypeError: Error while assigning an option</pre> <p>Let's visualize the experiments that were chosen. We will see that such a design puts the experiments at the extremes of the experimental space - these are the points that best allow us to estimate the parameters of the linear model we chose.</p> In\u00a0[\u00a0]: Copied! <pre>fig = plt.figure(figsize=((10, 10)))\nax = fig.add_subplot(111, projection=\"3d\")\nax.view_init(45, 45)\nax.set_title(\"Linear model\")\nax.set_xlabel(\"$x_1$\")\nax.set_ylabel(\"$x_2$\")\nax.set_zlabel(\"$x_3$\")\nplt.rcParams[\"figure.figsize\"] = (10, 8)\n\n# plot feasible polytope\nax.plot(\n    xs=[7 / 10, 3 / 10, 1 / 5, 3 / 10, 7 / 10],\n    ys=[1 / 10, 3 / 5, 1 / 5, 1 / 10, 1 / 10],\n    zs=[1 / 5, 1 / 10, 3 / 5, 3 / 5, 1 / 5],\n    linewidth=2,\n)\n\n# plot D-optimal solutions\nax.scatter(\n    xs=candidates[\"x1\"],\n    ys=candidates[\"x2\"],\n    zs=candidates[\"x3\"],\n    marker=\"o\",\n    s=40,\n    color=\"orange\",\n    label=\"optimal_design solution, 12 points\",\n)\n\nplt.legend()\n</pre> fig = plt.figure(figsize=((10, 10))) ax = fig.add_subplot(111, projection=\"3d\") ax.view_init(45, 45) ax.set_title(\"Linear model\") ax.set_xlabel(\"$x_1$\") ax.set_ylabel(\"$x_2$\") ax.set_zlabel(\"$x_3$\") plt.rcParams[\"figure.figsize\"] = (10, 8)  # plot feasible polytope ax.plot(     xs=[7 / 10, 3 / 10, 1 / 5, 3 / 10, 7 / 10],     ys=[1 / 10, 3 / 5, 1 / 5, 1 / 10, 1 / 10],     zs=[1 / 5, 1 / 10, 3 / 5, 3 / 5, 1 / 5],     linewidth=2, )  # plot D-optimal solutions ax.scatter(     xs=candidates[\"x1\"],     ys=candidates[\"x2\"],     zs=candidates[\"x3\"],     marker=\"o\",     s=40,     color=\"orange\",     label=\"optimal_design solution, 12 points\", )  plt.legend() Out[\u00a0]: <pre>&lt;matplotlib.legend.Legend at 0x312f78d50&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>data_model = DoEStrategy(\n    domain=domain,\n    criterion=DOptimalityCriterion(\n        formula=\"x1 + x2 + x3 + {x1**2} + {x2**2} + {x3**2} + {x1**3} + {x2**3} + {x3**3} + x1:x2 + x1:x3 + x2:x3 + x1:x2:x3\"\n    ),\n    ipopt_options={\"print_level\": 0},\n)\nstrategy = strategies.map(data_model=data_model)\ncandidates = strategy.ask(12)\n</pre> data_model = DoEStrategy(     domain=domain,     criterion=DOptimalityCriterion(         formula=\"x1 + x2 + x3 + {x1**2} + {x2**2} + {x3**2} + {x1**3} + {x2**3} + {x3**3} + x1:x2 + x1:x3 + x2:x3 + x1:x2:x3\"     ),     ipopt_options={\"print_level\": 0}, ) strategy = strategies.map(data_model=data_model) candidates = strategy.ask(12) <p>In this case we can compare with the result reported in the paper of Coetzer and Haines.</p> In\u00a0[\u00a0]: Copied! <pre>d_opt = np.array(\n    [\n        [\n            0.7,\n            0.3,\n            0.2,\n            0.3,\n            0.5902,\n            0.4098,\n            0.2702,\n            0.2279,\n            0.4118,\n            0.5738,\n            0.4211,\n            0.3360,\n        ],\n        [0.1, 0.6, 0.2, 0.1, 0.2373, 0.4628, 0.4808, 0.3117, 0.1, 0.1, 0.2911, 0.2264],\n        [\n            0.2,\n            0.1,\n            0.6,\n            0.6,\n            0.1725,\n            0.1274,\n            0.249,\n            0.4604,\n            0.4882,\n            0.3262,\n            0.2878,\n            0.4376,\n        ],\n    ],\n)  # values taken from paper\n\n\nfig = plt.figure(figsize=((10, 10)))\nax = fig.add_subplot(111, projection=\"3d\")\nax.set_title(\"cubic model\")\nax.view_init(45, 45)\nax.set_xlabel(\"$x_1$\")\nax.set_ylabel(\"$x_2$\")\nax.set_zlabel(\"$x_3$\")\nplt.rcParams[\"figure.figsize\"] = (10, 8)\n\n# plot feasible polytope\nax.plot(\n    xs=[7 / 10, 3 / 10, 1 / 5, 3 / 10, 7 / 10],\n    ys=[1 / 10, 3 / 5, 1 / 5, 1 / 10, 1 / 10],\n    zs=[1 / 5, 1 / 10, 3 / 5, 3 / 5, 1 / 5],\n    linewidth=2,\n)\n\n# plot D-optimal solution\nax.scatter(\n    xs=d_opt[0],\n    ys=d_opt[1],\n    zs=d_opt[2],\n    marker=\"o\",\n    s=40,\n    color=\"darkgreen\",\n    label=\"D-optimal design, 12 points\",\n)\n\nax.scatter(\n    xs=candidates[\"x1\"],\n    ys=candidates[\"x2\"],\n    zs=candidates[\"x3\"],\n    marker=\"o\",\n    s=40,\n    color=\"orange\",\n    label=\"optimal_design solution, 12 points\",\n)\n\nplt.legend()\n</pre> d_opt = np.array(     [         [             0.7,             0.3,             0.2,             0.3,             0.5902,             0.4098,             0.2702,             0.2279,             0.4118,             0.5738,             0.4211,             0.3360,         ],         [0.1, 0.6, 0.2, 0.1, 0.2373, 0.4628, 0.4808, 0.3117, 0.1, 0.1, 0.2911, 0.2264],         [             0.2,             0.1,             0.6,             0.6,             0.1725,             0.1274,             0.249,             0.4604,             0.4882,             0.3262,             0.2878,             0.4376,         ],     ], )  # values taken from paper   fig = plt.figure(figsize=((10, 10))) ax = fig.add_subplot(111, projection=\"3d\") ax.set_title(\"cubic model\") ax.view_init(45, 45) ax.set_xlabel(\"$x_1$\") ax.set_ylabel(\"$x_2$\") ax.set_zlabel(\"$x_3$\") plt.rcParams[\"figure.figsize\"] = (10, 8)  # plot feasible polytope ax.plot(     xs=[7 / 10, 3 / 10, 1 / 5, 3 / 10, 7 / 10],     ys=[1 / 10, 3 / 5, 1 / 5, 1 / 10, 1 / 10],     zs=[1 / 5, 1 / 10, 3 / 5, 3 / 5, 1 / 5],     linewidth=2, )  # plot D-optimal solution ax.scatter(     xs=d_opt[0],     ys=d_opt[1],     zs=d_opt[2],     marker=\"o\",     s=40,     color=\"darkgreen\",     label=\"D-optimal design, 12 points\", )  ax.scatter(     xs=candidates[\"x1\"],     ys=candidates[\"x2\"],     zs=candidates[\"x3\"],     marker=\"o\",     s=40,     color=\"orange\",     label=\"optimal_design solution, 12 points\", )  plt.legend() Out[\u00a0]: <pre>&lt;matplotlib.legend.Legend at 0x32fb49710&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>data_model = DoEStrategy(\n    domain=domain,\n    criterion=IOptimalityCriterion(\n        formula=\"x1 + x2 + x3 + {x1**2} + {x2**2} + {x3**2} + {x1**3} + {x2**3} + {x3**3} + x1:x2 + x1:x3 + x2:x3 + x1:x2:x3\",\n        n_space_filling_points=60,\n        ipopt_options={\"max_iter\": 500},\n    ),\n    ipopt_options={\"print_level\": 0},\n)\nstrategy = strategies.map(data_model=data_model)\ncandidates = strategy.ask(12).to_numpy().T\n\n\ni_opt = np.array(\n    [\n        [0.7000, 0.1000, 0.2000],\n        [0.3000, 0.6000, 0.1000],\n        [0.2031, 0.1969, 0.6000],\n        [0.5899, 0.2376, 0.1725],\n        [0.4105, 0.4619, 0.1276],\n        [0.2720, 0.4882, 0.2398],\n        [0.2281, 0.3124, 0.4595],\n        [0.3492, 0.1000, 0.5508],\n        [0.5614, 0.1000, 0.3386],\n        [0.4621, 0.2342, 0.3037],\n        [0.3353, 0.2228, 0.4419],\n        [0.3782, 0.3618, 0.2600],\n    ]\n).T  # values taken from paper\n\n\nfig = plt.figure(figsize=((10, 10)))\nax = fig.add_subplot(111, projection=\"3d\")\nax.set_title(\"cubic model\")\nax.view_init(45, 45)\nax.set_xlabel(\"$x_1$\")\nax.set_ylabel(\"$x_2$\")\nax.set_zlabel(\"$x_3$\")\nplt.rcParams[\"figure.figsize\"] = (10, 8)\n\n# plot feasible polytope\nax.plot(\n    xs=[7 / 10, 3 / 10, 1 / 5, 3 / 10, 7 / 10],\n    ys=[1 / 10, 3 / 5, 1 / 5, 1 / 10, 1 / 10],\n    zs=[1 / 5, 1 / 10, 3 / 5, 3 / 5, 1 / 5],\n    linewidth=2,\n)\n\n# plot I-optimal solution\nax.scatter(\n    xs=i_opt[0],\n    ys=i_opt[1],\n    zs=i_opt[2],\n    marker=\"o\",\n    s=40,\n    color=\"darkgreen\",\n    label=\"I-optimal design, 12 points\",\n)\n\nax.scatter(\n    xs=candidates[0],\n    ys=candidates[1],\n    zs=candidates[2],\n    marker=\"o\",\n    s=40,\n    color=\"orange\",\n    label=\"optimal_design solution, 12 points\",\n)\n\nplt.legend()\n</pre> data_model = DoEStrategy(     domain=domain,     criterion=IOptimalityCriterion(         formula=\"x1 + x2 + x3 + {x1**2} + {x2**2} + {x3**2} + {x1**3} + {x2**3} + {x3**3} + x1:x2 + x1:x3 + x2:x3 + x1:x2:x3\",         n_space_filling_points=60,         ipopt_options={\"max_iter\": 500},     ),     ipopt_options={\"print_level\": 0}, ) strategy = strategies.map(data_model=data_model) candidates = strategy.ask(12).to_numpy().T   i_opt = np.array(     [         [0.7000, 0.1000, 0.2000],         [0.3000, 0.6000, 0.1000],         [0.2031, 0.1969, 0.6000],         [0.5899, 0.2376, 0.1725],         [0.4105, 0.4619, 0.1276],         [0.2720, 0.4882, 0.2398],         [0.2281, 0.3124, 0.4595],         [0.3492, 0.1000, 0.5508],         [0.5614, 0.1000, 0.3386],         [0.4621, 0.2342, 0.3037],         [0.3353, 0.2228, 0.4419],         [0.3782, 0.3618, 0.2600],     ] ).T  # values taken from paper   fig = plt.figure(figsize=((10, 10))) ax = fig.add_subplot(111, projection=\"3d\") ax.set_title(\"cubic model\") ax.view_init(45, 45) ax.set_xlabel(\"$x_1$\") ax.set_ylabel(\"$x_2$\") ax.set_zlabel(\"$x_3$\") plt.rcParams[\"figure.figsize\"] = (10, 8)  # plot feasible polytope ax.plot(     xs=[7 / 10, 3 / 10, 1 / 5, 3 / 10, 7 / 10],     ys=[1 / 10, 3 / 5, 1 / 5, 1 / 10, 1 / 10],     zs=[1 / 5, 1 / 10, 3 / 5, 3 / 5, 1 / 5],     linewidth=2, )  # plot I-optimal solution ax.scatter(     xs=i_opt[0],     ys=i_opt[1],     zs=i_opt[2],     marker=\"o\",     s=40,     color=\"darkgreen\",     label=\"I-optimal design, 12 points\", )  ax.scatter(     xs=candidates[0],     ys=candidates[1],     zs=candidates[2],     marker=\"o\",     s=40,     color=\"orange\",     label=\"optimal_design solution, 12 points\", )  plt.legend() <pre>/Users/aaron/Desktop/bofire/bofire/strategies/doe/objective.py:222: UserWarning: Equality constraints were detected. No equidistant grid of points can be generated. The design space will be filled via SpaceFilling.\n  warnings.warn(\n</pre> Out[\u00a0]: <pre>&lt;matplotlib.legend.Legend at 0x32fb7ded0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>def plot_results_3d(result, surface_func):\n    u, v = np.mgrid[0 : 2 * np.pi : 100j, 0 : np.pi : 80j]\n    X = np.cos(u) * np.sin(v)\n    Y = np.sin(u) * np.sin(v)\n    Z = surface_func(X, Y)\n\n    fig = plt.figure(figsize=(8, 8))\n    ax = fig.add_subplot(111, projection=\"3d\")\n    ax.plot_surface(X, Y, Z, alpha=0.3)\n    ax.scatter(\n        xs=result[\"x1\"],\n        ys=result[\"x2\"],\n        zs=result[\"x3\"],\n        marker=\"o\",\n        s=40,\n        color=\"red\",\n    )\n    ax.set(xlabel=\"x1\", ylabel=\"x2\", zlabel=\"x3\")\n    ax.xaxis.set_major_formatter(FormatStrFormatter(\"%.2f\"))\n    ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.2f\"))\n</pre> def plot_results_3d(result, surface_func):     u, v = np.mgrid[0 : 2 * np.pi : 100j, 0 : np.pi : 80j]     X = np.cos(u) * np.sin(v)     Y = np.sin(u) * np.sin(v)     Z = surface_func(X, Y)      fig = plt.figure(figsize=(8, 8))     ax = fig.add_subplot(111, projection=\"3d\")     ax.plot_surface(X, Y, Z, alpha=0.3)     ax.scatter(         xs=result[\"x1\"],         ys=result[\"x2\"],         zs=result[\"x3\"],         marker=\"o\",         s=40,         color=\"red\",     )     ax.set(xlabel=\"x1\", ylabel=\"x2\", zlabel=\"x3\")     ax.xaxis.set_major_formatter(FormatStrFormatter(\"%.2f\"))     ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.2f\")) In\u00a0[\u00a0]: Copied! <pre>domain = Domain(\n    inputs=[\n        ContinuousInput(key=\"x1\", bounds=(-1, 1)),\n        ContinuousInput(key=\"x2\", bounds=(-1, 1)),\n        ContinuousInput(key=\"x3\", bounds=(0, 1)),\n    ],\n    outputs=[ContinuousOutput(key=\"y\")],\n    constraints=[\n        NonlinearInequalityConstraint(\n            expression=\"(x1**2 + x2**2)**0.5 - x3\",\n            features=[\"x1\", \"x2\", \"x3\"],\n        ),\n    ],\n)\n\ndata_model = DoEStrategy(\n    domain=domain,\n    criterion=DOptimalityCriterion(formula=\"linear\"),\n    ipopt_options={\"max_iter\": 100, \"print_level\": 0},\n)\nstrategy = strategies.map(data_model=data_model)\nresult = strategy.ask(\n    strategy.get_required_number_of_experiments(), raise_validation_error=False\n)\nresult.round(3)\nplot_results_3d(result, surface_func=lambda x1, x2: np.sqrt(x1**2 + x2**2))\n</pre> domain = Domain(     inputs=[         ContinuousInput(key=\"x1\", bounds=(-1, 1)),         ContinuousInput(key=\"x2\", bounds=(-1, 1)),         ContinuousInput(key=\"x3\", bounds=(0, 1)),     ],     outputs=[ContinuousOutput(key=\"y\")],     constraints=[         NonlinearInequalityConstraint(             expression=\"(x1**2 + x2**2)**0.5 - x3\",             features=[\"x1\", \"x2\", \"x3\"],         ),     ], )  data_model = DoEStrategy(     domain=domain,     criterion=DOptimalityCriterion(formula=\"linear\"),     ipopt_options={\"max_iter\": 100, \"print_level\": 0}, ) strategy = strategies.map(data_model=data_model) result = strategy.ask(     strategy.get_required_number_of_experiments(), raise_validation_error=False ) result.round(3) plot_results_3d(result, surface_func=lambda x1, x2: np.sqrt(x1**2 + x2**2)) <pre>/Users/aaron/Desktop/bofire/bofire/strategies/doe/design.py:106: UserWarning: Nonlinear constraints were detected. Not all features and checks are supported for this type of constraints.                 Using them can lead to unexpected behaviour. Please make sure to provide jacobians for nonlinear constraints.\n  warnings.warn(\n/Users/aaron/Desktop/bofire/bofire/strategies/doe/design.py:130: UserWarning: Sampling failed. Falling back to uniform sampling on input domain.                      Providing a custom sampling strategy compatible with the problem can                       possibly improve performance.\n  warnings.warn(\n/Users/aaron/Desktop/bofire/bofire/strategies/doe/design.py:204: UserWarning: Some points do not lie inside the domain or violate constraints. Please check if the                 results lie within your tolerance.\n  warnings.warn(\n/Users/aaron/Desktop/bofire/bofire/data_models/domain/domain.py:454: UserWarning: Not all constraints are fulfilled.\n  warnings.warn(\"Not all constraints are fulfilled.\")\n</pre> <p>We can do the same for a design space limited by an elliptical cone $x_1^2 + x_2^2 - x_3 \\leq 0$.</p> In\u00a0[\u00a0]: Copied! <pre>domain = Domain(\n    inputs=[\n        ContinuousInput(key=\"x1\", bounds=(-1, 1)),\n        ContinuousInput(key=\"x2\", bounds=(-1, 1)),\n        ContinuousInput(key=\"x3\", bounds=(0, 1)),\n    ],\n    outputs=[ContinuousOutput(key=\"y\")],\n    constraints=[\n        NonlinearInequalityConstraint(\n            expression=\"x1**2 + x2**2 - x3\",\n            features=[\"x1\", \"x2\", \"x3\"],\n        ),\n    ],\n)\ndata_model = DoEStrategy(\n    domain=domain,\n    criterion=DOptimalityCriterion(formula=\"linear\"),\n    ipopt_options={\"max_iter\": 100, \"print_level\": 0},\n)\nstrategy = strategies.map(data_model=data_model)\nresult = strategy.ask(\n    strategy.get_required_number_of_experiments(), raise_validation_error=False\n)\nresult.round(3)\nplot_results_3d(result, surface_func=lambda x1, x2: x1**2 + x2**2)\n</pre> domain = Domain(     inputs=[         ContinuousInput(key=\"x1\", bounds=(-1, 1)),         ContinuousInput(key=\"x2\", bounds=(-1, 1)),         ContinuousInput(key=\"x3\", bounds=(0, 1)),     ],     outputs=[ContinuousOutput(key=\"y\")],     constraints=[         NonlinearInequalityConstraint(             expression=\"x1**2 + x2**2 - x3\",             features=[\"x1\", \"x2\", \"x3\"],         ),     ], ) data_model = DoEStrategy(     domain=domain,     criterion=DOptimalityCriterion(formula=\"linear\"),     ipopt_options={\"max_iter\": 100, \"print_level\": 0}, ) strategy = strategies.map(data_model=data_model) result = strategy.ask(     strategy.get_required_number_of_experiments(), raise_validation_error=False ) result.round(3) plot_results_3d(result, surface_func=lambda x1, x2: x1**2 + x2**2) <pre>/Users/aaron/Desktop/bofire/bofire/strategies/doe/design.py:106: UserWarning: Nonlinear constraints were detected. Not all features and checks are supported for this type of constraints.                 Using them can lead to unexpected behaviour. Please make sure to provide jacobians for nonlinear constraints.\n  warnings.warn(\n/Users/aaron/Desktop/bofire/bofire/strategies/doe/design.py:130: UserWarning: Sampling failed. Falling back to uniform sampling on input domain.                      Providing a custom sampling strategy compatible with the problem can                       possibly improve performance.\n  warnings.warn(\n</pre> In\u00a0[\u00a0]: Copied! <pre>domain = Domain(\n    inputs=[\n        ContinuousInput(key=\"x1\", bounds=(-1, 1)),\n        ContinuousInput(key=\"x2\", bounds=(-1, 1)),\n        ContinuousInput(key=\"x3\", bounds=(0, 1)),\n    ],\n    outputs=[ContinuousOutput(key=\"y\")],\n    constraints=[\n        NonlinearEqualityConstraint(\n            expression=\"(x1**2 + x2**2)**0.5 - x3\",\n            features=[\"x1\", \"x2\", \"x3\"],\n        ),\n    ],\n)\ndata_model = DoEStrategy(\n    domain=domain,\n    criterion=DOptimalityCriterion(formula=\"linear\"),\n    ipopt_options={\"max_iter\": 100, \"print_level\": 0},\n)\nstrategy = strategies.map(data_model=data_model)\nresult = strategy.ask(12, raise_validation_error=False)\nresult.round(3)\nplot_results_3d(result, surface_func=lambda x1, x2: np.sqrt(x1**2 + x2**2))\n</pre> domain = Domain(     inputs=[         ContinuousInput(key=\"x1\", bounds=(-1, 1)),         ContinuousInput(key=\"x2\", bounds=(-1, 1)),         ContinuousInput(key=\"x3\", bounds=(0, 1)),     ],     outputs=[ContinuousOutput(key=\"y\")],     constraints=[         NonlinearEqualityConstraint(             expression=\"(x1**2 + x2**2)**0.5 - x3\",             features=[\"x1\", \"x2\", \"x3\"],         ),     ], ) data_model = DoEStrategy(     domain=domain,     criterion=DOptimalityCriterion(formula=\"linear\"),     ipopt_options={\"max_iter\": 100, \"print_level\": 0}, ) strategy = strategies.map(data_model=data_model) result = strategy.ask(12, raise_validation_error=False) result.round(3) plot_results_3d(result, surface_func=lambda x1, x2: np.sqrt(x1**2 + x2**2)) <pre>/Users/aaron/Desktop/bofire/bofire/strategies/doe/design.py:106: UserWarning: Nonlinear constraints were detected. Not all features and checks are supported for this type of constraints.                 Using them can lead to unexpected behaviour. Please make sure to provide jacobians for nonlinear constraints.\n  warnings.warn(\n/Users/aaron/Desktop/bofire/bofire/strategies/doe/design.py:130: UserWarning: Sampling failed. Falling back to uniform sampling on input domain.                      Providing a custom sampling strategy compatible with the problem can                       possibly improve performance.\n  warnings.warn(\n</pre> In\u00a0[\u00a0]: Copied! <pre>domain = Domain(\n    inputs=[\n        ContinuousInput(key=\"x1\", bounds=(0, 1)),\n        ContinuousInput(key=\"x2\", bounds=(0, 1)),\n        ContinuousInput(key=\"x3\", bounds=(0, 1)),\n    ],\n    outputs=[ContinuousOutput(key=\"y\")],\n    constraints=[InterpointEqualityConstraint(feature=\"x1\", multiplicity=3)],\n)\ndata_model = DoEStrategy(\n    domain=domain,\n    criterion=DOptimalityCriterion(formula=\"linear\"),\n    ipopt_options={\"max_iter\": 500, \"print_level\": 0},\n)\nstrategy = strategies.map(data_model=data_model)\nresult = strategy.ask(12)\nresult.round(3)\n</pre> domain = Domain(     inputs=[         ContinuousInput(key=\"x1\", bounds=(0, 1)),         ContinuousInput(key=\"x2\", bounds=(0, 1)),         ContinuousInput(key=\"x3\", bounds=(0, 1)),     ],     outputs=[ContinuousOutput(key=\"y\")],     constraints=[InterpointEqualityConstraint(feature=\"x1\", multiplicity=3)], ) data_model = DoEStrategy(     domain=domain,     criterion=DOptimalityCriterion(formula=\"linear\"),     ipopt_options={\"max_iter\": 500, \"print_level\": 0}, ) strategy = strategies.map(data_model=data_model) result = strategy.ask(12) result.round(3) Out[\u00a0]: x1 x2 x3 0 1.0 -0.0 -0.0 1 1.0 1.0 1.0 2 1.0 1.0 1.0 3 1.0 1.0 -0.0 4 1.0 -0.0 -0.0 5 1.0 -0.0 1.0 6 -0.0 -0.0 1.0 7 -0.0 1.0 -0.0 8 -0.0 -0.0 -0.0 9 -0.0 -0.0 -0.0 10 -0.0 1.0 1.0 11 -0.0 -0.0 1.0"},{"location":"basic_examples/#basic-examples-for-the-doe-subpackage","title":"Basic Examples for the DoE Subpackage\u00b6","text":"<p>The following example has been taken from the paper \"The construction of D- and I-optimal designs for mixture experiments with linear constraints on the components\" by R. Coetzer and L. M. Haines (https://www.sciencedirect.com/science/article/pii/S0169743917303106).</p>"},{"location":"basic_examples/#linear-model","title":"Linear model\u00b6","text":"<p>Creating an experimental design that is D-optimal with respect to a linear model is done the same way as making proposals using other methods in BoFire; you</p> <ol> <li>create a domain</li> <li>construct a stategy data model (here we want DoEStrategy)</li> <li>map the strategy to its functional version, and finally</li> <li>ask the strategy for proposals.</li> </ol> <p>We will start with the simplest case: make a design based on a linear model containing main-effects (i.e., simply the inputs themselves and an intercept, without any second-order terms).</p>"},{"location":"basic_examples/#cubic-model","title":"cubic model\u00b6","text":"<p>While the previous design is optimal for the main-effects model, we might prefer to see something that does not allocate all the experimental effort to values at the boundary of the space. This implies that we think there might be some higher-order effects present in the system - if we were sure that the target variable would follow straight-line behavior across the domain, we would not need to investigate any points away from the extremes.</p> <p>We can address this by specifying our own linear model that includes higher-order terms.</p>"},{"location":"basic_examples/#nonlinear-constraints","title":"Nonlinear Constraints\u00b6","text":"<p>Design generation also supports nonlinear constraints. The following 3 examples show what is possible.</p> <p>First, a convenience function for plotting.</p>"},{"location":"basic_examples/#example-1-design-inside-a-cone-nonlinear-inequality","title":"Example 1: Design inside a cone / nonlinear inequality\u00b6","text":"<p>In the following example we have three design variables. We impose the constraint that all experiments have to be contained in the interior of a cone, which corresponds to the nonlinear inequality constraint $\\sqrt{x_1^2 + x_2^2} - x_3 \\leq 0$. The optimization is done for a linear model and we will see that it places the points on the surface of the cone so as to maximize the distance between them (although this is not explicitly the objective of the optimization).</p>"},{"location":"basic_examples/#example-2-design-on-the-surface-of-a-cone-nonlinear-equality","title":"Example 2: Design on the surface of a cone / nonlinear equality\u00b6","text":"<p>We can also limit the design space to the surface of a cone, defined by the equality constraint $\\sqrt{x_1^2 + x_2^2} - x_3 = 0$. Before, we observed that the experimental proposals happened to be on the surface of the cone, but now they are constrained so that this must be the case.</p> <p>Remark: Due to missing sampling methods, the initial points provided to IPOPT don't satisfy the constraints. But this does not matter for the solution.</p>"},{"location":"basic_examples/#example-3-batch-constraints","title":"Example 3: Batch constraints\u00b6","text":"<p>Batch constraints can be used to create designs where each set of <code>multiplicity</code> subsequent experiments have the same value for a certain feature. This can be useful for setups where experiments are done in parallel and some parameters must be shared by experiments in the same parallel batch.</p> <p>In the following example we fix the value of the decision variable <code>x1</code> for each batch of 3 experiments.</p>"},{"location":"data_models_functionals/","title":"Data Models vs. Functional Components","text":"<p>Data models in BoFire hold static data of an optimization problem. These are input and output features as well as constraints making up the domain. They further include possible optimization objectives, acquisition functions, and kernels.</p> <p>All data models in <code>bofire.data_models</code>, are specified as pydantic models and inherit from <code>bofire.data_models.base.BaseModel</code>. These data models can be (de)serialized via <code>.dict()</code> and <code>.model_dump_json()</code> (provided by pydantic). A json schema of each data model can be obtained using <code>.schema()</code>.</p> <p>For surrogates and strategies, all functional parts are located in <code>bofire.surrogates</code> and <code>bofire.strategies</code>. These functionalities include the <code>ask</code> and <code>tell</code> as well as <code>fit</code> and <code>predict</code> methods. All class attributes (used by these method) are also removed from the data models. Each functional entity is initialized using the corresponding data model. As an example, consider the following data model of a <code>RandomStrategy</code>:</p> <pre><code>import bofire.data_models.domain.api as dm_domain\nimport bofire.data_models.features.api as dm_features\nimport bofire.data_models.strategies.api as dm_strategies\n\nin1 = dm_features.ContinuousInput(key=\"in1\", bounds=[0.0,1.0])\nin2 = dm_features.ContinuousInput(key=\"in2\", bounds=[0.0,2.0])\nin3 = dm_features.ContinuousInput(key=\"in3\", bounds=[0.0,3.0])\n\nout1 = dm_features.ContinuousOutput(key=\"out1\")\n\ninputs = dm_domain.Inputs(features=[in1, in2, in3])\noutputs = dm_domain.Outputs(features=[out1])\nconstraints = dm_domain.Constraints()\n\ndomain = dm_domain.Domain(\n    inputs=inputs,\n    outputs=outputs,\n    constraints=constraints,\n)\n\ndata_model = dm_strategies.RandomStrategy(domain=domain)\n</code></pre> <p>Such a data model can be (de)serialized as follows:</p> <p><pre><code>from pydantic import TypeAdapter\nfrom bofire.data_models.strategies.api import AnyStrategy\n\nserialized = data_model.model_dump_json()\n\ndata_model_ = TypeAdapter(AnyStrategy).validate_json(serialized)\n\nassert data_model_ == data_model\n</code></pre> The data model of a strategy contains its hyperparameters. Using this data model of a strategy, we can create an instance of a (functional) strategy:</p> <pre><code>import bofire.strategies.api as strategies\nstrategy = strategies.RandomStrategy(data_model=data_model)\n</code></pre> <p>As each strategy data model should be mapped to a specific (functional) strategy, we provide such a mapping:</p> <pre><code>strategy = strategies.map(data_model)\n</code></pre>"},{"location":"design_with_explicit_formula/","title":"Design with explicit Formula","text":"In\u00a0[\u00a0]: Copied! <pre>import bofire.strategies.api as strategies\nfrom bofire.data_models.api import Domain, Inputs\nfrom bofire.data_models.features.api import ContinuousInput\nfrom bofire.data_models.strategies.api import DoEStrategy\nfrom bofire.data_models.strategies.doe import DOptimalityCriterion\nfrom bofire.utils.doe import get_confounding_matrix\n</pre> import bofire.strategies.api as strategies from bofire.data_models.api import Domain, Inputs from bofire.data_models.features.api import ContinuousInput from bofire.data_models.strategies.api import DoEStrategy from bofire.data_models.strategies.doe import DOptimalityCriterion from bofire.utils.doe import get_confounding_matrix In\u00a0[\u00a0]: Copied! <pre>input_features = Inputs(\n    features=[\n        ContinuousInput(key=\"a\", bounds=(0, 5)),\n        ContinuousInput(key=\"b\", bounds=(40, 800)),\n        ContinuousInput(key=\"c\", bounds=(80, 180)),\n        ContinuousInput(key=\"d\", bounds=(200, 800)),\n    ],\n)\ndomain = Domain(inputs=input_features)\n</pre> input_features = Inputs(     features=[         ContinuousInput(key=\"a\", bounds=(0, 5)),         ContinuousInput(key=\"b\", bounds=(40, 800)),         ContinuousInput(key=\"c\", bounds=(80, 180)),         ContinuousInput(key=\"d\", bounds=(200, 800)),     ], ) domain = Domain(inputs=input_features) In\u00a0[\u00a0]: Copied! <pre>model_type = \"a + {a**2} + b + c + d + a:b + a:c + a:d + b:c + b:d + c:d\"\nmodel_type\n</pre> model_type = \"a + {a**2} + b + c + d + a:b + a:c + a:d + b:c + b:d + c:d\" model_type Out[\u00a0]: <pre>'a + {a**2} + b + c + d + a:b + a:c + a:d + b:c + b:d + c:d'</pre> In\u00a0[\u00a0]: Copied! <pre>data_model = DoEStrategy(\n    domain=domain,\n    criterion=DOptimalityCriterion(formula=model_type),\n    ipopt_options={\"max_iter\": 100, \"print_level\": 0},\n)\nstrategy = strategies.map(data_model=data_model)\ndesign = strategy.ask(17)\ndesign\n</pre> data_model = DoEStrategy(     domain=domain,     criterion=DOptimalityCriterion(formula=model_type),     ipopt_options={\"max_iter\": 100, \"print_level\": 0}, ) strategy = strategies.map(data_model=data_model) design = strategy.ask(17) design <pre>Tried to set Option: disp. It is not a valid option. Please check the list of available options.\n</pre> <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[4], line 7\n      1 data_model = DoEStrategy(\n      2     domain=domain,\n      3     criterion=DOptimalityCriterion(formula=model_type),\n      4     ipopt_options={\"max_iter\": 100, \"disp\": 0},\n      5 )\n      6 strategy = strategies.map(data_model=data_model)\n----&gt; 7 design = strategy.ask(17)\n      8 design\n\nFile ~/Documents/temporary/bofire/bofire/strategies/strategy.py:128, in Strategy.ask(self, candidate_count, add_pending, raise_validation_error)\n    123 if not self.has_sufficient_experiments():\n    124     raise ValueError(\n    125         \"Not enough experiments available to execute the strategy.\",\n    126     )\n--&gt; 128 candidates = self._ask(candidate_count=candidate_count)\n    130 self.domain.validate_candidates(\n    131     candidates=candidates,\n    132     only_inputs=True,\n    133     raise_validation_error=raise_validation_error,\n    134 )\n    136 if candidate_count is not None:\n\nFile ~/Documents/temporary/bofire/bofire/strategies/doe_strategy.py:113, in DoEStrategy._ask(self, candidate_count)\n    103 num_discrete_vars = len(new_discretes)\n    104 if (\n    105     self.data_model.optimization_strategy == \"relaxed\"\n    106     or (num_binary_vars == 0 and num_discrete_vars == 0)\n   (...)\n    111     )\n    112 ):\n--&gt; 113     design = find_local_max_ipopt(\n    114         new_domain,\n    115         n_experiments=_candidate_count,\n    116         fixed_experiments=None,\n    117         partially_fixed_experiments=adapted_partially_fixed_candidates,\n    118         ipopt_options=self.data_model.ipopt_options,\n    119         criterion=self.data_model.criterion,\n    120         use_hessian=self.data_model.use_hessian,\n    121     )\n    122 # TODO adapt to when exhaustive search accepts discrete variables\n    123 elif (\n    124     self.data_model.optimization_strategy == \"exhaustive\"\n    125     and num_discrete_vars == 0\n    126 ):\n\nFile ~/Documents/temporary/bofire/bofire/strategies/doe/design.py:188, in find_local_max_ipopt(domain, n_experiments, criterion, ipopt_options, sampling, fixed_experiments, partially_fixed_experiments, use_hessian)\n    182     problem = FirstOrderDoEProblem(\n    183         doe_objective=objective_function,\n    184         bounds=bounds,\n    185         constraints=constraints,\n    186     )\n    187 for key in _ipopt_options.keys():\n--&gt; 188     problem.add_option(key, _ipopt_options[key])\n    190 x, info = problem.solve(x0)\n    192 design = pd.DataFrame(\n    193     x.reshape(n_experiments, len(domain.inputs)),\n    194     columns=domain.inputs.get_keys(),\n    195     index=[f\"exp{i}\" for i in range(n_experiments)],\n    196 )\n\nFile ~/anaconda3/envs/bofire/lib/python3.11/site-packages/cyipopt/cython/ipopt_wrapper.pyx:495, in ipopt_wrapper.Problem.add_option()\n\nTypeError: Error while assigning an option</pre> In\u00a0[\u00a0]: Copied! <pre>import matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nmatplotlib.rcParams[\"figure.dpi\"] = 120\n\nm = get_confounding_matrix(\n    domain.inputs,\n    design=design,\n    interactions=[2, 3],\n    powers=[2],\n)\n\nsns.heatmap(m, annot=True, annot_kws={\"fontsize\": 7}, fmt=\"2.1f\")\nplt.show()\n</pre> import matplotlib import matplotlib.pyplot as plt import seaborn as sns   matplotlib.rcParams[\"figure.dpi\"] = 120  m = get_confounding_matrix(     domain.inputs,     design=design,     interactions=[2, 3],     powers=[2], )  sns.heatmap(m, annot=True, annot_kws={\"fontsize\": 7}, fmt=\"2.1f\") plt.show()"},{"location":"design_with_explicit_formula/#design-with-explicit-formula","title":"Design with explicit Formula\u00b6","text":"<p>This tutorial notebook shows how to setup a D-optimal design with BoFire while providing an explicit formula and not just one of the four available keywords <code>linear</code>, <code>linear-and-interaction</code>, <code>linear-and-quadratic</code>, <code>fully-quadratic</code>.</p> <p>Make sure that <code>cyipopt</code>is installed. The recommend way is the installation via conda <code>conda install -c conda-forge cyipopt</code>.</p>"},{"location":"design_with_explicit_formula/#imports","title":"Imports\u00b6","text":""},{"location":"design_with_explicit_formula/#setup-of-the-problem","title":"Setup of the problem\u00b6","text":""},{"location":"design_with_explicit_formula/#definition-of-the-formula-for-which-the-optimal-points-should-be-found","title":"Definition of the formula for which the optimal points should be found\u00b6","text":""},{"location":"design_with_explicit_formula/#find-d-optimal-design","title":"Find D-optimal Design\u00b6","text":""},{"location":"design_with_explicit_formula/#analyze-confounding","title":"Analyze Confounding\u00b6","text":""},{"location":"examples/","title":"Examples","text":"<p>This is a collection of code examples to allow for an easy exploration of the functionalities that BoFire offers. We provide even more tutorials in the repository.</p>"},{"location":"examples/#doe","title":"DoE","text":"<ul> <li>Creating designs for constrained design spaces</li> <li>Optimizing designs with respect to various optimality criteria</li> <li>Creating designs for a custom model</li> <li>Creating designs with NChooseK constraints</li> <li>Creating full and fractional factorial designs</li> </ul>"},{"location":"examples/#bayesian-optimization-for-chemistry","title":"Bayesian Optimization for Chemistry","text":"<p>These examples show how the tools provided by BoFire can be used for Bayesian Optimization with some of the challenges faced in real-world experiments:</p> <ul> <li>A toy example for optimizing a reaction</li> <li>Using a Tanimoto fingerprint kernel to optimize over molecules</li> <li>Using a MultiFidelity strategy with cheap, approximate experiments</li> </ul>"},{"location":"examples/#api-with-bofire","title":"API with BoFire","text":"<p>You can find an examples of how BoFire can be used in APIs in separate repositories:</p> <ul> <li>The Candidates API demonstrates an API that provides get new experimental candidates based on DoE or Bayesian optimization.</li> <li>The Types API is an API to check serialized data models. For instance, a JavaScript frontend that allows the user to define an optimization domain can check its validity explicitly.</li> </ul>"},{"location":"fingerprint_bayesopt/","title":"Fingerprint bayesopt","text":"In\u00a0[\u00a0]: Copied! <pre>import os\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\nimport bofire.strategies.api as strategies\nfrom bofire.benchmarks.data.photoswitches import EXPERIMENTS\nfrom bofire.benchmarks.LookupTableBenchmark import LookupTableBenchmark\nfrom bofire.data_models.acquisition_functions.api import qLogEI\nfrom bofire.data_models.domain.api import Domain, Inputs, Outputs\nfrom bofire.data_models.features.api import CategoricalMolecularInput, ContinuousOutput\nfrom bofire.data_models.molfeatures.api import FingerprintsFragments\nfrom bofire.data_models.objectives.api import MaximizeObjective\nfrom bofire.data_models.strategies.api import RandomStrategy, SoboStrategy\nfrom bofire.data_models.surrogates.api import BotorchSurrogates, TanimotoGPSurrogate\nfrom bofire.runners.api import run\n\n\nwarnings.filterwarnings(\"ignore\")\n\nSMOKE_TEST = os.environ.get(\"SMOKE_TEST\")\n</pre> import os import warnings  import numpy as np import pandas as pd from matplotlib import pyplot as plt  import bofire.strategies.api as strategies from bofire.benchmarks.data.photoswitches import EXPERIMENTS from bofire.benchmarks.LookupTableBenchmark import LookupTableBenchmark from bofire.data_models.acquisition_functions.api import qLogEI from bofire.data_models.domain.api import Domain, Inputs, Outputs from bofire.data_models.features.api import CategoricalMolecularInput, ContinuousOutput from bofire.data_models.molfeatures.api import FingerprintsFragments from bofire.data_models.objectives.api import MaximizeObjective from bofire.data_models.strategies.api import RandomStrategy, SoboStrategy from bofire.data_models.surrogates.api import BotorchSurrogates, TanimotoGPSurrogate from bofire.runners.api import run   warnings.filterwarnings(\"ignore\")  SMOKE_TEST = os.environ.get(\"SMOKE_TEST\") In\u00a0[\u00a0]: Copied! <pre>benchmark = {\n    \"input\": \"SMILES\",\n    \"output\": \"E isomer pi-pi* wavelength in nm\",\n}\ndf = pd.read_json(EXPERIMENTS)\nmain_file = pd.DataFrame(columns=[benchmark[\"input\"], benchmark[\"output\"]])\nnans = df[benchmark[\"output\"]].isnull().to_list()\nnan_indices = [nan for nan, x in enumerate(nans) if x]\nmain_file[benchmark[\"input\"]] = df[benchmark[\"input\"]].drop(nan_indices).to_list()\nmain_file[benchmark[\"output\"]] = (\n    df[benchmark[\"output\"]].dropna().to_numpy().reshape(-1, 1)\n)\ninput_feature = CategoricalMolecularInput(\n    key=benchmark[\"input\"],\n    categories=list(set(main_file[benchmark[\"input\"]].to_list())),\n)\nobjective = MaximizeObjective(\n    w=1.0,\n)\ninputs = Inputs(features=[input_feature])\noutput_feature = ContinuousOutput(key=benchmark[\"output\"], objective=objective)\noutputs = Outputs(features=[output_feature])\ndomain = Domain(inputs=inputs, outputs=outputs)\n</pre> benchmark = {     \"input\": \"SMILES\",     \"output\": \"E isomer pi-pi* wavelength in nm\", } df = pd.read_json(EXPERIMENTS) main_file = pd.DataFrame(columns=[benchmark[\"input\"], benchmark[\"output\"]]) nans = df[benchmark[\"output\"]].isnull().to_list() nan_indices = [nan for nan, x in enumerate(nans) if x] main_file[benchmark[\"input\"]] = df[benchmark[\"input\"]].drop(nan_indices).to_list() main_file[benchmark[\"output\"]] = (     df[benchmark[\"output\"]].dropna().to_numpy().reshape(-1, 1) ) input_feature = CategoricalMolecularInput(     key=benchmark[\"input\"],     categories=list(set(main_file[benchmark[\"input\"]].to_list())), ) objective = MaximizeObjective(     w=1.0, ) inputs = Inputs(features=[input_feature]) output_feature = ContinuousOutput(key=benchmark[\"output\"], objective=objective) outputs = Outputs(features=[output_feature]) domain = Domain(inputs=inputs, outputs=outputs) In\u00a0[\u00a0]: Copied! <pre>def sample(domain):\n    datamodel = RandomStrategy(domain=domain)\n    sampler = strategies.map(data_model=datamodel)\n    sampled = sampler.ask(20)\n    return sampled\n\n\ndef best(domain: Domain, experiments: pd.DataFrame) -&gt; float:\n    return experiments[domain.outputs.get_keys()[0]].max()\n\n\nn_iter = 20 if not SMOKE_TEST else 1\nbo_results_set = []\nrandom_results_set = []\nn_iterations = 49 if not SMOKE_TEST else 1\n\nfor _ in range(n_iter):\n    Benchmark = LookupTableBenchmark(domain=domain, lookup_table=main_file)\n    sampled = sample(Benchmark.domain)\n    sampled_xy = Benchmark.f(sampled, return_complete=True)\n    random_results = run(\n        Benchmark,\n        strategy_factory=lambda domain: strategies.map(RandomStrategy(domain=domain)),\n        n_iterations=n_iterations,\n        metric=best,\n        initial_sampler=sampled_xy,\n        n_runs=1,\n        n_procs=1,\n    )\n\n    specs = {Benchmark.domain.inputs.get_keys()[0]: FingerprintsFragments(n_bits=2048)}\n    surrogate = TanimotoGPSurrogate(\n        inputs=Benchmark.domain.inputs,\n        outputs=Benchmark.domain.outputs,\n        input_preprocessing_specs=specs,\n    )\n\n    def sobo_factory(domain: Domain, surrogate=surrogate):\n        return strategies.map(\n            SoboStrategy(\n                domain=domain,\n                acquisition_function=qLogEI(),\n                surrogate_specs=BotorchSurrogates(surrogates=[surrogate]),\n            ),\n        )\n\n    qExpectedImprovement = qLogEI()\n    bo_results = run(\n        Benchmark,\n        strategy_factory=sobo_factory,\n        n_iterations=n_iterations,\n        metric=best,\n        initial_sampler=sampled_xy,\n        n_runs=1,\n        n_procs=1,\n    )\n    random_results_new = np.insert(\n        random_results[0][1].to_numpy(),\n        0,\n        best(Benchmark.domain, sampled_xy),\n    )\n    bo_results_new = np.insert(\n        bo_results[0][1].to_numpy(),\n        0,\n        best(Benchmark.domain, sampled_xy),\n    )\n    random_results_set.append(random_results_new)\n    bo_results_set.append(bo_results_new)\n</pre> def sample(domain):     datamodel = RandomStrategy(domain=domain)     sampler = strategies.map(data_model=datamodel)     sampled = sampler.ask(20)     return sampled   def best(domain: Domain, experiments: pd.DataFrame) -&gt; float:     return experiments[domain.outputs.get_keys()[0]].max()   n_iter = 20 if not SMOKE_TEST else 1 bo_results_set = [] random_results_set = [] n_iterations = 49 if not SMOKE_TEST else 1  for _ in range(n_iter):     Benchmark = LookupTableBenchmark(domain=domain, lookup_table=main_file)     sampled = sample(Benchmark.domain)     sampled_xy = Benchmark.f(sampled, return_complete=True)     random_results = run(         Benchmark,         strategy_factory=lambda domain: strategies.map(RandomStrategy(domain=domain)),         n_iterations=n_iterations,         metric=best,         initial_sampler=sampled_xy,         n_runs=1,         n_procs=1,     )      specs = {Benchmark.domain.inputs.get_keys()[0]: FingerprintsFragments(n_bits=2048)}     surrogate = TanimotoGPSurrogate(         inputs=Benchmark.domain.inputs,         outputs=Benchmark.domain.outputs,         input_preprocessing_specs=specs,     )      def sobo_factory(domain: Domain, surrogate=surrogate):         return strategies.map(             SoboStrategy(                 domain=domain,                 acquisition_function=qLogEI(),                 surrogate_specs=BotorchSurrogates(surrogates=[surrogate]),             ),         )      qExpectedImprovement = qLogEI()     bo_results = run(         Benchmark,         strategy_factory=sobo_factory,         n_iterations=n_iterations,         metric=best,         initial_sampler=sampled_xy,         n_runs=1,         n_procs=1,     )     random_results_new = np.insert(         random_results[0][1].to_numpy(),         0,         best(Benchmark.domain, sampled_xy),     )     bo_results_new = np.insert(         bo_results[0][1].to_numpy(),         0,         best(Benchmark.domain, sampled_xy),     )     random_results_set.append(random_results_new)     bo_results_set.append(bo_results_new) In\u00a0[\u00a0]: Copied! <pre># Define a confience interval function for plotting.\ndef ci(y):\n    return 1.96 * y.std(axis=0) / np.sqrt(n_iter)\n\n\nif not SMOKE_TEST:\n    iters = np.arange(n_iterations + 1)\n    y_rnd = np.asarray(random_results_set)\n    y_ei = np.asarray(bo_results_set)\n\n    y_rnd_mean = y_rnd.mean(axis=0)\n    y_ei_mean = y_ei.mean(axis=0)\n    y_rnd_std = y_rnd.std(axis=0)\n    y_ei_std = y_ei.std(axis=0)\n\n    lower_rnd = y_rnd_mean - y_rnd_std\n    upper_rnd = y_rnd_mean + y_rnd_std\n    lower_ei = y_ei_mean - y_ei_std\n    upper_ei = y_ei_mean + y_ei_std\n\n    plt.plot(iters, y_rnd_mean, label=\"Random\")\n    plt.fill_between(iters, lower_rnd, upper_rnd, alpha=0.2)\n    plt.plot(iters, y_ei_mean, label=\"SOBO\")\n    plt.fill_between(iters, lower_ei, upper_ei, alpha=0.2)\n    plt.xlabel(\"Number of Iterations\")\n    plt.ylabel(\"Best Objective Value\")\n    plt.legend(loc=\"lower right\")\n    plt.show()\n</pre> # Define a confience interval function for plotting. def ci(y):     return 1.96 * y.std(axis=0) / np.sqrt(n_iter)   if not SMOKE_TEST:     iters = np.arange(n_iterations + 1)     y_rnd = np.asarray(random_results_set)     y_ei = np.asarray(bo_results_set)      y_rnd_mean = y_rnd.mean(axis=0)     y_ei_mean = y_ei.mean(axis=0)     y_rnd_std = y_rnd.std(axis=0)     y_ei_std = y_ei.std(axis=0)      lower_rnd = y_rnd_mean - y_rnd_std     upper_rnd = y_rnd_mean + y_rnd_std     lower_ei = y_ei_mean - y_ei_std     upper_ei = y_ei_mean + y_ei_std      plt.plot(iters, y_rnd_mean, label=\"Random\")     plt.fill_between(iters, lower_rnd, upper_rnd, alpha=0.2)     plt.plot(iters, y_ei_mean, label=\"SOBO\")     plt.fill_between(iters, lower_ei, upper_ei, alpha=0.2)     plt.xlabel(\"Number of Iterations\")     plt.ylabel(\"Best Objective Value\")     plt.legend(loc=\"lower right\")     plt.show()"},{"location":"fingerprint_bayesopt/#bayesian-optimisation-over-molecules","title":"Bayesian Optimisation Over Molecules\u00b6","text":"<p>An example notebook for Bayesian optimisation on a molecular dataset using a Tanimoto fingerprint kernel and the photoswitch dataset.$\\newline$ Paper: https://pubs.rsc.org/en/content/articlelanding/2022/sc/d2sc04306h $\\newline$ Code: https://github.com/Ryan-Rhys/The-Photoswitch-Dataset $\\newline$ This notebook is adapted from https://github.com/leojklarner/gauche/blob/main/notebooks/Bayesian%20Optimisation%20Over%20Molecules.ipynb $\\newline$ The method of obtaining new data from a discrete dataset is explained in the notebook and the details of the dataset and the method are explained in the code and the paper respectively.</p>"},{"location":"fingerprint_bayesopt/#imports","title":"Imports\u00b6","text":""},{"location":"fingerprint_bayesopt/#benchmark","title":"Benchmark\u00b6","text":"<p>input and output feature keys and extract them to get LookUpTable</p>"},{"location":"fingerprint_bayesopt/#random-vs-sobo-optimization","title":"Random vs SOBO optimization\u00b6","text":"<p>For molecules, we use Tanimoto GP which has a Tanimoto kernel as default</p>"},{"location":"fingerprint_bayesopt/#performance","title":"Performance\u00b6","text":"<p>SOBO outperforms random search in terms of selecting molecules with high E isomer pi-pi* transition wavelength.</p>"},{"location":"fractional_factorial/","title":"Full and Fractional Factorial Designs","text":"In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\nimport bofire.strategies.api as strategies\nfrom bofire.data_models.domain.api import Domain\nfrom bofire.data_models.features.api import CategoricalInput, ContinuousInput\nfrom bofire.data_models.strategies.api import FractionalFactorialStrategy\nfrom bofire.utils.doe import get_alias_structure, get_confounding_matrix, get_generator\n\n\ndef plot_design(design: pd.DataFrame):\n    # we do a plot with three subplots in one row in which the three degrees of freedom (temperature, time and ph) are plotted\n    _, axs = plt.subplots(1, 3, figsize=(15, 5))\n    axs[0].scatter(design[\"temperature\"], design[\"time\"])\n    axs[0].set_xlabel(\"Temperature\")\n    axs[0].set_ylabel(\"Time\")\n    axs[1].scatter(design[\"temperature\"], design[\"ph\"])\n    axs[1].set_xlabel(\"Temperature\")\n    axs[1].set_ylabel(\"pH\")\n    axs[2].scatter(design[\"time\"], design[\"ph\"])\n    axs[2].set_xlabel(\"Time\")\n    axs[2].set_ylabel(\"pH\")\n    plt.show()\n</pre> import matplotlib.pyplot as plt import pandas as pd import seaborn as sns  import bofire.strategies.api as strategies from bofire.data_models.domain.api import Domain from bofire.data_models.features.api import CategoricalInput, ContinuousInput from bofire.data_models.strategies.api import FractionalFactorialStrategy from bofire.utils.doe import get_alias_structure, get_confounding_matrix, get_generator   def plot_design(design: pd.DataFrame):     # we do a plot with three subplots in one row in which the three degrees of freedom (temperature, time and ph) are plotted     _, axs = plt.subplots(1, 3, figsize=(15, 5))     axs[0].scatter(design[\"temperature\"], design[\"time\"])     axs[0].set_xlabel(\"Temperature\")     axs[0].set_ylabel(\"Time\")     axs[1].scatter(design[\"temperature\"], design[\"ph\"])     axs[1].set_xlabel(\"Temperature\")     axs[1].set_ylabel(\"pH\")     axs[2].scatter(design[\"time\"], design[\"ph\"])     axs[2].set_xlabel(\"Time\")     axs[2].set_ylabel(\"pH\")     plt.show() <pre>/opt/homebrew/Caskroom/miniforge/base/envs/bofire-2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> In\u00a0[\u00a0]: Copied! <pre>domain = Domain(\n    inputs=[\n        ContinuousInput(key=\"temperature\", bounds=(20, 80)),\n        ContinuousInput(key=\"time\", bounds=(60, 120)),\n        ContinuousInput(key=\"ph\", bounds=(7, 13)),\n    ],\n)\n</pre> domain = Domain(     inputs=[         ContinuousInput(key=\"temperature\", bounds=(20, 80)),         ContinuousInput(key=\"time\", bounds=(60, 120)),         ContinuousInput(key=\"ph\", bounds=(7, 13)),     ], ) In\u00a0[\u00a0]: Copied! <pre>strategy_data = FractionalFactorialStrategy(\n    domain=domain,\n    n_center=1,  # number of center points\n    n_repetitions=1,  # number of repetitions, we do only one round here\n)\nstrategy = strategies.map(strategy_data)\ndesign = strategy.ask()\ndisplay(design)\n\nplot_design(design=design)\n</pre> strategy_data = FractionalFactorialStrategy(     domain=domain,     n_center=1,  # number of center points     n_repetitions=1,  # number of repetitions, we do only one round here ) strategy = strategies.map(strategy_data) design = strategy.ask() display(design)  plot_design(design=design) ph temperature time 0 7.0 20.0 60.0 1 7.0 20.0 120.0 2 7.0 80.0 60.0 3 7.0 80.0 120.0 4 13.0 20.0 60.0 5 13.0 20.0 120.0 6 13.0 80.0 60.0 7 13.0 80.0 120.0 8 10.0 50.0 90.0 <p>The confounding structure is shown below, as expected for a full factorial design, no confound is present.</p> In\u00a0[\u00a0]: Copied! <pre>m = get_confounding_matrix(domain.inputs, design=design, interactions=[2])\n\nsns.heatmap(m, annot=True, annot_kws={\"fontsize\": 7}, fmt=\"2.1f\")\nplt.show()\n</pre> m = get_confounding_matrix(domain.inputs, design=design, interactions=[2])  sns.heatmap(m, annot=True, annot_kws={\"fontsize\": 7}, fmt=\"2.1f\") plt.show() In\u00a0[\u00a0]: Copied! <pre>blocked_domain = Domain(\n    inputs=[\n        ContinuousInput(key=\"temperature\", bounds=(20, 80)),\n        ContinuousInput(key=\"time\", bounds=(60, 120)),\n        ContinuousInput(key=\"ph\", bounds=(7, 13)),\n        CategoricalInput(key=\"operator\", categories=[\"A\", \"B\", \"C\", \"D\"]),\n    ],\n)\n\n\nstrategy_data = FractionalFactorialStrategy(\n    domain=blocked_domain,\n    n_center=1,  # number of center points per block\n    n_repetitions=1,  # number of repetitions, we do only one round here\n    block_feature_key=\"operator\",\n)\nstrategy = strategies.map(strategy_data)\ndesign = strategy.ask()\ndisplay(design)\n\nplot_design(design=design)\n</pre> blocked_domain = Domain(     inputs=[         ContinuousInput(key=\"temperature\", bounds=(20, 80)),         ContinuousInput(key=\"time\", bounds=(60, 120)),         ContinuousInput(key=\"ph\", bounds=(7, 13)),         CategoricalInput(key=\"operator\", categories=[\"A\", \"B\", \"C\", \"D\"]),     ], )   strategy_data = FractionalFactorialStrategy(     domain=blocked_domain,     n_center=1,  # number of center points per block     n_repetitions=1,  # number of repetitions, we do only one round here     block_feature_key=\"operator\", ) strategy = strategies.map(strategy_data) design = strategy.ask() display(design)  plot_design(design=design) ph temperature time operator 0 7.0 20.0 60.0 A 1 13.0 80.0 120.0 A 2 10.0 50.0 90.0 A 3 7.0 20.0 120.0 B 4 13.0 80.0 60.0 B 5 10.0 50.0 90.0 B 6 7.0 80.0 60.0 C 7 13.0 20.0 120.0 C 8 10.0 50.0 90.0 C 9 7.0 80.0 120.0 D 10 13.0 20.0 60.0 D 11 10.0 50.0 90.0 D <p>Here a fractional factorial design of the form $2^{3-1}$ is setup by specifying the number of generators (here 1). In comparison to the full factorial design with 9 candidates, it features only 5 experiments.</p> In\u00a0[\u00a0]: Copied! <pre>strategy_data = FractionalFactorialStrategy(\n    domain=domain,\n    n_center=1,  # number of center points\n    n_repetitions=1,  # number of repetitions, we do only one round here\n    n_generators=1,  # number of generators, ie number of reducing factors\n)\nstrategy = strategies.map(strategy_data)\ndesign = strategy.ask()\ndisplay(design)\n</pre> strategy_data = FractionalFactorialStrategy(     domain=domain,     n_center=1,  # number of center points     n_repetitions=1,  # number of repetitions, we do only one round here     n_generators=1,  # number of generators, ie number of reducing factors ) strategy = strategies.map(strategy_data) design = strategy.ask() display(design) <p>The generator string is automatically generated by making use of the method <code>get_generator</code> and specifying the total number of factors (here 3) and the number of generators (here 1).</p> In\u00a0[\u00a0]: Copied! <pre>get_generator(n_factors=3, n_generators=1)\n</pre> get_generator(n_factors=3, n_generators=1) <p>As expected for a type III design the main effects are confounded with the two factor interactions:</p> In\u00a0[\u00a0]: Copied! <pre>m = get_confounding_matrix(domain.inputs, design=design, interactions=[2])\n\nsns.heatmap(m, annot=True, annot_kws={\"fontsize\": 7}, fmt=\"2.1f\")\nplt.show()\n</pre> m = get_confounding_matrix(domain.inputs, design=design, interactions=[2])  sns.heatmap(m, annot=True, annot_kws={\"fontsize\": 7}, fmt=\"2.1f\") plt.show() <p>This can also be expressed by the so called alias structure that can be calculated as following:</p> In\u00a0[\u00a0]: Copied! <pre>get_alias_structure(\"a b ab\")\n</pre> get_alias_structure(\"a b ab\") <p>Here again a fractional factorial design of the form $2^{3-1}$ is setup by providing the complete generator string of the form <code>a b -ab</code> explicitly to the strategy.</p> In\u00a0[\u00a0]: Copied! <pre>strategy_data = FractionalFactorialStrategy(\n    domain=domain,\n    n_center=1,  # number of center points\n    n_repetitions=1,  # number of repetitions, we do only one round here\n    generator=\"a b -ab\",  # the exact generator\n)\nstrategy = strategies.map(strategy_data)\ndesign = strategy.ask()\ndisplay(design)\n</pre> strategy_data = FractionalFactorialStrategy(     domain=domain,     n_center=1,  # number of center points     n_repetitions=1,  # number of repetitions, we do only one round here     generator=\"a b -ab\",  # the exact generator ) strategy = strategies.map(strategy_data) design = strategy.ask() display(design) <p>The last two designs differ only in the last feature <code>time</code>, since the generator strings are different. In the first one it holds <code>time=ph x temperature</code> whereas in the second it holds <code>time=-ph x temperature</code>, which is also reflected in the confounding structure.</p> In\u00a0[\u00a0]: Copied! <pre>m = get_confounding_matrix(domain.inputs, design=design, interactions=[2])\n\nsns.heatmap(m, annot=True, annot_kws={\"fontsize\": 7}, fmt=\"2.1f\")\nplt.show()\n</pre> m = get_confounding_matrix(domain.inputs, design=design, interactions=[2])  sns.heatmap(m, annot=True, annot_kws={\"fontsize\": 7}, fmt=\"2.1f\") plt.show()"},{"location":"fractional_factorial/#full-and-fractional-factorial-designs","title":"Full and Fractional Factorial Designs\u00b6","text":"<p>BoFire can be used to setup full (two level) and fractional factorial designs (https://en.wikipedia.org/wiki/Fractional_factorial_design). This tutorial notebook shows how.</p>"},{"location":"fractional_factorial/#imports-and-helper-functions","title":"Imports and helper functions\u00b6","text":""},{"location":"fractional_factorial/#setup-the-problem-domain","title":"Setup the problem domain\u00b6","text":"<p>The designs are generated for a simple three dimensional problem comprised of three continuous factors/features.</p>"},{"location":"fractional_factorial/#setup-a-full-factorial-design","title":"Setup a full factorial design\u00b6","text":"<p>Here we setup a full two-level factorial design including a center point and plot it.</p>"},{"location":"fractional_factorial/#setup-a-full-factorial-design-with-blocking","title":"Setup a full factorial design with blocking\u00b6","text":"<p>Here we setup a blocked full two-level factorial design including a center point and plot it.</p>"},{"location":"fractional_factorial/#setup-a-fractional-factorial-design","title":"Setup a fractional factorial design\u00b6","text":""},{"location":"getting_started/","title":"Basic terminology","text":"In\u00a0[\u00a0]: Copied! <pre>from bofire.data_models.features.api import (\n    CategoricalDescriptorInput,\n    CategoricalInput,\n    ContinuousInput,\n    DiscreteInput,\n)\n\n\nx1 = ContinuousInput(key=\"conc_A\", bounds=[0, 1])\nx2 = ContinuousInput(key=\"conc_B\", bounds=[0, 1])\nx3 = ContinuousInput(key=\"conc_C\", bounds=[0, 1])\nx4 = DiscreteInput(key=\"temperature\", values=[20, 50, 90], unit=\"\u00b0C\")\n\nx5 = CategoricalInput(\n    key=\"catalyst\",\n    categories=[\"cat_X\", \"cat_Y\", \"cat_Z\"],\n    allowed=[\n        True,\n        True,\n        False,\n    ],  # we have run out of catalyst Z, but still want to model past experiments\n)\n\nx6 = CategoricalDescriptorInput(\n    key=\"solvent\",\n    categories=[\"water\", \"methanol\", \"ethanol\"],\n    descriptors=[\"viscosity (mPa s)\", \"density (kg/m3)\"],\n    values=[[1.0, 997], [0.59, 792], [1.2, 789]],\n)\n</pre> from bofire.data_models.features.api import (     CategoricalDescriptorInput,     CategoricalInput,     ContinuousInput,     DiscreteInput, )   x1 = ContinuousInput(key=\"conc_A\", bounds=[0, 1]) x2 = ContinuousInput(key=\"conc_B\", bounds=[0, 1]) x3 = ContinuousInput(key=\"conc_C\", bounds=[0, 1]) x4 = DiscreteInput(key=\"temperature\", values=[20, 50, 90], unit=\"\u00b0C\")  x5 = CategoricalInput(     key=\"catalyst\",     categories=[\"cat_X\", \"cat_Y\", \"cat_Z\"],     allowed=[         True,         True,         False,     ],  # we have run out of catalyst Z, but still want to model past experiments )  x6 = CategoricalDescriptorInput(     key=\"solvent\",     categories=[\"water\", \"methanol\", \"ethanol\"],     descriptors=[\"viscosity (mPa s)\", \"density (kg/m3)\"],     values=[[1.0, 997], [0.59, 792], [1.2, 789]], ) <p>We can define both continuous and categorical outputs. Each output feature should have an objective, which determines if we aim to minimize, maximize, or drive the feature to a given value. Furthermore, we can define weights between 0 and 1 in case the objectives should not be weighted equally.</p> In\u00a0[\u00a0]: Copied! <pre>from bofire.data_models.features.api import ContinuousOutput\nfrom bofire.data_models.objectives.api import MaximizeObjective, MinimizeObjective\n\n\nobjective1 = MaximizeObjective(\n    w=1.0,\n    bounds=[0.0, 1.0],\n)\ny1 = ContinuousOutput(key=\"yield\", objective=objective1)\n\nobjective2 = MinimizeObjective(w=1.0)\ny2 = ContinuousOutput(key=\"time_taken\", objective=objective2)\n</pre> from bofire.data_models.features.api import ContinuousOutput from bofire.data_models.objectives.api import MaximizeObjective, MinimizeObjective   objective1 = MaximizeObjective(     w=1.0,     bounds=[0.0, 1.0], ) y1 = ContinuousOutput(key=\"yield\", objective=objective1)  objective2 = MinimizeObjective(w=1.0) y2 = ContinuousOutput(key=\"time_taken\", objective=objective2) <p>In- and output features are collected in respective feature lists, which can be summarized with the <code>get_reps_df</code> method.</p> In\u00a0[\u00a0]: Copied! <pre>from bofire.data_models.domain.api import Inputs, Outputs\n\n\ninput_features = Inputs(features=[x1, x2, x3, x4, x5, x6])\noutput_features = Outputs(features=[y1, y2])\n\ninput_features.get_reps_df()\n</pre> from bofire.data_models.domain.api import Inputs, Outputs   input_features = Inputs(features=[x1, x2, x3, x4, x5, x6]) output_features = Outputs(features=[y1, y2])  input_features.get_reps_df() In\u00a0[\u00a0]: Copied! <pre>output_features.get_reps_df()\n</pre> output_features.get_reps_df() <p>Individual features can be retrieved by name, and a collection of features can be retrieved with a list of names.</p> In\u00a0[\u00a0]: Copied! <pre>input_features.get_by_key(\"catalyst\")\n</pre> input_features.get_by_key(\"catalyst\") In\u00a0[\u00a0]: Copied! <pre>input_features.get_by_keys([\"catalyst\", \"conc_B\"])\n</pre> input_features.get_by_keys([\"catalyst\", \"conc_B\"]) <p>Features of a specific type can be returned by the <code>get</code> method. By using the <code>exact</code> argument, we can force the method to only return features that match the class exactly.</p> In\u00a0[\u00a0]: Copied! <pre>input_features.get(CategoricalInput)\n</pre> input_features.get(CategoricalInput) In\u00a0[\u00a0]: Copied! <pre>input_features.get(CategoricalInput, exact=True)\n</pre> input_features.get(CategoricalInput, exact=True) <p>The <code>get_keys</code> method follows the same logic as the <code>get</code> method, but returns just the keys of the features instead of the features itself.</p> In\u00a0[\u00a0]: Copied! <pre>input_features.get_keys(CategoricalInput)\n</pre> input_features.get_keys(CategoricalInput) <p>The input feature container further provides methods to return a feature container with only all fixed or all free features.</p> In\u00a0[\u00a0]: Copied! <pre>free_inputs = input_features.get_free()\nfixed_inputs = input_features.get_fixed()\n</pre> free_inputs = input_features.get_free() fixed_inputs = input_features.get_fixed() <p>One can uniformly sample from individual input features.</p> In\u00a0[\u00a0]: Copied! <pre>x5.sample(2)\n</pre> x5.sample(2) <p>Or directly from input feature containers, uniform, sobol and LHS sampling is possible. A default, uniform sampling is used.</p> In\u00a0[\u00a0]: Copied! <pre>from bofire.data_models.enum import SamplingMethodEnum\n\n\nX = input_features.sample(n=10, method=SamplingMethodEnum.LHS)\n\nX\n</pre> from bofire.data_models.enum import SamplingMethodEnum   X = input_features.sample(n=10, method=SamplingMethodEnum.LHS)  X In\u00a0[\u00a0]: Copied! <pre>from bofire.data_models.constraints.api import (\n    LinearEqualityConstraint,\n    LinearInequalityConstraint,\n)\n\n\n# A mixture: x1 + x2 + x3 = 1\nconstr1 = LinearEqualityConstraint(\n    features=[\"conc_A\", \"conc_B\", \"conc_C\"],\n    coefficients=[1, 1, 1],\n    rhs=1,\n)\n\n# x1 + 2 * x3 &lt; 0.8\nconstr2 = LinearInequalityConstraint(\n    features=[\"conc_A\", \"conc_C\"],\n    coefficients=[1, 2],\n    rhs=0.8,\n)\n</pre> from bofire.data_models.constraints.api import (     LinearEqualityConstraint,     LinearInequalityConstraint, )   # A mixture: x1 + x2 + x3 = 1 constr1 = LinearEqualityConstraint(     features=[\"conc_A\", \"conc_B\", \"conc_C\"],     coefficients=[1, 1, 1],     rhs=1, )  # x1 + 2 * x3 &lt; 0.8 constr2 = LinearInequalityConstraint(     features=[\"conc_A\", \"conc_C\"],     coefficients=[1, 2],     rhs=0.8, ) <p>Linear constraints can only operate on <code>ContinuousInput</code> features.</p> <p><code>NonlinearEqualityConstraint</code> and <code>NonlinearInequalityConstraint</code> take any expression that can be evaluated by pandas.eval, including mathematical operators such as <code>sin</code>, <code>exp</code>, <code>log10</code> or exponentiation. So far, they cannot be used in any optimizations.</p> In\u00a0[\u00a0]: Copied! <pre>from bofire.data_models.constraints.api import NonlinearEqualityConstraint\n\n\n# The unit circle: x1**2 + x2**2 = 1\nconst3 = NonlinearEqualityConstraint(expression=\"conc_A**2 + conc_B**2 - 1\")\nconst3\n</pre> from bofire.data_models.constraints.api import NonlinearEqualityConstraint   # The unit circle: x1**2 + x2**2 = 1 const3 = NonlinearEqualityConstraint(expression=\"conc_A**2 + conc_B**2 - 1\") const3 In\u00a0[\u00a0]: Copied! <pre>from bofire.data_models.constraints.api import NChooseKConstraint\n\n\n# Only 1 or 2 out of 3 compounds can be present (have non-zero concentration)\nconstr5 = NChooseKConstraint(\n    features=[\"conc_A\", \"conc_B\", \"conc_C\"],\n    min_count=1,\n    max_count=2,\n    none_also_valid=False,\n)\nconstr5\n</pre> from bofire.data_models.constraints.api import NChooseKConstraint   # Only 1 or 2 out of 3 compounds can be present (have non-zero concentration) constr5 = NChooseKConstraint(     features=[\"conc_A\", \"conc_B\", \"conc_C\"],     min_count=1,     max_count=2,     none_also_valid=False, ) constr5 <p>Note that we have to set a boolean, if none is also a valid selection, e.g. if we want to have 0, 1, or 2 of the ingredients in our recipe.</p> <p>Similar to the features, constraints can be grouped in a container which acts as the union constraints.</p> In\u00a0[\u00a0]: Copied! <pre>from bofire.data_models.domain.api import Constraints\n\n\nconstraints = Constraints(constraints=[constr1, constr2])\n</pre> from bofire.data_models.domain.api import Constraints   constraints = Constraints(constraints=[constr1, constr2]) <p>A summary of the constraints can be obtained by the method <code>get_reps_df</code>:</p> In\u00a0[\u00a0]: Copied! <pre>constraints.get_reps_df()\n</pre> constraints.get_reps_df() <p>We can check whether a point satisfies individual constraints or the list of constraints.</p> In\u00a0[\u00a0]: Copied! <pre>constr2.is_fulfilled(X).values\n</pre> constr2.is_fulfilled(X).values <p>Output constraints can be setup via sigmoid-shaped objectives passed as argument to the respective feature, which can then also be plotted.</p> In\u00a0[\u00a0]: Copied! <pre>from bofire.data_models.objectives.api import MinimizeSigmoidObjective\nfrom bofire.plot.api import plot_objective_plotly\n\n\noutput_constraint = MinimizeSigmoidObjective(w=1.0, steepness=10, tp=0.5)\ny3 = ContinuousOutput(key=\"y3\", objective=output_constraint)\n\noutput_features = Outputs(features=[y1, y2, y3])\n\nfig = plot_objective_plotly(feature=y3, lower=0, upper=1)\n\nfig.show()\n</pre> from bofire.data_models.objectives.api import MinimizeSigmoidObjective from bofire.plot.api import plot_objective_plotly   output_constraint = MinimizeSigmoidObjective(w=1.0, steepness=10, tp=0.5) y3 = ContinuousOutput(key=\"y3\", objective=output_constraint)  output_features = Outputs(features=[y1, y2, y3])  fig = plot_objective_plotly(feature=y3, lower=0, upper=1)  fig.show() In\u00a0[\u00a0]: Copied! <pre>from bofire.data_models.domain.api import Domain\n\n\ndomain = Domain(inputs=input_features, outputs=output_features, constraints=constraints)\n</pre> from bofire.data_models.domain.api import Domain   domain = Domain(inputs=input_features, outputs=output_features, constraints=constraints) <p>In addition one can instantiate the domain also just from lists.</p> In\u00a0[\u00a0]: Copied! <pre>domain_single_objective = Domain.from_lists(\n    inputs=[x1, x2, x3, x4, x5, x6],\n    outputs=[y1],\n    constraints=[],\n)\n</pre> domain_single_objective = Domain.from_lists(     inputs=[x1, x2, x3, x4, x5, x6],     outputs=[y1],     constraints=[], ) In\u00a0[\u00a0]: Copied! <pre>import bofire.strategies.api as strategies\nfrom bofire.data_models.strategies.api import RandomStrategy\n\n\nstrategy_data_model = RandomStrategy(domain=domain)\n\nrandom_strategy = strategies.map(strategy_data_model)\nrandom_candidates = random_strategy.ask(2)\n\nrandom_candidates\n</pre> import bofire.strategies.api as strategies from bofire.data_models.strategies.api import RandomStrategy   strategy_data_model = RandomStrategy(domain=domain)  random_strategy = strategies.map(strategy_data_model) random_candidates = random_strategy.ask(2)  random_candidates In\u00a0[\u00a0]: Copied! <pre>from bofire.benchmarks.single import Himmelblau\n\n\nbenchmark = Himmelblau()\n\n(benchmark.domain.inputs + benchmark.domain.outputs).get_reps_df()\n</pre> from bofire.benchmarks.single import Himmelblau   benchmark = Himmelblau()  (benchmark.domain.inputs + benchmark.domain.outputs).get_reps_df() <p>Generating some initial data works as follows:</p> In\u00a0[\u00a0]: Copied! <pre>samples = benchmark.domain.inputs.sample(10)\n\nexperiments = benchmark.f(samples, return_complete=True)\n\nexperiments\n</pre> samples = benchmark.domain.inputs.sample(10)  experiments = benchmark.f(samples, return_complete=True)  experiments <p>Let's setup the SOBO strategy and ask for a candidate. First we need a serializable data model that contains the hyperparameters.</p> In\u00a0[\u00a0]: Copied! <pre>from pprint import pprint\n\nfrom bofire.data_models.acquisition_functions.api import qLogNEI\nfrom bofire.data_models.strategies.api import SoboStrategy as SoboStrategyDM\n\n\nsobo_strategy_data_model = SoboStrategyDM(\n    domain=benchmark.domain,\n    acquisition_function=qLogNEI(),\n)\n\n# print information about hyperparameters\nprint(\"Acquisition function:\", sobo_strategy_data_model.acquisition_function)\nprint()\nprint(\"Surrogate type:\", sobo_strategy_data_model.surrogate_specs.surrogates[0].type)\nprint()\nprint(\"Surrogate's kernel:\")\npprint(sobo_strategy_data_model.surrogate_specs.surrogates[0].kernel.model_dump())\n</pre> from pprint import pprint  from bofire.data_models.acquisition_functions.api import qLogNEI from bofire.data_models.strategies.api import SoboStrategy as SoboStrategyDM   sobo_strategy_data_model = SoboStrategyDM(     domain=benchmark.domain,     acquisition_function=qLogNEI(), )  # print information about hyperparameters print(\"Acquisition function:\", sobo_strategy_data_model.acquisition_function) print() print(\"Surrogate type:\", sobo_strategy_data_model.surrogate_specs.surrogates[0].type) print() print(\"Surrogate's kernel:\") pprint(sobo_strategy_data_model.surrogate_specs.surrogates[0].kernel.model_dump()) <p>The actual strategy can then be created via the mapper function.</p> In\u00a0[\u00a0]: Copied! <pre>sobo_strategy = strategies.map(sobo_strategy_data_model)\nsobo_strategy.tell(experiments=experiments)\nsobo_strategy.ask(candidate_count=1)\n</pre> sobo_strategy = strategies.map(sobo_strategy_data_model) sobo_strategy.tell(experiments=experiments) sobo_strategy.ask(candidate_count=1) <p>An alternative way is calling the strategy's constructor directly.</p> In\u00a0[\u00a0]: Copied! <pre>sobo_strategy = strategies.SoboStrategy(sobo_strategy_data_model)\n</pre> sobo_strategy = strategies.SoboStrategy(sobo_strategy_data_model) <p>The latter way is helpful to keep type information.</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\n\nfrom bofire.data_models.strategies.api import DoEStrategy\nfrom bofire.data_models.strategies.doe import DOptimalityCriterion\n\n\ndomain = Domain.from_lists(inputs=[x1, x2, x3], outputs=[y1], constraints=[constr1])\ndata_model = DoEStrategy(\n    domain=domain,\n    criterion=DOptimalityCriterion(formula=\"fully-quadratic\"),\n)\nstrategy = strategies.map(data_model=data_model)\ncandidates = strategy.ask(candidate_count=12)\nnp.round(candidates, 3)\n</pre> import numpy as np  from bofire.data_models.strategies.api import DoEStrategy from bofire.data_models.strategies.doe import DOptimalityCriterion   domain = Domain.from_lists(inputs=[x1, x2, x3], outputs=[y1], constraints=[constr1]) data_model = DoEStrategy(     domain=domain,     criterion=DOptimalityCriterion(formula=\"fully-quadratic\"), ) strategy = strategies.map(data_model=data_model) candidates = strategy.ask(candidate_count=12) np.round(candidates, 3) <p>The resulting design looks like this:</p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n\nfig = plt.figure(figsize=((10, 10)))\nax = fig.add_subplot(111, projection=\"3d\")\nax.view_init(45, 45)\nax.set_title(\"fully-quadratic model\")\nax.set_xlabel(\"$x_1$\")\nax.set_ylabel(\"$x_2$\")\nax.set_zlabel(\"$x_3$\")\nplt.rcParams[\"figure.figsize\"] = (10, 8)\n\n# plot feasible polytope\nax.plot(xs=[1, 0, 0, 1], ys=[0, 1, 0, 0], zs=[0, 0, 1, 0], linewidth=2)\n\n# plot D-optimal solutions\nax.scatter(\n    xs=candidates[x1.key],\n    ys=candidates[x2.key],\n    zs=candidates[x3.key],\n    marker=\"o\",\n    s=40,\n    color=\"orange\",\n)\n</pre> import matplotlib.pyplot as plt   fig = plt.figure(figsize=((10, 10))) ax = fig.add_subplot(111, projection=\"3d\") ax.view_init(45, 45) ax.set_title(\"fully-quadratic model\") ax.set_xlabel(\"$x_1$\") ax.set_ylabel(\"$x_2$\") ax.set_zlabel(\"$x_3$\") plt.rcParams[\"figure.figsize\"] = (10, 8)  # plot feasible polytope ax.plot(xs=[1, 0, 0, 1], ys=[0, 1, 0, 0], zs=[0, 0, 1, 0], linewidth=2)  # plot D-optimal solutions ax.scatter(     xs=candidates[x1.key],     ys=candidates[x2.key],     zs=candidates[x3.key],     marker=\"o\",     s=40,     color=\"orange\", )"},{"location":"getting_started/#basic-terminology","title":"Basic terminology\u00b6","text":"<p>In the following it is showed how to setup optimization problems in BoFire and how to use strategies to solve them.</p>"},{"location":"getting_started/#setting-up-the-optimization-problem","title":"Setting up the optimization problem\u00b6","text":"<p>In BoFire, an optimization problem is defined by defining a domain containing input and output features, as well as optionally including constraints.</p>"},{"location":"getting_started/#features","title":"Features\u00b6","text":"<p>Input features can be continuous, discrete, categorical.</p> <p>We also support a range of specialized inputs that make defining your experiments easier, such as:</p> <ul> <li><code>MolecularInput</code> allows transformations of molecules to featurizations (<code>Fingerprints</code>, <code>Fragments</code> and more).</li> <li><code>TaskInput</code> enables transfer learning and multi-fidelity methods, where you have access to similar experiments that can inform your optimization.</li> <li><code>*DescriptorInput</code> gives additional information about its value, combining the data with its significance.</li> </ul>"},{"location":"getting_started/#constraints","title":"Constraints\u00b6","text":"<p>The search space can be further defined by constraints on the input features. BoFire supports linear equality and inequality constraints, as well as non-linear equality and inequality constraints.</p>"},{"location":"getting_started/#linear-constraints","title":"Linear constraints\u00b6","text":"<p><code>LinearEqualityConstraint</code> and <code>LinearInequalityConstraint</code> are expressions of the form $\\sum_i a_i x_i = b$ or $\\leq b$ for equality and inequality constraints respectively. They take a list of names of the input features they are operating on, a list of left-hand-side coefficients $a_i$ and a right-hand-side constant $b$.</p>"},{"location":"getting_started/#nonlinear-constraints","title":"Nonlinear constraints\u00b6","text":""},{"location":"getting_started/#combinatorial-constraint","title":"Combinatorial constraint\u00b6","text":"<p>Use <code>NChooseKConstraint</code> to express that we only want to have $k$ out of the $n$ parameters to take positive values. Think of a mixture, where we have long list of possible ingredients, but want to limit number of ingredients in any given recipe.</p>"},{"location":"getting_started/#the-domain","title":"The domain\u00b6","text":"<p>The domain holds then all information about an optimization problem and can be understood as a search space definition.</p>"},{"location":"getting_started/#optimization","title":"Optimization\u00b6","text":"<p>To solve the optimization problem, we further need a solving strategy. BoFire supports strategies without a prediction model such as a random strategy and predictive strategies which are based on a prediction model.</p> <p>All strategies contain an <code>ask</code> method returning a defined number of candidate experiments.</p>"},{"location":"getting_started/#random-strategy","title":"Random Strategy\u00b6","text":""},{"location":"getting_started/#single-objective-bayesian-optimization-strategy","title":"Single objective Bayesian Optimization strategy\u00b6","text":"<p>Since a predictive strategy includes a prediction model, we need to generate some historical data, which we can afterwards pass as training data to the strategy via the tell method.</p> <p>For didactic purposes we just choose here from one of our benchmark methods.</p>"},{"location":"getting_started/#design-of-experiments","title":"Design of Experiments\u00b6","text":"<p>As a simple example for the DoE functionalities we consider the task of finding a D-optimal design for a fully-quadratic model with three design variables with bounds (0,1) and a mixture constraint.</p> <p>We define the design space including the constraint as a domain. Then we pass it to the optimization routine and specify the model. If the user does not indicate a number of experiments it will be chosen automatically based on the number of model terms.</p>"},{"location":"install/","title":"Installation Guide","text":""},{"location":"install/#installation-from-python-package-index-pypi","title":"Installation from Python Package Index (PyPI)","text":"<p>BoFire can be installed to your Python environment by using <code>pip</code>. It can be done by executing</p> <pre><code>pip install bofire\n</code></pre> <p>Tip</p> <p>The command from above will install a minimal BoFire version, consisting only of the data models. To install BoFire's including its core optimization features, execute: <pre><code>pip install 'bofire[optimization]'\n</code></pre></p>"},{"location":"install/#additional-optional-dependencies","title":"Additional optional dependencies","text":"<p>In BoFire, there are several optional dependencies that can be selected during installation via pip, like</p> <pre><code>pip install 'bofire[optimization, cheminfo] # will install bofire with additional dependencies `optimization` and `cheminfo`\n</code></pre> <p>To get the most our of BoFire, it is recommended to install at least <pre><code>pip install 'bofire[optimization]'\n</code></pre></p> <p>The available dependencies are:</p> <ul> <li><code>optimization</code>: Core Bayesian optimization features.</li> <li><code>cheminfo</code>: Cheminformatics utilities.</li> <li><code>entmoot</code>: Entmoot functionality.</li> <li><code>xgb</code>: XGboost surrogates.</li> <li><code>tests</code>: Required for running the test suite.</li> <li><code>docs</code>: Required for building the documentation.</li> <li><code>tutorials</code>: Required for running the tutorials.</li> <li><code>all</code>: Install all possible options (except DoE)</li> </ul> <p>Warning</p> <p>BoFire has the functionalities for creating D, E, A, G, K and I-optimal experimental designs via the <code>DoEStrategy</code>. This feature depends on cyipopt which is a python interface to <code>ipopt</code>. Unfortunately, it is not possible to install <code>cyipopt</code> including <code>ipopt</code> via pip. A solution is to install <code>cyipopt</code> and its dependencies via conda:</p> <pre><code>conda install -c conda-forge cyipopt\n</code></pre> <p>We are working on a solution that makes BoFire's model based DoE functionalities also accessible to users which do not have <code>cyipopt</code> available.</p>"},{"location":"install/#development-installation","title":"Development Installation","text":"<p>If you want to contribute to BoFire, it is recommended to install the repository in editable mode (<code>-e</code>).</p> <p>After cloning the repository via <pre><code>git clone https://github.com/experimental-design/bofire.git\n</code></pre> and navigating to the repositories root folder (<code>cd bofire</code>), you can proceed with <pre><code>pip install -e \".[optimization, tests]\" # include optional dependencies as you wish\n</code></pre></p>"},{"location":"multifidelity_bo/","title":"Multi-fidelity Bayesian Optimization","text":"In\u00a0[\u00a0]: Copied! <pre>import os\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport bofire.strategies.api as strategies\nfrom bofire.benchmarks.api import Ackley, Benchmark, Branin\nfrom bofire.data_models.acquisition_functions.api import qLogEI\nfrom bofire.data_models.domain.api import Domain\nfrom bofire.data_models.features.api import TaskInput\nfrom bofire.data_models.surrogates.api import BotorchSurrogates, MultiTaskGPSurrogate\n</pre> import os  import numpy as np import pandas as pd from tqdm import tqdm  import bofire.strategies.api as strategies from bofire.benchmarks.api import Ackley, Benchmark, Branin from bofire.data_models.acquisition_functions.api import qLogEI from bofire.data_models.domain.api import Domain from bofire.data_models.features.api import TaskInput from bofire.data_models.surrogates.api import BotorchSurrogates, MultiTaskGPSurrogate In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\n</pre> import matplotlib.pyplot as plt from matplotlib.axes import Axes In\u00a0[\u00a0]: Copied! <pre>SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")\nNUM_INIT_HF = 4\nNUM_INIT_LF = 10\nif SMOKE_TEST:\n    num_runs = 5\n    num_iters = 2\n    verbose = False\nelse:\n    num_runs = 10\n    num_iters = 10\n    verbose = True\n</pre> SMOKE_TEST = os.environ.get(\"SMOKE_TEST\") NUM_INIT_HF = 4 NUM_INIT_LF = 10 if SMOKE_TEST:     num_runs = 5     num_iters = 2     verbose = False else:     num_runs = 10     num_iters = 10     verbose = True <p>This notebook is a sequel to \"Transfer Learning in BO\".</p> In\u00a0[\u00a0]: Copied! <pre>class BraninMultiTask(Benchmark):\n    def __init__(self, low_fidelity_allowed=False, **kwargs):\n        super().__init__(**kwargs)\n        self._branin = Branin()\n        self._ackley = Ackley()\n        task_input = TaskInput(\n            key=\"task\",\n            categories=[\"task_hf\", \"task_lf\"],\n            allowed=[True, low_fidelity_allowed],\n            fidelities=[0, 1],\n        )\n        self._domain = Domain(\n            inputs=self._branin.domain.inputs + (task_input,),\n            outputs=self._branin.domain.outputs,\n        )\n\n    def _f(self, candidates: pd.DataFrame) -&gt; pd.DataFrame:\n        candidates_no_task = candidates.drop(columns=[\"task\"])\n        f_branin = self._branin.f(candidates_no_task)\n        f_ackley = self._ackley.f(candidates_no_task)\n        bias_scale = np.where(candidates[\"task\"] == \"task_hf\", 0.0, 0.15).reshape(-1, 1)\n        bias_scale = pd.DataFrame(bias_scale, columns=self._domain.outputs.get_keys())\n        bias_scale[\"valid_y\"] = 0.0\n        return f_branin + bias_scale * f_ackley\n\n    def get_optima(self) -&gt; pd.DataFrame:\n        optima = self._branin.get_optima()\n        optima[\"task\"] = \"task_hf\"\n        return optima\n\n\nmf_benchmark = BraninMultiTask(low_fidelity_allowed=True)\ntl_benchmark = BraninMultiTask(low_fidelity_allowed=False)\n</pre> class BraninMultiTask(Benchmark):     def __init__(self, low_fidelity_allowed=False, **kwargs):         super().__init__(**kwargs)         self._branin = Branin()         self._ackley = Ackley()         task_input = TaskInput(             key=\"task\",             categories=[\"task_hf\", \"task_lf\"],             allowed=[True, low_fidelity_allowed],             fidelities=[0, 1],         )         self._domain = Domain(             inputs=self._branin.domain.inputs + (task_input,),             outputs=self._branin.domain.outputs,         )      def _f(self, candidates: pd.DataFrame) -&gt; pd.DataFrame:         candidates_no_task = candidates.drop(columns=[\"task\"])         f_branin = self._branin.f(candidates_no_task)         f_ackley = self._ackley.f(candidates_no_task)         bias_scale = np.where(candidates[\"task\"] == \"task_hf\", 0.0, 0.15).reshape(-1, 1)         bias_scale = pd.DataFrame(bias_scale, columns=self._domain.outputs.get_keys())         bias_scale[\"valid_y\"] = 0.0         return f_branin + bias_scale * f_ackley      def get_optima(self) -&gt; pd.DataFrame:         optima = self._branin.get_optima()         optima[\"task\"] = \"task_hf\"         return optima   mf_benchmark = BraninMultiTask(low_fidelity_allowed=True) tl_benchmark = BraninMultiTask(low_fidelity_allowed=False) In\u00a0[\u00a0]: Copied! <pre>def create_data_set(seed: int):\n    # use the tl_benchmark to sample without the low fidelity\n    experiments = tl_benchmark.domain.inputs.sample(\n        NUM_INIT_HF + NUM_INIT_LF, seed=seed\n    )\n    experiments[\"task\"] = np.where(\n        experiments.index &lt; NUM_INIT_LF, \"task_lf\", \"task_hf\"\n    )\n\n    # then use the ml_benchmark to evaluate the low fidelity\n    return mf_benchmark.f(experiments, return_complete=True)\n\n\ncreate_data_set(0)\n</pre> def create_data_set(seed: int):     # use the tl_benchmark to sample without the low fidelity     experiments = tl_benchmark.domain.inputs.sample(         NUM_INIT_HF + NUM_INIT_LF, seed=seed     )     experiments[\"task\"] = np.where(         experiments.index &lt; NUM_INIT_LF, \"task_lf\", \"task_hf\"     )      # then use the ml_benchmark to evaluate the low fidelity     return mf_benchmark.f(experiments, return_complete=True)   create_data_set(0) In\u00a0[\u00a0]: Copied! <pre>from bofire.data_models.strategies.api import MultiFidelityStrategy\n\n\n# It isn't necessary to define the surrogate specs here, as the MFStrategy\n# will use a MultiTaskGP by default.\n\nmf_data_model = MultiFidelityStrategy(\n    domain=mf_benchmark.domain,\n    acquisition_function=qLogEI(),\n    fidelity_thresholds=0.1,\n)\nmf_data_model.surrogate_specs.surrogates[0].inputs\n</pre> from bofire.data_models.strategies.api import MultiFidelityStrategy   # It isn't necessary to define the surrogate specs here, as the MFStrategy # will use a MultiTaskGP by default.  mf_data_model = MultiFidelityStrategy(     domain=mf_benchmark.domain,     acquisition_function=qLogEI(),     fidelity_thresholds=0.1, ) mf_data_model.surrogate_specs.surrogates[0].inputs In\u00a0[\u00a0]: Copied! <pre>from bofire.data_models.strategies.api import SoboStrategy\n\n\nsurrogate_specs = BotorchSurrogates(\n    surrogates=[\n        MultiTaskGPSurrogate(\n            inputs=tl_benchmark.domain.inputs,\n            outputs=tl_benchmark.domain.outputs,\n        )\n    ]\n)\n\ntl_data_model = SoboStrategy(\n    domain=tl_benchmark.domain,\n    acquisition_function=qLogEI(),\n    surrogate_specs=surrogate_specs,\n)\n</pre> from bofire.data_models.strategies.api import SoboStrategy   surrogate_specs = BotorchSurrogates(     surrogates=[         MultiTaskGPSurrogate(             inputs=tl_benchmark.domain.inputs,             outputs=tl_benchmark.domain.outputs,         )     ] )  tl_data_model = SoboStrategy(     domain=tl_benchmark.domain,     acquisition_function=qLogEI(),     surrogate_specs=surrogate_specs, ) <p>We first optimize only on the target fidelity (the \"Transfer Learning\" baseline). This uses the <code>SoboStrategy</code> defined above.</p> In\u00a0[\u00a0]: Copied! <pre>tl_results = pd.DataFrame(columns=pd.MultiIndex.from_tuples([], names=(\"col\", \"run\")))\nfor run in range(num_runs):\n    seed = 2048 * run + 123\n    experiments = create_data_set(seed)\n\n    tl_strategy = strategies.map(tl_data_model)\n    tl_strategy.tell(experiments)\n\n    assert tl_strategy.experiments is not None\n\n    pbar = tqdm(range(num_iters), desc=\"Optimizing\")\n    for _ in pbar:\n        candidate = tl_strategy.ask(1)\n        y = tl_benchmark.f(candidate, return_complete=True)\n        tl_strategy.tell(y)\n\n        hf_experiments = tl_strategy.experiments[\n            tl_strategy.experiments[\"task\"] == \"task_hf\"\n        ]\n        regret = hf_experiments[\"y\"].min() - tl_benchmark.get_optima()[\"y\"][0].item()\n\n        pbar.set_postfix({\"Regret\": f\"{regret:.4f}\"})\n\n    tl_results[\"fidelity\", f\"{run}\"] = tl_strategy.experiments[\"task\"]\n    tl_results[\"y\", f\"{run}\"] = tl_strategy.experiments[\"y\"]\n</pre> tl_results = pd.DataFrame(columns=pd.MultiIndex.from_tuples([], names=(\"col\", \"run\"))) for run in range(num_runs):     seed = 2048 * run + 123     experiments = create_data_set(seed)      tl_strategy = strategies.map(tl_data_model)     tl_strategy.tell(experiments)      assert tl_strategy.experiments is not None      pbar = tqdm(range(num_iters), desc=\"Optimizing\")     for _ in pbar:         candidate = tl_strategy.ask(1)         y = tl_benchmark.f(candidate, return_complete=True)         tl_strategy.tell(y)          hf_experiments = tl_strategy.experiments[             tl_strategy.experiments[\"task\"] == \"task_hf\"         ]         regret = hf_experiments[\"y\"].min() - tl_benchmark.get_optima()[\"y\"][0].item()          pbar.set_postfix({\"Regret\": f\"{regret:.4f}\"})      tl_results[\"fidelity\", f\"{run}\"] = tl_strategy.experiments[\"task\"]     tl_results[\"y\", f\"{run}\"] = tl_strategy.experiments[\"y\"] <p>We now repeat the experiment using multi-fidelity BO, allowing the strategy to query the low fidelity function as well as the high fidelity function:</p> In\u00a0[\u00a0]: Copied! <pre>mf_results = pd.DataFrame(columns=pd.MultiIndex.from_tuples([], names=(\"col\", \"run\")))\nfor run in range(num_runs):\n    seed = 2048 * run + 123\n    experiments = create_data_set(seed)\n\n    mf_strategy = strategies.map(mf_data_model)\n    mf_strategy.tell(experiments)\n\n    assert mf_strategy.experiments is not None\n\n    pbar = tqdm(range(num_iters), desc=\"Optimizing\")\n    for _ in pbar:\n        candidate = mf_strategy.ask(1)\n        y = mf_benchmark.f(candidate, return_complete=True)\n        mf_strategy.tell(y)\n\n        hf_experiments = mf_strategy.experiments[\n            mf_strategy.experiments[\"task\"] == \"task_hf\"\n        ]\n        regret = hf_experiments[\"y\"].min() - mf_benchmark.get_optima()[\"y\"][0].item()\n\n        pbar.set_postfix({\"Regret\": f\"{regret:.4f}\"})\n\n    mf_results[\"fidelity\", f\"{run}\"] = mf_strategy.experiments[\"task\"]\n    mf_results[\"y\", f\"{run}\"] = mf_strategy.experiments[\"y\"]\n</pre> mf_results = pd.DataFrame(columns=pd.MultiIndex.from_tuples([], names=(\"col\", \"run\"))) for run in range(num_runs):     seed = 2048 * run + 123     experiments = create_data_set(seed)      mf_strategy = strategies.map(mf_data_model)     mf_strategy.tell(experiments)      assert mf_strategy.experiments is not None      pbar = tqdm(range(num_iters), desc=\"Optimizing\")     for _ in pbar:         candidate = mf_strategy.ask(1)         y = mf_benchmark.f(candidate, return_complete=True)         mf_strategy.tell(y)          hf_experiments = mf_strategy.experiments[             mf_strategy.experiments[\"task\"] == \"task_hf\"         ]         regret = hf_experiments[\"y\"].min() - mf_benchmark.get_optima()[\"y\"][0].item()          pbar.set_postfix({\"Regret\": f\"{regret:.4f}\"})      mf_results[\"fidelity\", f\"{run}\"] = mf_strategy.experiments[\"task\"]     mf_results[\"y\", f\"{run}\"] = mf_strategy.experiments[\"y\"] <p>When evaluating the performance, we need to consider how cheap the low-fidelity (LF) is to query. When the LF has the same cost as the target fidelity, then we gain very little from the multi-fidelity approach. However, if the LF is cheaper than the target (in the example below, 3x cheaper) then we observe an improvement in BO performance.</p> <p>Specifically, although both strategies have a budget of 10 function queries, the MF approach uses some of them on</p> In\u00a0[\u00a0]: Copied! <pre>def plot_regret(\n    ax: Axes, bo_results: pd.DataFrame, fidelity_cost_ratio: float, **plot_kwargs\n):\n    cummin = (\n        bo_results[\"y\"]\n        .where(bo_results[\"fidelity\"] == \"task_hf\", other=np.inf)\n        .cummin(axis=0)\n    )\n    # only select iterations, and the final training point\n    cummin = cummin.iloc[-num_iters - 1 :]\n    regret: np.ndarray = (cummin - mf_benchmark.get_optima()[\"y\"][0].item()).to_numpy()\n\n    # keep track of \"real time\", where low fidelities are cheaper to evaluate.\n    time_taken = np.where(bo_results[\"fidelity\"] == \"task_hf\", fidelity_cost_ratio, 1)[\n        -num_iters - 1 :\n    ].cumsum(axis=0)\n    time_taken -= time_taken[0, 0]  # start from T=0 after training data\n    iterations = np.arange(num_iters * fidelity_cost_ratio)\n    before_time = time_taken[:, :, np.newaxis] &lt;= iterations[np.newaxis, np.newaxis, :]\n    regret_before_time = regret[:, :, np.newaxis] * np.where(before_time, 1.0, np.inf)\n    # regret_before_time.shape == (num_iters+1, num_runs, len(iterations))\n    # project into time dimension\n    regret = regret_before_time.min(axis=0)\n\n    ax.plot(\n        iterations,\n        np.median(regret, axis=0),\n        label=plot_kwargs.get(\"label\"),\n        color=plot_kwargs.get(\"color\"),\n    )\n    ax.fill_between(\n        iterations,\n        np.quantile(regret, 0.75, axis=0),\n        np.quantile(regret, 0.25, axis=0),\n        color=plot_kwargs.get(\"color\"),\n        alpha=0.2,\n    )\n\n\nfig, axs = plt.subplots(ncols=2, figsize=(8, 4), sharey=True)\ncost_ratios = (1, 3)\n\nfor ax, cost_ratio in zip(axs, cost_ratios):\n    plot_regret(\n        ax,\n        tl_results,\n        fidelity_cost_ratio=cost_ratio,\n        label=\"Transfer Learning\",\n        color=\"blue\",\n    )\n    plot_regret(\n        ax,\n        mf_results,\n        fidelity_cost_ratio=cost_ratio,\n        label=\"Multi-fidelity\",\n        color=\"green\",\n    )\n    ax.set_xlabel(\"Time step\")\n    ax.set_title(f\"Fidelity cost ratio = {cost_ratio}\")\n\n\naxs[1].legend()\naxs[0].set_ylabel(\"Regret\")\n\nplt.show()\n</pre> def plot_regret(     ax: Axes, bo_results: pd.DataFrame, fidelity_cost_ratio: float, **plot_kwargs ):     cummin = (         bo_results[\"y\"]         .where(bo_results[\"fidelity\"] == \"task_hf\", other=np.inf)         .cummin(axis=0)     )     # only select iterations, and the final training point     cummin = cummin.iloc[-num_iters - 1 :]     regret: np.ndarray = (cummin - mf_benchmark.get_optima()[\"y\"][0].item()).to_numpy()      # keep track of \"real time\", where low fidelities are cheaper to evaluate.     time_taken = np.where(bo_results[\"fidelity\"] == \"task_hf\", fidelity_cost_ratio, 1)[         -num_iters - 1 :     ].cumsum(axis=0)     time_taken -= time_taken[0, 0]  # start from T=0 after training data     iterations = np.arange(num_iters * fidelity_cost_ratio)     before_time = time_taken[:, :, np.newaxis] &lt;= iterations[np.newaxis, np.newaxis, :]     regret_before_time = regret[:, :, np.newaxis] * np.where(before_time, 1.0, np.inf)     # regret_before_time.shape == (num_iters+1, num_runs, len(iterations))     # project into time dimension     regret = regret_before_time.min(axis=0)      ax.plot(         iterations,         np.median(regret, axis=0),         label=plot_kwargs.get(\"label\"),         color=plot_kwargs.get(\"color\"),     )     ax.fill_between(         iterations,         np.quantile(regret, 0.75, axis=0),         np.quantile(regret, 0.25, axis=0),         color=plot_kwargs.get(\"color\"),         alpha=0.2,     )   fig, axs = plt.subplots(ncols=2, figsize=(8, 4), sharey=True) cost_ratios = (1, 3)  for ax, cost_ratio in zip(axs, cost_ratios):     plot_regret(         ax,         tl_results,         fidelity_cost_ratio=cost_ratio,         label=\"Transfer Learning\",         color=\"blue\",     )     plot_regret(         ax,         mf_results,         fidelity_cost_ratio=cost_ratio,         label=\"Multi-fidelity\",         color=\"green\",     )     ax.set_xlabel(\"Time step\")     ax.set_title(f\"Fidelity cost ratio = {cost_ratio}\")   axs[1].legend() axs[0].set_ylabel(\"Regret\")  plt.show() <p>We can see that allowing the lower fidelities to be queries leads to stronger optimization performance. We can also see below that the MF approach only samples the target fidelity in later iterations, once the variance of the LF has been sufficiently reduced.</p> In\u00a0[\u00a0]: Copied! <pre>(mf_results[\"fidelity\"] == \"task_hf\")[-num_iters:].mean(axis=1)  # type: ignore\n</pre> (mf_results[\"fidelity\"] == \"task_hf\")[-num_iters:].mean(axis=1)  # type: ignore"},{"location":"multifidelity_bo/#multi-fidelity-bayesian-optimization","title":"Multi-fidelity Bayesian Optimization\u00b6","text":"<p>In the previous notebook, we saw how using low-fidelity approximations to our target function can improve the predictions from our surrogate model, leading to a faster optimization procedure. In this notebook, we show how we can gain even further performance gains by querying the cheap low-fidelity approximations during the BO loop.</p>"},{"location":"multifidelity_bo/#problem-definition","title":"Problem definition\u00b6","text":"<p>We use the same problem as the transfer learning notebook; optimizing the Branin benchmark, with a low-fidelity function biased by the Ackley function (with fewer initial points, to demonstrate the strength of being able to query low fidelities). Below, we define the problem domain, and the strategies we will use to optimize.</p> <p>As a baseline, we use the <code>SoboStrategy</code> with the <code>MultiTaskSurrogate</code>, as in the previous notebook. We also introduce the <code>MultiFidelityStrategy</code> here, which uses the same surrogate, but is able to query the lower fidelity functions using a variance-based acquisition function [Kandasamy et al. 2016, Folch et al. 2023].</p> <p>Both strategies first select a design point $x$ by optimizing the target fidelity. The <code>MultiFidelityStrategy</code> then selects the fidelity, $m$, by selecting the lowest fidelity that has a variance over a fixed threshold. This means that the strategy will explore the cheapest fidelities first, and only query the expensive fidelities when there is no information to be gained by the cheap approximations.</p>"},{"location":"multifidelity_bo/#multi-fidelity-bayesian-optimisation","title":"Multi-fidelity Bayesian Optimisation\u00b6","text":""},{"location":"nchoosek_constraint/","title":"Nchoosek constraint","text":"In\u00a0[\u00a0]: Copied! <pre>import numpy as np\n\nimport bofire.strategies.api as strategies\nfrom bofire.data_models.constraints.api import (\n    LinearEqualityConstraint,\n    LinearInequalityConstraint,\n    NChooseKConstraint,\n)\nfrom bofire.data_models.domain.api import Domain\nfrom bofire.data_models.features.api import ContinuousInput, ContinuousOutput\nfrom bofire.data_models.strategies.api import DoEStrategy\nfrom bofire.data_models.strategies.doe import DOptimalityCriterion\n\n\ndomain = Domain(\n    inputs=[ContinuousInput(key=f\"x{i+1}\", bounds=(0, 1)) for i in range(8)],\n    outputs=[ContinuousOutput(key=\"y\")],\n    constraints=[\n        LinearEqualityConstraint(\n            features=[f\"x{i+1}\" for i in range(8)],\n            coefficients=[1, 1, 1, 1, 1, 1, 1, 1],\n            rhs=1,\n        ),\n        NChooseKConstraint(\n            features=[\"x1\", \"x2\", \"x3\"],\n            min_count=0,\n            max_count=1,\n            none_also_valid=True,\n        ),\n        LinearInequalityConstraint(\n            features=[\"x1\", \"x2\", \"x3\"],\n            coefficients=[1, 1, 1],\n            rhs=0.7,\n        ),\n        LinearInequalityConstraint(\n            features=[\"x7\", \"x8\"],\n            coefficients=[-1, -1],\n            rhs=-0.1,\n        ),\n        LinearInequalityConstraint(features=[\"x7\", \"x8\"], coefficients=[1, 1], rhs=0.9),\n    ],\n)\n\ndata_model = DoEStrategy(\n    domain=domain,\n    criterion=DOptimalityCriterion(formula=\"fully-quadratic\"),\n    ipopt_options={\"max_iter\": 500},\n)\nstrategy = strategies.map(data_model=data_model)\ncandidates = strategy.ask(candidate_count=12)\nnp.round(candidates, 3)\n</pre> import numpy as np  import bofire.strategies.api as strategies from bofire.data_models.constraints.api import (     LinearEqualityConstraint,     LinearInequalityConstraint,     NChooseKConstraint, ) from bofire.data_models.domain.api import Domain from bofire.data_models.features.api import ContinuousInput, ContinuousOutput from bofire.data_models.strategies.api import DoEStrategy from bofire.data_models.strategies.doe import DOptimalityCriterion   domain = Domain(     inputs=[ContinuousInput(key=f\"x{i+1}\", bounds=(0, 1)) for i in range(8)],     outputs=[ContinuousOutput(key=\"y\")],     constraints=[         LinearEqualityConstraint(             features=[f\"x{i+1}\" for i in range(8)],             coefficients=[1, 1, 1, 1, 1, 1, 1, 1],             rhs=1,         ),         NChooseKConstraint(             features=[\"x1\", \"x2\", \"x3\"],             min_count=0,             max_count=1,             none_also_valid=True,         ),         LinearInequalityConstraint(             features=[\"x1\", \"x2\", \"x3\"],             coefficients=[1, 1, 1],             rhs=0.7,         ),         LinearInequalityConstraint(             features=[\"x7\", \"x8\"],             coefficients=[-1, -1],             rhs=-0.1,         ),         LinearInequalityConstraint(features=[\"x7\", \"x8\"], coefficients=[1, 1], rhs=0.9),     ], )  data_model = DoEStrategy(     domain=domain,     criterion=DOptimalityCriterion(formula=\"fully-quadratic\"),     ipopt_options={\"max_iter\": 500}, ) strategy = strategies.map(data_model=data_model) candidates = strategy.ask(candidate_count=12) np.round(candidates, 3) <pre>/home/linznedd/miniforge3/envs/bofire/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> <pre>\n******************************************************************************\nThis program contains Ipopt, a library for large-scale nonlinear optimization.\n Ipopt is released as open source code under the Eclipse Public License (EPL).\n         For more information visit https://github.com/coin-or/Ipopt\n******************************************************************************\n\n</pre> Out[\u00a0]: x1 x2 x3 x4 x5 x6 x7 x8 0 -0.0 -0.0 -0.0 0.9 -0.0 -0.0 -0.0 0.1 1 -0.0 -0.0 -0.0 0.1 -0.0 -0.0 -0.0 0.9 2 -0.0 0.7 -0.0 -0.0 -0.0 -0.0 0.3 -0.0 3 -0.0 -0.0 -0.0 -0.0 -0.0 0.1 -0.0 0.9 4 -0.0 -0.0 -0.0 -0.0 -0.0 0.9 0.1 -0.0 5 -0.0 -0.0 0.7 -0.0 -0.0 -0.0 -0.0 0.3 6 -0.0 -0.0 -0.0 0.9 -0.0 -0.0 0.1 -0.0 7 -0.0 -0.0 -0.0 -0.0 -0.0 0.9 -0.0 0.1 8 0.7 -0.0 -0.0 -0.0 -0.0 -0.0 0.3 -0.0 9 -0.0 -0.0 -0.0 -0.0 0.1 -0.0 0.9 -0.0 10 -0.0 -0.0 -0.0 -0.0 0.9 -0.0 -0.0 0.1 11 -0.0 -0.0 -0.0 -0.0 -0.0 0.9 -0.0 0.1"},{"location":"nchoosek_constraint/#design-with-nchoosek-constraint","title":"Design with NChooseK constraint\u00b6","text":"<p>The doe subpackage also supports problems with NChooseK constraints. Since IPOPT has problems finding feasible solutions using the gradient of the NChooseK constraint violation, a closely related (but stricter) constraint that suffices to fulfill the NChooseK constraint is imposed onto the problem: For each experiment $j$ N-K decision variables $x_{i_1,j},...,x_{i_{N-K,j}}$ from the NChooseK constraints' names attribute are picked that are forced to be zero. This is done by setting the upper and lower bounds of the picked variables are set to 0 in the corresponding experiments. This causes IPOPT to treat them as \"fixed variables\" (i.e. it will not optimize for them) and will always stick to the only feasible value (which is 0 here). However, this constraint is stricter than the original NChooseK constraint. In combination with other constraints on the same decision variables this can result in a situation where the constraints cannot be fulfilled even though the original constraints would allow for a solution. For example consider a problem with four decision variables $x_1, x_2, x_3, x_4$, an NChooseK constraint on the first four variable that restricts the number of nonzero variables to two. Additionally, we have a linear constraint $$ x_3 + x_4 \\geq 0.1 $$ We can easily find points that fulfill both constraints (e.g. $(0,0,0,0.1)$). Now consider the stricter, linear constraint from above. Eventually, it will happen that $x_3$ and $x_4$ are chosen to be zero for one experiment. For this experiment it is impossible to fulfill the linear constraint $x_3 + x_4 \\geq 0.1$ since $x_3 = x_4 = 0$.</p> <p>Therefore one has to be very careful when imposing linear constraints upon decision variables that already show up in an NChooseK constraint.</p> <p>For practical reasons it necessary that two NChooseK constraints of the same problem must not share any variables.</p> <p>You can find an example for a problem with NChooseK constraints and additional linear constraints imposed on the same variables.</p>"},{"location":"optimality_criteria/","title":"Optimality criteria","text":"In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\nimport bofire.strategies.api as strategies\nfrom bofire.data_models.constraints.api import LinearEqualityConstraint\nfrom bofire.data_models.domain.api import Domain\nfrom bofire.data_models.features.api import ContinuousInput, ContinuousOutput\nfrom bofire.data_models.strategies.api import DoEStrategy\nfrom bofire.data_models.strategies.doe import (\n    AOptimalityCriterion,\n    DOptimalityCriterion,\n    EOptimalityCriterion,\n    IOptimalityCriterion,\n    KOptimalityCriterion,\n    SpaceFillingCriterion,\n)\nfrom bofire.strategies.doe.objective import get_objective_function\n</pre> import matplotlib.pyplot as plt  import bofire.strategies.api as strategies from bofire.data_models.constraints.api import LinearEqualityConstraint from bofire.data_models.domain.api import Domain from bofire.data_models.features.api import ContinuousInput, ContinuousOutput from bofire.data_models.strategies.api import DoEStrategy from bofire.data_models.strategies.doe import (     AOptimalityCriterion,     DOptimalityCriterion,     EOptimalityCriterion,     IOptimalityCriterion,     KOptimalityCriterion,     SpaceFillingCriterion, ) from bofire.strategies.doe.objective import get_objective_function <pre>/home/linznedd/miniforge3/envs/bofire/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> In\u00a0[\u00a0]: Copied! <pre># Optimal designs for a quadratic model on the unit square\ndomain = Domain(\n    inputs=[ContinuousInput(key=f\"x{i+1}\", bounds=(0, 1)) for i in range(2)],\n    outputs=[ContinuousOutput(key=\"y\")],\n)\nmodel_type = \"fully-quadratic\"\nn_experiments = 13\n\ndesigns = {}\nfor crit in [\n    DOptimalityCriterion,\n    AOptimalityCriterion,\n    KOptimalityCriterion,\n    EOptimalityCriterion,\n    IOptimalityCriterion,\n]:\n    criterion = crit(formula=model_type)\n    data_model = DoEStrategy(\n        domain=domain,\n        criterion=criterion,\n        ipopt_options={\"max_iter\": 300},\n    )\n    strategy = strategies.map(data_model=data_model)\n    design = strategy.ask(candidate_count=n_experiments)\n    obj_value = get_objective_function(\n        criterion=criterion, domain=domain, n_experiments=n_experiments\n    ).evaluate(design.to_numpy().flatten())\n    designs[obj_value] = design.to_numpy()\n\nfig = plt.figure(figsize=((8, 8)))\nax = fig.add_subplot(111)\nax.set_title(\"Designs with different optimality criteria\")\nax.set_xlabel(\"$x_1$\")\nax.set_ylabel(\"$x_2$\")\nfor obj, X in designs.items():\n    ax.scatter(X[:, 0], X[:, 1], s=40, label=obj)\nax.grid(alpha=0.3)\nax.legend();\n</pre> # Optimal designs for a quadratic model on the unit square domain = Domain(     inputs=[ContinuousInput(key=f\"x{i+1}\", bounds=(0, 1)) for i in range(2)],     outputs=[ContinuousOutput(key=\"y\")], ) model_type = \"fully-quadratic\" n_experiments = 13  designs = {} for crit in [     DOptimalityCriterion,     AOptimalityCriterion,     KOptimalityCriterion,     EOptimalityCriterion,     IOptimalityCriterion, ]:     criterion = crit(formula=model_type)     data_model = DoEStrategy(         domain=domain,         criterion=criterion,         ipopt_options={\"max_iter\": 300},     )     strategy = strategies.map(data_model=data_model)     design = strategy.ask(candidate_count=n_experiments)     obj_value = get_objective_function(         criterion=criterion, domain=domain, n_experiments=n_experiments     ).evaluate(design.to_numpy().flatten())     designs[obj_value] = design.to_numpy()  fig = plt.figure(figsize=((8, 8))) ax = fig.add_subplot(111) ax.set_title(\"Designs with different optimality criteria\") ax.set_xlabel(\"$x_1$\") ax.set_ylabel(\"$x_2$\") for obj, X in designs.items():     ax.scatter(X[:, 0], X[:, 1], s=40, label=obj) ax.grid(alpha=0.3) ax.legend(); <pre>\n******************************************************************************\nThis program contains Ipopt, a library for large-scale nonlinear optimization.\n Ipopt is released as open source code under the Eclipse Public License (EPL).\n         For more information visit https://github.com/coin-or/Ipopt\n******************************************************************************\n\n</pre> In\u00a0[\u00a0]: Copied! <pre># Space filling design on the unit 2-simplex\ndomain = Domain(\n    inputs=[ContinuousInput(key=f\"x{i+1}\", bounds=(0, 1)) for i in range(3)],\n    outputs=[ContinuousOutput(key=\"y\")],\n    constraints=[\n        LinearEqualityConstraint(\n            features=[\"x1\", \"x2\", \"x3\"],\n            coefficients=[1, 1, 1],\n            rhs=1,\n        ),\n    ],\n)\ndata_model = DoEStrategy(\n    domain=domain, criterion=SpaceFillingCriterion(), ipopt_options={\"max_iter\": 500}\n)\nstrategy = strategies.map(data_model=data_model)\nX = strategy.ask(candidate_count=40).to_numpy()\n\nfig = plt.figure(figsize=((10, 8)))\nax = fig.add_subplot(111, projection=\"3d\")\nax.view_init(45, 20)\nax.set_title(\"Space filling design\")\nax.set_xlabel(\"$x_1$\")\nax.set_ylabel(\"$x_2$\")\nax.set_zlabel(\"$x_3$\")\n\n# plot feasible polytope\nax.plot(xs=[0, 0, 1, 0], ys=[0, 1, 0, 0], zs=[1, 0, 0, 1], linewidth=2)\n\n# plot design points\nax.scatter(xs=X[:, 0], ys=X[:, 1], zs=X[:, 2], s=40)\n</pre> # Space filling design on the unit 2-simplex domain = Domain(     inputs=[ContinuousInput(key=f\"x{i+1}\", bounds=(0, 1)) for i in range(3)],     outputs=[ContinuousOutput(key=\"y\")],     constraints=[         LinearEqualityConstraint(             features=[\"x1\", \"x2\", \"x3\"],             coefficients=[1, 1, 1],             rhs=1,         ),     ], ) data_model = DoEStrategy(     domain=domain, criterion=SpaceFillingCriterion(), ipopt_options={\"max_iter\": 500} ) strategy = strategies.map(data_model=data_model) X = strategy.ask(candidate_count=40).to_numpy()  fig = plt.figure(figsize=((10, 8))) ax = fig.add_subplot(111, projection=\"3d\") ax.view_init(45, 20) ax.set_title(\"Space filling design\") ax.set_xlabel(\"$x_1$\") ax.set_ylabel(\"$x_2$\") ax.set_zlabel(\"$x_3$\")  # plot feasible polytope ax.plot(xs=[0, 0, 1, 0], ys=[0, 1, 0, 0], zs=[1, 0, 0, 1], linewidth=2)  # plot design points ax.scatter(xs=X[:, 0], ys=X[:, 1], zs=X[:, 2], s=40) Out[\u00a0]: <pre>&lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7cf598509510&gt;</pre>"},{"location":"optimality_criteria/#designs-for-different-optimality-criteria","title":"Designs for different optimality criteria\u00b6","text":""},{"location":"optimality_criteria/#space-filling-design","title":"Space filling design\u00b6","text":""},{"location":"reaction_optimization/","title":"Getting started by Example: Optimization of Reaction Conditions","text":"In\u00a0[\u00a0]: Copied! <pre># python imports we'll need in this notebook\nimport os\nimport time\n\nimport numpy as np\nimport pandas as pd\n\n\nSMOKE_TEST = os.environ.get(\"SMOKE_TEST\")\nprint(f\"SMOKE_TEST: {SMOKE_TEST}\")\n</pre> # python imports we'll need in this notebook import os import time  import numpy as np import pandas as pd   SMOKE_TEST = os.environ.get(\"SMOKE_TEST\") print(f\"SMOKE_TEST: {SMOKE_TEST}\") In\u00a0[\u00a0]: Copied! <pre>from bofire.data_models.domain.api import Domain, Inputs, Outputs\nfrom bofire.data_models.features.api import (  # we won't need all of those.\n    CategoricalInput,\n    ContinuousInput,\n    ContinuousOutput,\n)\n</pre> from bofire.data_models.domain.api import Domain, Inputs, Outputs from bofire.data_models.features.api import (  # we won't need all of those.     CategoricalInput,     ContinuousInput,     ContinuousOutput, ) In\u00a0[\u00a0]: Copied! <pre># We wish the temperature of the reaction to be between 0 and 60 \u00b0C\ntemperature_feature = ContinuousInput(key=\"Temperature\", bounds=[0.0, 60.0], unit=\"\u00b0C\")\n\n# Solvent Amount\nsolvent_amount_feature = ContinuousInput(key=\"Solvent Volume\", bounds=[20, 90])\n\n# we have a couple of solvents in stock, which we'd like to use\nsolvent_type_feature = CategoricalInput(\n    key=\"Solvent Type\",\n    categories=[\"MeOH\", \"THF\", \"Dioxane\"],\n)\n\n\n# gather all individual features\ninput_features = Inputs(\n    features=[\n        temperature_feature,\n        solvent_type_feature,\n        solvent_amount_feature,\n    ],\n)\n</pre> # We wish the temperature of the reaction to be between 0 and 60 \u00b0C temperature_feature = ContinuousInput(key=\"Temperature\", bounds=[0.0, 60.0], unit=\"\u00b0C\")  # Solvent Amount solvent_amount_feature = ContinuousInput(key=\"Solvent Volume\", bounds=[20, 90])  # we have a couple of solvents in stock, which we'd like to use solvent_type_feature = CategoricalInput(     key=\"Solvent Type\",     categories=[\"MeOH\", \"THF\", \"Dioxane\"], )   # gather all individual features input_features = Inputs(     features=[         temperature_feature,         solvent_type_feature,         solvent_amount_feature,     ], ) In\u00a0[\u00a0]: Copied! <pre># outputs: we wish to maximize the Yield\n# import Maximize Objective to tell the optimizer you wish to optimize\nfrom bofire.data_models.objectives.api import MaximizeObjective\n\n\nobjective = MaximizeObjective(\n    w=1.0,\n)\nyield_feature = ContinuousOutput(key=\"Yield\", objective=objective)\n# create an output feature\noutput_features = Outputs(features=[yield_feature])\n</pre> # outputs: we wish to maximize the Yield # import Maximize Objective to tell the optimizer you wish to optimize from bofire.data_models.objectives.api import MaximizeObjective   objective = MaximizeObjective(     w=1.0, ) yield_feature = ContinuousOutput(key=\"Yield\", objective=objective) # create an output feature output_features = Outputs(features=[yield_feature]) In\u00a0[\u00a0]: Copied! <pre>objective\n</pre> objective In\u00a0[\u00a0]: Copied! <pre># we now have\nprint(\"input_features:\", input_features)\nprint(\"output_features:\", output_features)\n</pre> # we now have print(\"input_features:\", input_features) print(\"output_features:\", output_features) In\u00a0[\u00a0]: Copied! <pre># The domain is now the object that holds the entire optimization problem / problem definition.\ndomain = Domain(\n    inputs=input_features,\n    outputs=output_features,\n)\n</pre> # The domain is now the object that holds the entire optimization problem / problem definition. domain = Domain(     inputs=input_features,     outputs=output_features, ) In\u00a0[\u00a0]: Copied! <pre># you can now have a pretty printout of your domain via\n(domain.inputs + domain.outputs).get_reps_df()\n</pre> # you can now have a pretty printout of your domain via (domain.inputs + domain.outputs).get_reps_df() In\u00a0[\u00a0]: Copied! <pre># and you can access your domain features via\nfor (\n    feature_key\n) in domain.inputs.get_keys():  # this will get all the feature names and loop over them\n    input_feature = domain.inputs.get_by_key(\n        feature_key,\n    )  # we can extract the individual feature object by asking for it by name\n    print(feature_key, \"|\", input_feature)\n</pre> # and you can access your domain features via for (     feature_key ) in domain.inputs.get_keys():  # this will get all the feature names and loop over them     input_feature = domain.inputs.get_by_key(         feature_key,     )  # we can extract the individual feature object by asking for it by name     print(feature_key, \"|\", input_feature) In\u00a0[\u00a0]: Copied! <pre># as well as the output features as\n# and you can access your domain features via\nfor feature_key in (\n    domain.outputs.get_keys()\n):  # this will get all the feature names and loop over them\n    output_feature = domain.outputs.get_by_key(\n        feature_key,\n    )  # we can extract the individual feature object by asking for it by name\n    print(feature_key, \" | \", output_feature.__repr__())\n</pre> # as well as the output features as # and you can access your domain features via for feature_key in (     domain.outputs.get_keys() ):  # this will get all the feature names and loop over them     output_feature = domain.outputs.get_by_key(         feature_key,     )  # we can extract the individual feature object by asking for it by name     print(feature_key, \" | \", output_feature.__repr__()) In\u00a0[\u00a0]: Copied! <pre>(domain.inputs + domain.outputs).get_reps_df()\n</pre> (domain.inputs + domain.outputs).get_reps_df() In\u00a0[\u00a0]: Copied! <pre># Reaction Optimization Notebook util code\nT0 = 25\nT1 = 100\ne0 = np.exp((T1 + 0) / T0)\ne60 = np.exp((T1 + 60) / T0)\nde = e60 - e0\n\nboiling_points = {  # in \u00b0C\n    \"MeOH\": 64.7,\n    \"THF\": 66.0,\n    \"Dioxane\": 101.0,\n}\ndensity = {  # in kg/l\n    \"MeOH\": 0.792,\n    \"THF\": 0.886,\n    \"Dioxane\": 1.03,\n}\n# create dict from individual dicts\ndescs = {\n    \"boiling_points\": boiling_points,\n    \"density\": density,\n}\nsolvent_descriptors = pd.DataFrame(descs)\n\n\n# these functions are for faking real experimental data ;)\ndef calc_volume_fact(V):\n    # 20-90\n    # max at 75 = 1\n    # min at 20 = 0.7\n    # at 90=0.5\n    x = (V - 20) / 70\n    x = 0.5 + (x - 0.75) * 0.1 + (x - 0.4) ** 2\n    return x\n\n\ndef calc_rhofact(solvent_type, Tfact):\n    #  between 0.7 and 1.1\n    x = solvent_descriptors[\"density\"][solvent_type]\n    x = (1.5 - x) * (Tfact + 0.5) / 2\n    return x.values\n\n\ndef calc_Tfact(T):\n    x = np.exp((T1 + T) / T0)\n    return (x - e0) / de\n\n\n# this can be used to create a dataframe of experiments including yields\ndef create_experiments(domain, nsamples=100, A=25, B=90, candidates=None):\n    Tf = domain.inputs.get_by_key(\"Temperature\")\n    Vf = domain.inputs.get_by_key(\"Solvent Volume\")\n    typef = domain.inputs.get_by_key(\"Solvent Type\")\n    yf = domain.outputs.get_by_key(\"Yield\")\n    if candidates is None:\n        T = np.random.uniform(low=Tf.lower_bound, high=Tf.upper_bound, size=(nsamples,))\n        V = np.random.uniform(low=Vf.lower_bound, high=Vf.upper_bound, size=(nsamples,))\n        solvent_types = [\n            domain.inputs.get_by_key(\"Solvent Type\").categories[np.random.randint(0, 3)]\n            for i in range(nsamples)\n        ]\n    else:\n        nsamples = len(candidates)\n        T = candidates[\"Temperature\"].values\n        V = candidates[\"Solvent Volume\"].values\n        solvent_types = candidates[\"Solvent Type\"].values\n\n    Tfact = calc_Tfact(T)\n    rhofact = calc_rhofact(solvent_types, Tfact)\n    Vfact = calc_volume_fact(V)\n    y = A * Tfact + B * rhofact\n    y = 0.5 * y + 0.5 * y * Vfact\n    # y = y.values\n    samples = pd.DataFrame(\n        {\n            Tf.key: T,\n            Vf.key: V,\n            yf.key: y,\n            typef.key: solvent_types,\n            \"valid_\" + yf.key: np.ones(nsamples),\n        },\n        # index=pd.RangeIndex(nsamples),\n    )\n    samples.index = pd.RangeIndex(nsamples)\n    return samples\n\n\ndef create_candidates(domain, nsamples=4):\n    experiments = create_experiments(domain, nsamples=nsamples)\n    candidates = experiments.drop([\"Yield\", \"valid_Yield\"], axis=1)\n    return candidates\n\n\n# this is for evaluating candidates that do not yet have a yield attributed to it.\ndef evaluate_experiments(domain, candidates):\n    return create_experiments(domain, candidates=candidates)\n</pre> # Reaction Optimization Notebook util code T0 = 25 T1 = 100 e0 = np.exp((T1 + 0) / T0) e60 = np.exp((T1 + 60) / T0) de = e60 - e0  boiling_points = {  # in \u00b0C     \"MeOH\": 64.7,     \"THF\": 66.0,     \"Dioxane\": 101.0, } density = {  # in kg/l     \"MeOH\": 0.792,     \"THF\": 0.886,     \"Dioxane\": 1.03, } # create dict from individual dicts descs = {     \"boiling_points\": boiling_points,     \"density\": density, } solvent_descriptors = pd.DataFrame(descs)   # these functions are for faking real experimental data ;) def calc_volume_fact(V):     # 20-90     # max at 75 = 1     # min at 20 = 0.7     # at 90=0.5     x = (V - 20) / 70     x = 0.5 + (x - 0.75) * 0.1 + (x - 0.4) ** 2     return x   def calc_rhofact(solvent_type, Tfact):     #  between 0.7 and 1.1     x = solvent_descriptors[\"density\"][solvent_type]     x = (1.5 - x) * (Tfact + 0.5) / 2     return x.values   def calc_Tfact(T):     x = np.exp((T1 + T) / T0)     return (x - e0) / de   # this can be used to create a dataframe of experiments including yields def create_experiments(domain, nsamples=100, A=25, B=90, candidates=None):     Tf = domain.inputs.get_by_key(\"Temperature\")     Vf = domain.inputs.get_by_key(\"Solvent Volume\")     typef = domain.inputs.get_by_key(\"Solvent Type\")     yf = domain.outputs.get_by_key(\"Yield\")     if candidates is None:         T = np.random.uniform(low=Tf.lower_bound, high=Tf.upper_bound, size=(nsamples,))         V = np.random.uniform(low=Vf.lower_bound, high=Vf.upper_bound, size=(nsamples,))         solvent_types = [             domain.inputs.get_by_key(\"Solvent Type\").categories[np.random.randint(0, 3)]             for i in range(nsamples)         ]     else:         nsamples = len(candidates)         T = candidates[\"Temperature\"].values         V = candidates[\"Solvent Volume\"].values         solvent_types = candidates[\"Solvent Type\"].values      Tfact = calc_Tfact(T)     rhofact = calc_rhofact(solvent_types, Tfact)     Vfact = calc_volume_fact(V)     y = A * Tfact + B * rhofact     y = 0.5 * y + 0.5 * y * Vfact     # y = y.values     samples = pd.DataFrame(         {             Tf.key: T,             Vf.key: V,             yf.key: y,             typef.key: solvent_types,             \"valid_\" + yf.key: np.ones(nsamples),         },         # index=pd.RangeIndex(nsamples),     )     samples.index = pd.RangeIndex(nsamples)     return samples   def create_candidates(domain, nsamples=4):     experiments = create_experiments(domain, nsamples=nsamples)     candidates = experiments.drop([\"Yield\", \"valid_Yield\"], axis=1)     return candidates   # this is for evaluating candidates that do not yet have a yield attributed to it. def evaluate_experiments(domain, candidates):     return create_experiments(domain, candidates=candidates) In\u00a0[\u00a0]: Copied! <pre># create some trial experiments (at unitform random)\ncandidates = create_candidates(domain, nsamples=4)\n</pre> # create some trial experiments (at unitform random) candidates = create_candidates(domain, nsamples=4) In\u00a0[\u00a0]: Copied! <pre>candidates\n</pre> candidates In\u00a0[\u00a0]: Copied! <pre># we can evaluate the yield of those candidates\nexperiments = evaluate_experiments(domain, candidates)\n</pre> # we can evaluate the yield of those candidates experiments = evaluate_experiments(domain, candidates) In\u00a0[\u00a0]: Copied! <pre>experiments\n</pre> experiments In\u00a0[\u00a0]: Copied! <pre>import bofire.strategies.api as strategies\nfrom bofire.data_models.acquisition_functions.api import qLogEI\nfrom bofire.data_models.strategies.api import SoboStrategy\n</pre> import bofire.strategies.api as strategies from bofire.data_models.acquisition_functions.api import qLogEI from bofire.data_models.strategies.api import SoboStrategy In\u00a0[\u00a0]: Copied! <pre># a single objective BO strategy\n\nsobo_strategy_data_model = SoboStrategy(\n    domain=domain,\n    acquisition_function=qLogEI(),\n)\n\n# map the strategy data model to the actual strategy that has functionality\nsobo_strategy = strategies.map(sobo_strategy_data_model)\n</pre> # a single objective BO strategy  sobo_strategy_data_model = SoboStrategy(     domain=domain,     acquisition_function=qLogEI(), )  # map the strategy data model to the actual strategy that has functionality sobo_strategy = strategies.map(sobo_strategy_data_model) In\u00a0[\u00a0]: Copied! <pre># first we fit the model of the strategy\n\nsobo_strategy.tell(experiments)\n</pre> # first we fit the model of the strategy  sobo_strategy.tell(experiments) <p>Each implemented strategy has a <code>strategy.ask(n)</code> method implemented, where new experiment candidates can be fetched from.</p> In\u00a0[\u00a0]: Copied! <pre># uncomment and run me to see what's happening!\n# sobo_strategy.ask(1)\n</pre> # uncomment and run me to see what's happening! # sobo_strategy.ask(1) <p>Since a BO strategy requires an underlying regression model for predictions, it requires a certain amount of initial experiments for it to be able to build such a model.</p> <p>In order to obtain initial experiments, one way is to (pseudo)randomly sample candidate points in the reaction domain. This can e.g. be done by the RandomStrategy.</p> In\u00a0[\u00a0]: Copied! <pre># a random strategy\nfrom bofire.data_models.strategies.api import RandomStrategy as RandomStrategyModel\n\n\nrandom_strategy_model = RandomStrategyModel(domain=domain)\n# we have to provide the strategy with our optimization problem so it knows where to sample from.\nrandom_strategy = strategies.map(random_strategy_model)\n</pre> # a random strategy from bofire.data_models.strategies.api import RandomStrategy as RandomStrategyModel   random_strategy_model = RandomStrategyModel(domain=domain) # we have to provide the strategy with our optimization problem so it knows where to sample from. random_strategy = strategies.map(random_strategy_model) In\u00a0[\u00a0]: Copied! <pre>domain\n</pre> domain In\u00a0[\u00a0]: Copied! <pre># let's ask for five random sets of conditions\ncandidates = random_strategy.ask(5)\n</pre> # let's ask for five random sets of conditions candidates = random_strategy.ask(5) <p>you can have a look at the candidates</p> In\u00a0[\u00a0]: Copied! <pre>candidates\n</pre> candidates <p>In order to use those experiments as data foundation of the bo strategy above, the output values of these candidates have to be provided. Herein we'll use a dummy function to evaluate some more or less realistic yields given the proposed input candidates as.</p> In\u00a0[\u00a0]: Copied! <pre>experiments = evaluate_experiments(domain, candidates)\n</pre> experiments = evaluate_experiments(domain, candidates) In\u00a0[\u00a0]: Copied! <pre>experiments\n</pre> experiments <p>note, that the columns <code>Yield</code> and <code>valid_Yield</code> have been added. <code>Yield</code> contains the actual output, whereas <code>valid_Yield</code> labels the experiment as valid w.r.t. this respective measured output.</p> <p>This info can now be given to the bo strategy so it can use it to fit the underlying regression model it utilizes via the <code>strategy.tell()</code> method.</p> In\u00a0[\u00a0]: Copied! <pre>t1 = time.time()\nsobo_strategy.tell(experiments, replace=True, retrain=True)\nprint(f\"fit took {(time.time()-t1):.2f} seconds\")\n</pre> t1 = time.time() sobo_strategy.tell(experiments, replace=True, retrain=True) print(f\"fit took {(time.time()-t1):.2f} seconds\") <p>Using this data we can now get a proposal for a next point to evaluate via the <code>sobo_strategy.ask(1)</code> method.</p> In\u00a0[\u00a0]: Copied! <pre>t1 = time.time()\nnew_candidate = sobo_strategy.ask(1)\nprint(f\"SOBO step took {(time.time()-t1):.2f} seconds\")\n</pre> t1 = time.time() new_candidate = sobo_strategy.ask(1) print(f\"SOBO step took {(time.time()-t1):.2f} seconds\") <p>This ask call now takes way longer, since first a GP model is fitted to the data, and the acquisition function EI is optimized to obtain the new proposed candidates. Note that the predictied yield and standard deviation, as well as desirability function value (the underlying value the optimizer sees) are provided in the new_candidate dataframe.</p> In\u00a0[\u00a0]: Copied! <pre>new_candidate\n</pre> new_candidate In\u00a0[\u00a0]: Copied! <pre>experimental_budget = 10\ni = 0\n# in case of smoke_test we don't run the actual optimization loop ...\ndone = False if not SMOKE_TEST else True\n\nwhile not done:\n    i += 1\n    t1 = time.time()\n    # ask for a new experiment\n    new_candidate = sobo_strategy.ask(1)\n    new_experiment = evaluate_experiments(domain, new_candidate)\n    sobo_strategy.tell(new_experiment)\n    print(f\"Iteration took {(time.time()-t1):.2f} seconds\")\n    # inform the strategy about the new experiment\n    # experiments = pd.concat([experiments,new_experiment],ignore_index=True)\n    if i &gt; experimental_budget:\n        done = True\n</pre> experimental_budget = 10 i = 0 # in case of smoke_test we don't run the actual optimization loop ... done = False if not SMOKE_TEST else True  while not done:     i += 1     t1 = time.time()     # ask for a new experiment     new_candidate = sobo_strategy.ask(1)     new_experiment = evaluate_experiments(domain, new_candidate)     sobo_strategy.tell(new_experiment)     print(f\"Iteration took {(time.time()-t1):.2f} seconds\")     # inform the strategy about the new experiment     # experiments = pd.concat([experiments,new_experiment],ignore_index=True)     if i &gt; experimental_budget:         done = True In\u00a0[\u00a0]: Copied! <pre># you have access to the experiments here\nsobo_strategy.experiments\n</pre> # you have access to the experiments here sobo_strategy.experiments In\u00a0[\u00a0]: Copied! <pre># quick plot of yield vs. Iteration\nsobo_strategy.experiments[\"Yield\"].plot()\n</pre> # quick plot of yield vs. Iteration sobo_strategy.experiments[\"Yield\"].plot()"},{"location":"reaction_optimization/#getting-started-by-example-optimization-of-reaction-conditions","title":"Getting started by Example: Optimization of Reaction Conditions\u00b6","text":"<p>In this example we take on a reaction condition optimization problem: Suppose you have some simple reaction where two ingredients $A$ and $B$ react to $C$ as</p> <p>$$ A + B  \\rightarrow C $$</p> <p>Our reactors can be temperature controlled, and we can use different solvents. Furthermore, we can dilute our reaction mixture by using a different solvent volume. parameters like the temperature or the solvent volume are continuous parameters, where we have to set our ranges $$ 0^{\\, \\circ} \\text{C}  \\, \\le T \\le \\,  60^{\\, \\circ} \\text{C}  $$</p> <p>$$ 20 \\, \\text{ml} \\le V_{solvent} \\le 90 \\,\\text{ml}  $$</p> <p>Parameters like the use of which solvent, where there's a choice of either this or that, are categorical parameters $$ \\text{Solvent} \\, S \\,  \\in  \\, \\{ \\text{MeOH, THF, Dioxane} \\} $$</p> <p>For now we only wish top optimize the Reaction yield, making this a single objective optimization problem.</p> <p>$$ \\max _{T,V,S} \\text{ReactionYield}(T,V,S) $$</p> <p>Below we'll see how to perform such an optimization using bofire, Utilizing a Single Objective Bayesian Optimization (SOBO) Strategy</p>"},{"location":"reaction_optimization/#setting-up-the-optimization-problem-as-a-reaction-domain","title":"Setting up the optimization problem as a Reaction Domain\u00b6","text":""},{"location":"reaction_optimization/#import-a-toy-reaction-to-play-around-with","title":"Import a toy Reaction to play around with\u00b6","text":"<p>We've prepared a reaction emulator, which you can use to emulate a real experiment below.</p>"},{"location":"reaction_optimization/#strategy-setup","title":"Strategy Setup\u00b6","text":"<p>a BO Strategy requires a choice of an acquisition function in order to evaluate the quality of new trial candidates.</p> <p>In this example we'll use the popular Expected Improvement (EI) acqf, which can evaluate the expectation value for obtaining a better function value compared to the current best value by utilizing the regression models' prediction of botht the function value as well as the variance at that point.</p>"},{"location":"reaction_optimization/#optimization-loop","title":"Optimization Loop\u00b6","text":"<p>With this <code>strategy.ask()</code> and <code>strategy.tell()</code> we can now do our optimization loop, where after each new proposal, the conditions obtained from <code>ask</code> are evaluated and added to the known datapoints via <code>tell</code>. This requires to refit the underling model in each step.</p>"},{"location":"reaction_optimization/#investigating-results","title":"investigating results\u00b6","text":""},{"location":"reaction_optimization/#exercises","title":"Exercises:\u00b6","text":"<ul> <li>further analyze of the experiments.<ul> <li>plot of Iteration vs. Y and best observed Y</li> <li>evaluation of final model w.r.t. Optimal conditions</li> <li>plot of final models' mean and variance as a function of the input parameters, perhaps different plots for each solvent, or in 3d as slices</li> </ul> </li> </ul>"},{"location":"ref-constraints/","title":"Domain","text":""},{"location":"ref-constraints/#bofire.data_models.domain.constraints.Constraints","title":"<code>Constraints</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[C]</code></p> Source code in <code>bofire/data_models/domain/constraints.py</code> <pre><code>class Constraints(BaseModel, Generic[C]):\n    type: Literal[\"Constraints\"] = \"Constraints\"\n    constraints: Sequence[C] = Field(default_factory=list)\n\n    def __iter__(self) -&gt; Iterator[C]:\n        return iter(self.constraints)\n\n    def __len__(self):\n        return len(self.constraints)\n\n    def __getitem__(self, i) -&gt; C:\n        return self.constraints[i]\n\n    def __add__(\n        self,\n        other: Union[Sequence[CIncludes], \"Constraints[CIncludes]\"],\n    ) -&gt; \"Constraints[Union[C, CIncludes]]\":\n        if isinstance(other, collections.abc.Sequence):\n            other_constraints = other\n        else:\n            other_constraints = other.constraints\n        constraints = list(chain(self.constraints, other_constraints))\n        return Constraints(constraints=constraints)\n\n    def __call__(self, experiments: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Numerically evaluate all constraints\n\n        Args:\n            experiments (pd.DataFrame): data to evaluate the constraint on\n\n        Returns:\n            pd.DataFrame: Constraint evaluation for each of the constraints\n\n        \"\"\"\n        return pd.concat([c(experiments) for c in self.constraints], axis=1)\n\n    def jacobian(self, experiments: pd.DataFrame) -&gt; list:\n        \"\"\"Numerically evaluate the jacobians of all constraints\n\n        Args:\n            experiments (pd.DataFrame): data to evaluate the constraint jacobians on\n\n        Returns:\n            list: A list containing the jacobians as pd.DataFrames\n\n        \"\"\"\n        return [c.jacobian(experiments) for c in self.constraints]\n\n    def is_fulfilled(self, experiments: pd.DataFrame, tol: float = 1e-6) -&gt; pd.Series:\n        \"\"\"Check if all constraints are fulfilled on all rows of the provided dataframe\n\n        Args:\n            experiments (pd.DataFrame): Dataframe with data, the constraint validity should be tested on\n            tol (float, optional): tolerance parameter. A constraint is considered as not fulfilled if\n                the violation is larger than tol. Defaults to 0.\n\n        Returns:\n            Boolean: True if all constraints are fulfilled for all rows, false if not\n\n        \"\"\"\n        if len(self.constraints) == 0:\n            return pd.Series([True] * len(experiments), index=experiments.index)\n        return (\n            pd.concat(\n                [c.is_fulfilled(experiments, tol) for c in self.constraints],\n                axis=1,\n            )\n            .fillna(True)\n            .all(axis=1)\n        )\n\n    def get(\n        self,\n        includes: Union[Type[CIncludes], Sequence[Type[CIncludes]]] = Constraint,\n        excludes: Optional[Union[Type[CExcludes], List[Type[CExcludes]]]] = None,\n        exact: bool = False,\n    ) -&gt; \"Constraints[CIncludes]\":\n        \"\"\"Get constraints of the domain\n\n        Args:\n            includes: Constraint class or list of specific constraint classes to be returned. Defaults to Constraint.\n            excludes: Constraint class or list of specific constraint classes to be excluded from the return. Defaults to None.\n            exact: Boolean to distinguish if only the exact class listed in includes and no subclasses inherenting from this class shall be returned. Defaults to False.\n\n        Returns:\n            Constraints: constraints in the domain fitting to the passed requirements.\n\n        \"\"\"\n        return Constraints(\n            constraints=filter_by_class(\n                self.constraints,\n                includes=includes,\n                excludes=excludes,\n                exact=exact,\n            ),\n        )\n\n    def get_reps_df(self):\n        \"\"\"Provides a tabular overwiev of all constraints within the domain\n\n        Returns:\n            pd.DataFrame: DataFrame listing all constraints of the domain with a description\n\n        \"\"\"\n        df = pd.DataFrame(\n            index=range(len(self.constraints)),\n            columns=[\"Type\", \"Description\"],\n            data={\n                \"Type\": [feat.__class__.__name__ for feat in self.get(Constraint)],\n                \"Description\": [\n                    constraint.__str__() for constraint in self.get(Constraint)\n                ],\n            },\n        )\n        return df\n</code></pre>"},{"location":"ref-constraints/#bofire.data_models.domain.constraints.Constraints.__call__","title":"<code>__call__(experiments)</code>","text":"<p>Numerically evaluate all constraints</p> <p>Parameters:</p> Name Type Description Default <code>experiments</code> <code>DataFrame</code> <p>data to evaluate the constraint on</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Constraint evaluation for each of the constraints</p> Source code in <code>bofire/data_models/domain/constraints.py</code> <pre><code>def __call__(self, experiments: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Numerically evaluate all constraints\n\n    Args:\n        experiments (pd.DataFrame): data to evaluate the constraint on\n\n    Returns:\n        pd.DataFrame: Constraint evaluation for each of the constraints\n\n    \"\"\"\n    return pd.concat([c(experiments) for c in self.constraints], axis=1)\n</code></pre>"},{"location":"ref-constraints/#bofire.data_models.domain.constraints.Constraints.get","title":"<code>get(includes=Constraint, excludes=None, exact=False)</code>","text":"<p>Get constraints of the domain</p> <p>Parameters:</p> Name Type Description Default <code>includes</code> <code>Union[Type[CIncludes], Sequence[Type[CIncludes]]]</code> <p>Constraint class or list of specific constraint classes to be returned. Defaults to Constraint.</p> <code>Constraint</code> <code>excludes</code> <code>Optional[Union[Type[CExcludes], List[Type[CExcludes]]]]</code> <p>Constraint class or list of specific constraint classes to be excluded from the return. Defaults to None.</p> <code>None</code> <code>exact</code> <code>bool</code> <p>Boolean to distinguish if only the exact class listed in includes and no subclasses inherenting from this class shall be returned. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Constraints</code> <code>Constraints[CIncludes]</code> <p>constraints in the domain fitting to the passed requirements.</p> Source code in <code>bofire/data_models/domain/constraints.py</code> <pre><code>def get(\n    self,\n    includes: Union[Type[CIncludes], Sequence[Type[CIncludes]]] = Constraint,\n    excludes: Optional[Union[Type[CExcludes], List[Type[CExcludes]]]] = None,\n    exact: bool = False,\n) -&gt; \"Constraints[CIncludes]\":\n    \"\"\"Get constraints of the domain\n\n    Args:\n        includes: Constraint class or list of specific constraint classes to be returned. Defaults to Constraint.\n        excludes: Constraint class or list of specific constraint classes to be excluded from the return. Defaults to None.\n        exact: Boolean to distinguish if only the exact class listed in includes and no subclasses inherenting from this class shall be returned. Defaults to False.\n\n    Returns:\n        Constraints: constraints in the domain fitting to the passed requirements.\n\n    \"\"\"\n    return Constraints(\n        constraints=filter_by_class(\n            self.constraints,\n            includes=includes,\n            excludes=excludes,\n            exact=exact,\n        ),\n    )\n</code></pre>"},{"location":"ref-constraints/#bofire.data_models.domain.constraints.Constraints.get_reps_df","title":"<code>get_reps_df()</code>","text":"<p>Provides a tabular overwiev of all constraints within the domain</p> <p>Returns:</p> Type Description <p>pd.DataFrame: DataFrame listing all constraints of the domain with a description</p> Source code in <code>bofire/data_models/domain/constraints.py</code> <pre><code>def get_reps_df(self):\n    \"\"\"Provides a tabular overwiev of all constraints within the domain\n\n    Returns:\n        pd.DataFrame: DataFrame listing all constraints of the domain with a description\n\n    \"\"\"\n    df = pd.DataFrame(\n        index=range(len(self.constraints)),\n        columns=[\"Type\", \"Description\"],\n        data={\n            \"Type\": [feat.__class__.__name__ for feat in self.get(Constraint)],\n            \"Description\": [\n                constraint.__str__() for constraint in self.get(Constraint)\n            ],\n        },\n    )\n    return df\n</code></pre>"},{"location":"ref-constraints/#bofire.data_models.domain.constraints.Constraints.is_fulfilled","title":"<code>is_fulfilled(experiments, tol=1e-06)</code>","text":"<p>Check if all constraints are fulfilled on all rows of the provided dataframe</p> <p>Parameters:</p> Name Type Description Default <code>experiments</code> <code>DataFrame</code> <p>Dataframe with data, the constraint validity should be tested on</p> required <code>tol</code> <code>float</code> <p>tolerance parameter. A constraint is considered as not fulfilled if the violation is larger than tol. Defaults to 0.</p> <code>1e-06</code> <p>Returns:</p> Name Type Description <code>Boolean</code> <code>Series</code> <p>True if all constraints are fulfilled for all rows, false if not</p> Source code in <code>bofire/data_models/domain/constraints.py</code> <pre><code>def is_fulfilled(self, experiments: pd.DataFrame, tol: float = 1e-6) -&gt; pd.Series:\n    \"\"\"Check if all constraints are fulfilled on all rows of the provided dataframe\n\n    Args:\n        experiments (pd.DataFrame): Dataframe with data, the constraint validity should be tested on\n        tol (float, optional): tolerance parameter. A constraint is considered as not fulfilled if\n            the violation is larger than tol. Defaults to 0.\n\n    Returns:\n        Boolean: True if all constraints are fulfilled for all rows, false if not\n\n    \"\"\"\n    if len(self.constraints) == 0:\n        return pd.Series([True] * len(experiments), index=experiments.index)\n    return (\n        pd.concat(\n            [c.is_fulfilled(experiments, tol) for c in self.constraints],\n            axis=1,\n        )\n        .fillna(True)\n        .all(axis=1)\n    )\n</code></pre>"},{"location":"ref-constraints/#bofire.data_models.domain.constraints.Constraints.jacobian","title":"<code>jacobian(experiments)</code>","text":"<p>Numerically evaluate the jacobians of all constraints</p> <p>Parameters:</p> Name Type Description Default <code>experiments</code> <code>DataFrame</code> <p>data to evaluate the constraint jacobians on</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list containing the jacobians as pd.DataFrames</p> Source code in <code>bofire/data_models/domain/constraints.py</code> <pre><code>def jacobian(self, experiments: pd.DataFrame) -&gt; list:\n    \"\"\"Numerically evaluate the jacobians of all constraints\n\n    Args:\n        experiments (pd.DataFrame): data to evaluate the constraint jacobians on\n\n    Returns:\n        list: A list containing the jacobians as pd.DataFrames\n\n    \"\"\"\n    return [c.jacobian(experiments) for c in self.constraints]\n</code></pre>"},{"location":"ref-domain-util/","title":"Domain","text":""},{"location":"ref-domain/","title":"Domain","text":""},{"location":"ref-domain/#bofire.data_models.domain.domain.Domain","title":"<code>Domain</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>bofire/data_models/domain/domain.py</code> <pre><code>class Domain(BaseModel):\n    type: Literal[\"Domain\"] = \"Domain\"\n\n    inputs: Inputs = Field(default_factory=lambda: Inputs())\n    outputs: Outputs = Field(default_factory=lambda: Outputs())\n    constraints: Constraints = Field(default_factory=lambda: Constraints())\n\n    \"\"\"Representation of the optimization problem/domain\n\n    Attributes:\n        inputs (List[Input], optional): List of input features. Defaults to [].\n        outputs (List[Output], optional): List of output features. Defaults to [].\n        constraints (List[Constraint], optional): List of constraints. Defaults to [].\n    \"\"\"\n\n    @classmethod\n    def from_lists(\n        cls,\n        inputs: Optional[Sequence[AnyInput]] = None,\n        outputs: Optional[Sequence[AnyOutput]] = None,\n        constraints: Optional[Sequence[AnyConstraint]] = None,\n    ):\n        inputs = [] if inputs is None else inputs\n        outputs = [] if outputs is None else outputs\n        constraints = [] if constraints is None else constraints\n        return cls(\n            inputs=Inputs(features=inputs),\n            outputs=Outputs(features=outputs),\n            constraints=Constraints(constraints=constraints),\n        )\n\n    @field_validator(\"inputs\", mode=\"before\")\n    @classmethod\n    def validate_inputs_list(cls, v):\n        if isinstance(v, collections.abc.Sequence):\n            v = Inputs(features=v)\n            return v\n        if isinstance_or_union(v, AnyInput):\n            return Inputs(features=[v])\n        return v\n\n    @field_validator(\"outputs\", mode=\"before\")\n    @classmethod\n    def validate_outputs_list(cls, v):\n        if isinstance(v, collections.abc.Sequence):\n            return Outputs(features=v)\n        if isinstance_or_union(v, AnyOutput):\n            return Outputs(features=[v])\n        return v\n\n    @field_validator(\"constraints\", mode=\"before\")\n    @classmethod\n    def validate_constraints_list(cls, v):\n        if isinstance(v, list):\n            return Constraints(constraints=v)\n        if isinstance_or_union(v, AnyConstraint):\n            return Constraints(constraints=[v])\n        return v\n\n    @model_validator(mode=\"after\")\n    def validate_unique_feature_keys(self):\n        \"\"\"Validates if provided input and output feature keys are unique\n\n        Args:\n            v (Outputs): List of all output features of the domain.\n            value (Dict[str, Inputs]): Dict containing a list of input features as single entry.\n\n        Raises:\n            ValueError: Feature keys are not unique.\n\n        Returns:\n            Outputs: Keeps output features as given.\n\n        \"\"\"\n        keys = self.outputs.get_keys() + self.inputs.get_keys()\n        if len(set(keys)) != len(keys):\n            raise ValueError(\"Feature keys are not unique\")\n        return self\n\n    @model_validator(mode=\"after\")\n    def validate_constraints(self):\n        \"\"\"Validate that the constraints defined in the domain fit to the input features.\n\n        Args:\n            v (List[Constraint]): List of constraints or empty if no constraints are defined\n            values (List[Input]): List of input features of the domain\n\n        Raises:\n            ValueError: Feature key in constraint is unknown.\n\n        Returns:\n            List[Constraint]: List of constraints defined for the domain\n\n        \"\"\"\n        for c in self.constraints.get():\n            c.validate_inputs(self.inputs)\n        return self\n\n    # TODO: tidy this up\n    def get_nchoosek_combinations(self, exhaustive: bool = False):\n        \"\"\"Get all possible NChooseK combinations\n\n        Args:\n            exhaustive (bool, optional): if True all combinations are returned. Defaults to False.\n\n        Returns:\n            Tuple(used_features_list, unused_features_list): used_features_list is a list of lists containing features used in each NChooseK combination.\n                unused_features_list is a list of lists containing features unused in each NChooseK combination.\n\n        \"\"\"\n        if len(self.constraints.get(NChooseKConstraint)) == 0:\n            used_continuous_features = self.inputs.get_keys(ContinuousInput)\n            return used_continuous_features, []\n\n        used_features_list_all = []\n\n        # loops through each NChooseK constraint\n        for con in self.constraints.get(NChooseKConstraint):\n            assert isinstance(con, NChooseKConstraint)\n            used_features_list = []\n\n            if exhaustive:\n                for n in range(con.min_count, con.max_count + 1):\n                    used_features_list.extend(itertools.combinations(con.features, n))\n\n                if con.none_also_valid:\n                    used_features_list.append(())\n            else:\n                used_features_list.extend(\n                    itertools.combinations(con.features, con.max_count),\n                )\n\n            used_features_list_all.append(used_features_list)\n\n        used_features_list_all = list(\n            itertools.product(*used_features_list_all),\n        )  # product between NChooseK constraints\n\n        # format into a list of used features\n        used_features_list_formatted = []\n        for used_features_list in used_features_list_all:\n            used_features_list_flattened = [\n                item for sublist in used_features_list for item in sublist\n            ]\n            used_features_list_formatted.append(list(set(used_features_list_flattened)))\n\n        # sort lists\n        used_features_list_sorted = []\n        for used_features in used_features_list_formatted:\n            used_features_list_sorted.append(sorted(used_features))\n\n        # drop duplicates\n        used_features_list_no_dup = []\n        for used_features in used_features_list_sorted:\n            if used_features not in used_features_list_no_dup:\n                used_features_list_no_dup.append(used_features)\n\n        # print(f\"duplicates dropped: {len(used_features_list_sorted)-len(used_features_list_no_dup)}\")\n\n        # remove combinations not fulfilling constraints\n        used_features_list_final = []\n        for combo in used_features_list_no_dup:\n            fulfil_constraints = []  # list of bools tracking if constraints are fulfilled\n            for con in self.constraints.get(NChooseKConstraint):\n                assert isinstance(con, NChooseKConstraint)\n                count = 0  # count of features in combo that are in con.features\n                for f in combo:\n                    if f in con.features:\n                        count += 1\n                if (\n                    count &gt;= con.min_count\n                    and count &lt;= con.max_count\n                    or count == 0\n                    and con.none_also_valid\n                ):\n                    fulfil_constraints.append(True)\n                else:\n                    fulfil_constraints.append(False)\n            if np.all(fulfil_constraints):\n                used_features_list_final.append(combo)\n\n        # print(f\"violators dropped: {len(used_features_list_no_dup)-len(used_features_list_final)}\")\n\n        # features unused\n        features_in_cc = []\n        for con in self.constraints.get(NChooseKConstraint):\n            assert isinstance(con, NChooseKConstraint)\n            features_in_cc.extend(con.features)\n        features_in_cc = list(set(features_in_cc))\n        features_in_cc.sort()\n        unused_features_list = []\n        for used_features in used_features_list_final:\n            unused_features_list.append(\n                [f_key for f_key in features_in_cc if f_key not in used_features],\n            )\n\n        # postprocess\n        # used_features_list_final2 = []\n        # unused_features_list2 = []\n        # for used, unused in zip(used_features_list_final,unused_features_list):\n        #     if len(used) == 3:\n        #         used_features_list_final2.append(used), unused_features_list2.append(unused)\n\n        return used_features_list_final, unused_features_list\n\n    def coerce_invalids(self, experiments: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Coerces all invalid output measurements to np.nan\n\n        Args:\n            experiments (pd.DataFrame): Dataframe containing experimental data\n\n        Returns:\n            pd.DataFrame: coerced dataframe\n\n        \"\"\"\n        # coerce invalid to nan\n        for feat in self.outputs.get_keys(Output):\n            experiments.loc[experiments[f\"valid_{feat}\"] == 0, feat] = np.nan\n        return experiments\n\n    def aggregate_by_duplicates(\n        self,\n        experiments: pd.DataFrame,\n        prec: int,\n        delimiter: str = \"-\",\n        method: Literal[\"mean\", \"median\"] = \"mean\",\n    ) -&gt; Tuple[pd.DataFrame, list]:\n        \"\"\"Aggregate the dataframe by duplicate experiments\n\n        Duplicates are identified based on the experiments with the same input\n        features. Continuous input features are rounded before identifying the\n        duplicates. Aggregation is performed by taking the average of the\n        involved output features.\n\n        Args:\n            experiments (pd.DataFrame): Dataframe containing experimental data\n            prec (int): Precision of the rounding of the continuous input features\n            delimiter (str, optional): Delimiter used when combining the orig.\n                labcodes to a new one. Defaults to \"-\".\n            method (Literal[\"mean\", \"median\"], optional): Which aggregation\n                method to use. Defaults to \"mean\".\n\n        Returns:\n            Tuple[pd.DataFrame, list]: Dataframe holding the aggregated\n                experiments, list of lists holding the labcodes of the duplicates\n\n        \"\"\"\n        # prepare the parent frame\n        if method not in [\"mean\", \"median\"]:\n            raise ValueError(f\"Unknown aggregation type provided: {method}\")\n\n        preprocessed = self.outputs.preprocess_experiments_any_valid_output(experiments)\n        assert preprocessed is not None\n        experiments = preprocessed.copy()\n        if \"labcode\" not in experiments.columns:\n            experiments[\"labcode\"] = [\n                str(i + 1).zfill(int(np.ceil(np.log10(experiments.shape[0]))))\n                for i in range(experiments.shape[0])\n            ]\n\n        # round it if continuous inputs are present\n        if len(self.inputs.get(ContinuousInput)) &gt; 0:\n            experiments[self.inputs.get_keys(ContinuousInput)] = experiments[\n                self.inputs.get_keys(ContinuousInput)\n            ].round(prec)\n\n        # coerce invalid to nan\n        experiments = self.coerce_invalids(experiments)\n\n        # group and aggregate\n        agg: Dict[str, Any] = {\n            feat: method for feat in self.outputs.get_keys(ContinuousOutput)\n        }\n        agg[\"labcode\"] = lambda x: delimiter.join(sorted(x.tolist()))\n        for feat in self.outputs.get_keys(Output):\n            agg[f\"valid_{feat}\"] = lambda x: 1\n\n        grouped = experiments.groupby(self.inputs.get_keys(Input))\n        duplicated_labcodes = [\n            sorted(group.labcode.to_numpy().tolist())\n            for _, group in grouped\n            if group.shape[0] &gt; 1\n        ]\n\n        experiments = grouped.aggregate(agg).reset_index(drop=False)\n        for feat in self.outputs.get_keys(Output):\n            experiments.loc[experiments[feat].isna(), f\"valid_{feat}\"] = 0\n\n        experiments = experiments.sort_values(by=\"labcode\")\n        experiments = experiments.reset_index(drop=True)\n        return experiments, sorted(duplicated_labcodes)\n\n    def validate_experiments(\n        self,\n        experiments: pd.DataFrame,\n        strict: bool = False,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Checks the experimental data on validity\n\n        Args:\n            experiments (pd.DataFrame): Dataframe with experimental data\n            strict (bool, optional): Boolean to distinguish if the occurrence of\n                fixed features in the dataset should be considered or not.\n                Defaults to False.\n\n        Raises:\n            ValueError: empty dataframe\n            ValueError: the column for a specific feature is missing the provided data\n            ValueError: there are labcodes with null value\n            ValueError: there are labcodes with nan value\n            ValueError: labcodes are not unique\n            ValueError: the provided columns do no match to the defined domain\n            ValueError: the provided columns do no match to the defined domain\n            ValueError: Input with null values\n            ValueError: Input with nan values\n\n        Returns:\n            pd.DataFrame: The provided dataframe with experimental data\n\n        \"\"\"\n        if len(experiments) == 0:\n            raise ValueError(\"no experiments provided (empty dataframe)\")\n\n        # we allow here for a column named labcode used to identify experiments\n        if \"labcode\" in experiments.columns:\n            # test that labcodes are not na\n            if experiments.labcode.isnull().to_numpy().any():\n                raise ValueError(\"there are labcodes with null value\")\n            if experiments.labcode.isna().to_numpy().any():\n                raise ValueError(\"there are labcodes with nan value\")\n            # test that labcodes are distinct\n            if (\n                len(set(experiments.labcode.to_numpy().tolist()))\n                != experiments.shape[0]\n            ):\n                raise ValueError(\"labcodes are not unique\")\n\n        # run the individual validators\n        experiments = self.inputs.validate_experiments(\n            experiments=experiments,\n            strict=strict,\n        )\n        experiments = self.outputs.validate_experiments(experiments=experiments)\n        return experiments\n\n    def describe_experiments(self, experiments: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Method to get a tabular overview of how many measurements and how many valid entries are included in the input data for each output feature\n\n        Args:\n            experiments (pd.DataFrame): Dataframe with experimental data\n\n        Returns:\n            pd.DataFrame: Dataframe with counts how many measurements and how many valid entries are included in the input data for each output feature\n\n        \"\"\"\n        data = {}\n        for feat in self.outputs.get_keys(Output):\n            data[feat] = [\n                experiments.loc[experiments[feat].notna()].shape[0],\n                experiments.loc[experiments[feat].notna(), \"valid_%s\" % feat].sum(),\n            ]\n        preprocessed = self.outputs.preprocess_experiments_all_valid_outputs(\n            experiments,\n        )\n        assert preprocessed is not None\n        data[\"all\"] = [\n            experiments.shape[0],\n            preprocessed.shape[0],\n        ]\n        return pd.DataFrame.from_dict(\n            data,\n            orient=\"index\",\n            columns=[\"measured\", \"valid\"],\n        )\n\n    def validate_candidates(\n        self,\n        candidates: pd.DataFrame,\n        only_inputs: bool = False,\n        tol: float = 1e-5,\n        raise_validation_error: bool = True,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Method to check the validty of proposed candidates\n\n        Args:\n            candidates (pd.DataFrame): Dataframe with suggested new experiments (candidates)\n            only_inputs (bool,optional): If True, only the input columns are validated. Defaults to False.\n            tol (float,optional): tolerance parameter for constraints. A constraint is considered as not fulfilled if the violation\n                is larger than tol. Defaults to 1e-6.\n            raise_validation_error (bool, optional): If true an error will be raised if candidates violate constraints,\n                otherwise only a warning will be displayed. Defaults to True.\n\n        Raises:\n            ValueError: when a column is missing for a defined input feature\n            ValueError: when a column is missing for a defined output feature\n            ValueError: when a non-numerical value is proposed\n            ValueError: when an additional column is found\n            ConstraintNotFulfilledError: when the constraints are not fulfilled and `raise_validation_error = True`\n\n        Returns:\n            pd.DataFrame: dataframe with suggested experiments (candidates)\n\n        \"\"\"\n        # check that each input feature has a col and is valid in itself\n        assert isinstance(self.inputs, Inputs)\n        candidates = self.inputs.validate_candidates(candidates)\n        # check if all constraints are fulfilled\n        if not self.constraints.is_fulfilled(candidates, tol=tol).all():\n            if raise_validation_error:\n                raise ConstraintNotFulfilledError(\n                    f\"Constraints not fulfilled: {candidates}\",\n                )\n            warnings.warn(\"Not all constraints are fulfilled.\")\n        # for each continuous output feature with an attached objective object\n        if not only_inputs:\n            assert isinstance(self.outputs, Outputs)\n            candidates = self.outputs.validate_candidates(candidates=candidates)\n        return candidates\n\n    @property\n    def experiment_column_names(self):\n        \"\"\"The columns in the experimental dataframe\n\n        Returns:\n            List[str]: List of columns in the experiment dataframe (output feature keys + valid_output feature keys)\n\n        \"\"\"\n        return (self.inputs + self.outputs).get_keys() + [\n            f\"valid_{output_feature_key}\"\n            for output_feature_key in self.outputs.get_keys(Output)\n        ]\n\n    @property\n    def candidate_column_names(self):\n        \"\"\"The columns in the candidate dataframe\n\n        Returns:\n            List[str]: List of columns in the candidate dataframe (input feature keys + input feature keys_pred, input feature keys_sd, input feature keys_des)\n\n        \"\"\"\n        assert isinstance(self.outputs, Outputs)\n        return (\n            self.inputs.get_keys(Input)\n            + [\n                f\"{output_feature_key}_pred\"\n                for output_feature_key in self.outputs.get_keys_by_objective(Objective)\n            ]\n            + [\n                f\"{output_feature_key}_sd\"\n                for output_feature_key in self.outputs.get_keys_by_objective(Objective)\n            ]\n            + [\n                f\"{output_feature_key}_des\"\n                for output_feature_key in self.outputs.get_keys_by_objective(Objective)\n            ]\n        )\n</code></pre>"},{"location":"ref-domain/#bofire.data_models.domain.domain.Domain.candidate_column_names","title":"<code>candidate_column_names</code>  <code>property</code>","text":"<p>The columns in the candidate dataframe</p> <p>Returns:</p> Type Description <p>List[str]: List of columns in the candidate dataframe (input feature keys + input feature keys_pred, input feature keys_sd, input feature keys_des)</p>"},{"location":"ref-domain/#bofire.data_models.domain.domain.Domain.constraints","title":"<code>constraints = Field(default_factory=lambda: Constraints())</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Representation of the optimization problem/domain</p> <p>Attributes:</p> Name Type Description <code>inputs</code> <code>List[Input]</code> <p>List of input features. Defaults to [].</p> <code>outputs</code> <code>List[Output]</code> <p>List of output features. Defaults to [].</p> <code>constraints</code> <code>List[Constraint]</code> <p>List of constraints. Defaults to [].</p>"},{"location":"ref-domain/#bofire.data_models.domain.domain.Domain.experiment_column_names","title":"<code>experiment_column_names</code>  <code>property</code>","text":"<p>The columns in the experimental dataframe</p> <p>Returns:</p> Type Description <p>List[str]: List of columns in the experiment dataframe (output feature keys + valid_output feature keys)</p>"},{"location":"ref-domain/#bofire.data_models.domain.domain.Domain.aggregate_by_duplicates","title":"<code>aggregate_by_duplicates(experiments, prec, delimiter='-', method='mean')</code>","text":"<p>Aggregate the dataframe by duplicate experiments</p> <p>Duplicates are identified based on the experiments with the same input features. Continuous input features are rounded before identifying the duplicates. Aggregation is performed by taking the average of the involved output features.</p> <p>Parameters:</p> Name Type Description Default <code>experiments</code> <code>DataFrame</code> <p>Dataframe containing experimental data</p> required <code>prec</code> <code>int</code> <p>Precision of the rounding of the continuous input features</p> required <code>delimiter</code> <code>str</code> <p>Delimiter used when combining the orig. labcodes to a new one. Defaults to \"-\".</p> <code>'-'</code> <code>method</code> <code>Literal['mean', 'median']</code> <p>Which aggregation method to use. Defaults to \"mean\".</p> <code>'mean'</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, list]</code> <p>Tuple[pd.DataFrame, list]: Dataframe holding the aggregated experiments, list of lists holding the labcodes of the duplicates</p> Source code in <code>bofire/data_models/domain/domain.py</code> <pre><code>def aggregate_by_duplicates(\n    self,\n    experiments: pd.DataFrame,\n    prec: int,\n    delimiter: str = \"-\",\n    method: Literal[\"mean\", \"median\"] = \"mean\",\n) -&gt; Tuple[pd.DataFrame, list]:\n    \"\"\"Aggregate the dataframe by duplicate experiments\n\n    Duplicates are identified based on the experiments with the same input\n    features. Continuous input features are rounded before identifying the\n    duplicates. Aggregation is performed by taking the average of the\n    involved output features.\n\n    Args:\n        experiments (pd.DataFrame): Dataframe containing experimental data\n        prec (int): Precision of the rounding of the continuous input features\n        delimiter (str, optional): Delimiter used when combining the orig.\n            labcodes to a new one. Defaults to \"-\".\n        method (Literal[\"mean\", \"median\"], optional): Which aggregation\n            method to use. Defaults to \"mean\".\n\n    Returns:\n        Tuple[pd.DataFrame, list]: Dataframe holding the aggregated\n            experiments, list of lists holding the labcodes of the duplicates\n\n    \"\"\"\n    # prepare the parent frame\n    if method not in [\"mean\", \"median\"]:\n        raise ValueError(f\"Unknown aggregation type provided: {method}\")\n\n    preprocessed = self.outputs.preprocess_experiments_any_valid_output(experiments)\n    assert preprocessed is not None\n    experiments = preprocessed.copy()\n    if \"labcode\" not in experiments.columns:\n        experiments[\"labcode\"] = [\n            str(i + 1).zfill(int(np.ceil(np.log10(experiments.shape[0]))))\n            for i in range(experiments.shape[0])\n        ]\n\n    # round it if continuous inputs are present\n    if len(self.inputs.get(ContinuousInput)) &gt; 0:\n        experiments[self.inputs.get_keys(ContinuousInput)] = experiments[\n            self.inputs.get_keys(ContinuousInput)\n        ].round(prec)\n\n    # coerce invalid to nan\n    experiments = self.coerce_invalids(experiments)\n\n    # group and aggregate\n    agg: Dict[str, Any] = {\n        feat: method for feat in self.outputs.get_keys(ContinuousOutput)\n    }\n    agg[\"labcode\"] = lambda x: delimiter.join(sorted(x.tolist()))\n    for feat in self.outputs.get_keys(Output):\n        agg[f\"valid_{feat}\"] = lambda x: 1\n\n    grouped = experiments.groupby(self.inputs.get_keys(Input))\n    duplicated_labcodes = [\n        sorted(group.labcode.to_numpy().tolist())\n        for _, group in grouped\n        if group.shape[0] &gt; 1\n    ]\n\n    experiments = grouped.aggregate(agg).reset_index(drop=False)\n    for feat in self.outputs.get_keys(Output):\n        experiments.loc[experiments[feat].isna(), f\"valid_{feat}\"] = 0\n\n    experiments = experiments.sort_values(by=\"labcode\")\n    experiments = experiments.reset_index(drop=True)\n    return experiments, sorted(duplicated_labcodes)\n</code></pre>"},{"location":"ref-domain/#bofire.data_models.domain.domain.Domain.coerce_invalids","title":"<code>coerce_invalids(experiments)</code>","text":"<p>Coerces all invalid output measurements to np.nan</p> <p>Parameters:</p> Name Type Description Default <code>experiments</code> <code>DataFrame</code> <p>Dataframe containing experimental data</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: coerced dataframe</p> Source code in <code>bofire/data_models/domain/domain.py</code> <pre><code>def coerce_invalids(self, experiments: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Coerces all invalid output measurements to np.nan\n\n    Args:\n        experiments (pd.DataFrame): Dataframe containing experimental data\n\n    Returns:\n        pd.DataFrame: coerced dataframe\n\n    \"\"\"\n    # coerce invalid to nan\n    for feat in self.outputs.get_keys(Output):\n        experiments.loc[experiments[f\"valid_{feat}\"] == 0, feat] = np.nan\n    return experiments\n</code></pre>"},{"location":"ref-domain/#bofire.data_models.domain.domain.Domain.describe_experiments","title":"<code>describe_experiments(experiments)</code>","text":"<p>Method to get a tabular overview of how many measurements and how many valid entries are included in the input data for each output feature</p> <p>Parameters:</p> Name Type Description Default <code>experiments</code> <code>DataFrame</code> <p>Dataframe with experimental data</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Dataframe with counts how many measurements and how many valid entries are included in the input data for each output feature</p> Source code in <code>bofire/data_models/domain/domain.py</code> <pre><code>def describe_experiments(self, experiments: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Method to get a tabular overview of how many measurements and how many valid entries are included in the input data for each output feature\n\n    Args:\n        experiments (pd.DataFrame): Dataframe with experimental data\n\n    Returns:\n        pd.DataFrame: Dataframe with counts how many measurements and how many valid entries are included in the input data for each output feature\n\n    \"\"\"\n    data = {}\n    for feat in self.outputs.get_keys(Output):\n        data[feat] = [\n            experiments.loc[experiments[feat].notna()].shape[0],\n            experiments.loc[experiments[feat].notna(), \"valid_%s\" % feat].sum(),\n        ]\n    preprocessed = self.outputs.preprocess_experiments_all_valid_outputs(\n        experiments,\n    )\n    assert preprocessed is not None\n    data[\"all\"] = [\n        experiments.shape[0],\n        preprocessed.shape[0],\n    ]\n    return pd.DataFrame.from_dict(\n        data,\n        orient=\"index\",\n        columns=[\"measured\", \"valid\"],\n    )\n</code></pre>"},{"location":"ref-domain/#bofire.data_models.domain.domain.Domain.get_nchoosek_combinations","title":"<code>get_nchoosek_combinations(exhaustive=False)</code>","text":"<p>Get all possible NChooseK combinations</p> <p>Parameters:</p> Name Type Description Default <code>exhaustive</code> <code>bool</code> <p>if True all combinations are returned. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Tuple</code> <code>(used_features_list, unused_features_list)</code> <p>used_features_list is a list of lists containing features used in each NChooseK combination. unused_features_list is a list of lists containing features unused in each NChooseK combination.</p> Source code in <code>bofire/data_models/domain/domain.py</code> <pre><code>def get_nchoosek_combinations(self, exhaustive: bool = False):\n    \"\"\"Get all possible NChooseK combinations\n\n    Args:\n        exhaustive (bool, optional): if True all combinations are returned. Defaults to False.\n\n    Returns:\n        Tuple(used_features_list, unused_features_list): used_features_list is a list of lists containing features used in each NChooseK combination.\n            unused_features_list is a list of lists containing features unused in each NChooseK combination.\n\n    \"\"\"\n    if len(self.constraints.get(NChooseKConstraint)) == 0:\n        used_continuous_features = self.inputs.get_keys(ContinuousInput)\n        return used_continuous_features, []\n\n    used_features_list_all = []\n\n    # loops through each NChooseK constraint\n    for con in self.constraints.get(NChooseKConstraint):\n        assert isinstance(con, NChooseKConstraint)\n        used_features_list = []\n\n        if exhaustive:\n            for n in range(con.min_count, con.max_count + 1):\n                used_features_list.extend(itertools.combinations(con.features, n))\n\n            if con.none_also_valid:\n                used_features_list.append(())\n        else:\n            used_features_list.extend(\n                itertools.combinations(con.features, con.max_count),\n            )\n\n        used_features_list_all.append(used_features_list)\n\n    used_features_list_all = list(\n        itertools.product(*used_features_list_all),\n    )  # product between NChooseK constraints\n\n    # format into a list of used features\n    used_features_list_formatted = []\n    for used_features_list in used_features_list_all:\n        used_features_list_flattened = [\n            item for sublist in used_features_list for item in sublist\n        ]\n        used_features_list_formatted.append(list(set(used_features_list_flattened)))\n\n    # sort lists\n    used_features_list_sorted = []\n    for used_features in used_features_list_formatted:\n        used_features_list_sorted.append(sorted(used_features))\n\n    # drop duplicates\n    used_features_list_no_dup = []\n    for used_features in used_features_list_sorted:\n        if used_features not in used_features_list_no_dup:\n            used_features_list_no_dup.append(used_features)\n\n    # print(f\"duplicates dropped: {len(used_features_list_sorted)-len(used_features_list_no_dup)}\")\n\n    # remove combinations not fulfilling constraints\n    used_features_list_final = []\n    for combo in used_features_list_no_dup:\n        fulfil_constraints = []  # list of bools tracking if constraints are fulfilled\n        for con in self.constraints.get(NChooseKConstraint):\n            assert isinstance(con, NChooseKConstraint)\n            count = 0  # count of features in combo that are in con.features\n            for f in combo:\n                if f in con.features:\n                    count += 1\n            if (\n                count &gt;= con.min_count\n                and count &lt;= con.max_count\n                or count == 0\n                and con.none_also_valid\n            ):\n                fulfil_constraints.append(True)\n            else:\n                fulfil_constraints.append(False)\n        if np.all(fulfil_constraints):\n            used_features_list_final.append(combo)\n\n    # print(f\"violators dropped: {len(used_features_list_no_dup)-len(used_features_list_final)}\")\n\n    # features unused\n    features_in_cc = []\n    for con in self.constraints.get(NChooseKConstraint):\n        assert isinstance(con, NChooseKConstraint)\n        features_in_cc.extend(con.features)\n    features_in_cc = list(set(features_in_cc))\n    features_in_cc.sort()\n    unused_features_list = []\n    for used_features in used_features_list_final:\n        unused_features_list.append(\n            [f_key for f_key in features_in_cc if f_key not in used_features],\n        )\n\n    # postprocess\n    # used_features_list_final2 = []\n    # unused_features_list2 = []\n    # for used, unused in zip(used_features_list_final,unused_features_list):\n    #     if len(used) == 3:\n    #         used_features_list_final2.append(used), unused_features_list2.append(unused)\n\n    return used_features_list_final, unused_features_list\n</code></pre>"},{"location":"ref-domain/#bofire.data_models.domain.domain.Domain.validate_candidates","title":"<code>validate_candidates(candidates, only_inputs=False, tol=1e-05, raise_validation_error=True)</code>","text":"<p>Method to check the validty of proposed candidates</p> <p>Parameters:</p> Name Type Description Default <code>candidates</code> <code>DataFrame</code> <p>Dataframe with suggested new experiments (candidates)</p> required <code>only_inputs</code> <code>(bool, optional)</code> <p>If True, only the input columns are validated. Defaults to False.</p> <code>False</code> <code>tol</code> <code>(float, optional)</code> <p>tolerance parameter for constraints. A constraint is considered as not fulfilled if the violation is larger than tol. Defaults to 1e-6.</p> <code>1e-05</code> <code>raise_validation_error</code> <code>bool</code> <p>If true an error will be raised if candidates violate constraints, otherwise only a warning will be displayed. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>when a column is missing for a defined input feature</p> <code>ValueError</code> <p>when a column is missing for a defined output feature</p> <code>ValueError</code> <p>when a non-numerical value is proposed</p> <code>ValueError</code> <p>when an additional column is found</p> <code>ConstraintNotFulfilledError</code> <p>when the constraints are not fulfilled and <code>raise_validation_error = True</code></p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: dataframe with suggested experiments (candidates)</p> Source code in <code>bofire/data_models/domain/domain.py</code> <pre><code>def validate_candidates(\n    self,\n    candidates: pd.DataFrame,\n    only_inputs: bool = False,\n    tol: float = 1e-5,\n    raise_validation_error: bool = True,\n) -&gt; pd.DataFrame:\n    \"\"\"Method to check the validty of proposed candidates\n\n    Args:\n        candidates (pd.DataFrame): Dataframe with suggested new experiments (candidates)\n        only_inputs (bool,optional): If True, only the input columns are validated. Defaults to False.\n        tol (float,optional): tolerance parameter for constraints. A constraint is considered as not fulfilled if the violation\n            is larger than tol. Defaults to 1e-6.\n        raise_validation_error (bool, optional): If true an error will be raised if candidates violate constraints,\n            otherwise only a warning will be displayed. Defaults to True.\n\n    Raises:\n        ValueError: when a column is missing for a defined input feature\n        ValueError: when a column is missing for a defined output feature\n        ValueError: when a non-numerical value is proposed\n        ValueError: when an additional column is found\n        ConstraintNotFulfilledError: when the constraints are not fulfilled and `raise_validation_error = True`\n\n    Returns:\n        pd.DataFrame: dataframe with suggested experiments (candidates)\n\n    \"\"\"\n    # check that each input feature has a col and is valid in itself\n    assert isinstance(self.inputs, Inputs)\n    candidates = self.inputs.validate_candidates(candidates)\n    # check if all constraints are fulfilled\n    if not self.constraints.is_fulfilled(candidates, tol=tol).all():\n        if raise_validation_error:\n            raise ConstraintNotFulfilledError(\n                f\"Constraints not fulfilled: {candidates}\",\n            )\n        warnings.warn(\"Not all constraints are fulfilled.\")\n    # for each continuous output feature with an attached objective object\n    if not only_inputs:\n        assert isinstance(self.outputs, Outputs)\n        candidates = self.outputs.validate_candidates(candidates=candidates)\n    return candidates\n</code></pre>"},{"location":"ref-domain/#bofire.data_models.domain.domain.Domain.validate_constraints","title":"<code>validate_constraints()</code>","text":"<p>Validate that the constraints defined in the domain fit to the input features.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>List[Constraint]</code> <p>List of constraints or empty if no constraints are defined</p> required <code>values</code> <code>List[Input]</code> <p>List of input features of the domain</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>Feature key in constraint is unknown.</p> <p>Returns:</p> Type Description <p>List[Constraint]: List of constraints defined for the domain</p> Source code in <code>bofire/data_models/domain/domain.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_constraints(self):\n    \"\"\"Validate that the constraints defined in the domain fit to the input features.\n\n    Args:\n        v (List[Constraint]): List of constraints or empty if no constraints are defined\n        values (List[Input]): List of input features of the domain\n\n    Raises:\n        ValueError: Feature key in constraint is unknown.\n\n    Returns:\n        List[Constraint]: List of constraints defined for the domain\n\n    \"\"\"\n    for c in self.constraints.get():\n        c.validate_inputs(self.inputs)\n    return self\n</code></pre>"},{"location":"ref-domain/#bofire.data_models.domain.domain.Domain.validate_experiments","title":"<code>validate_experiments(experiments, strict=False)</code>","text":"<p>Checks the experimental data on validity</p> <p>Parameters:</p> Name Type Description Default <code>experiments</code> <code>DataFrame</code> <p>Dataframe with experimental data</p> required <code>strict</code> <code>bool</code> <p>Boolean to distinguish if the occurrence of fixed features in the dataset should be considered or not. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>empty dataframe</p> <code>ValueError</code> <p>the column for a specific feature is missing the provided data</p> <code>ValueError</code> <p>there are labcodes with null value</p> <code>ValueError</code> <p>there are labcodes with nan value</p> <code>ValueError</code> <p>labcodes are not unique</p> <code>ValueError</code> <p>the provided columns do no match to the defined domain</p> <code>ValueError</code> <p>the provided columns do no match to the defined domain</p> <code>ValueError</code> <p>Input with null values</p> <code>ValueError</code> <p>Input with nan values</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The provided dataframe with experimental data</p> Source code in <code>bofire/data_models/domain/domain.py</code> <pre><code>def validate_experiments(\n    self,\n    experiments: pd.DataFrame,\n    strict: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"Checks the experimental data on validity\n\n    Args:\n        experiments (pd.DataFrame): Dataframe with experimental data\n        strict (bool, optional): Boolean to distinguish if the occurrence of\n            fixed features in the dataset should be considered or not.\n            Defaults to False.\n\n    Raises:\n        ValueError: empty dataframe\n        ValueError: the column for a specific feature is missing the provided data\n        ValueError: there are labcodes with null value\n        ValueError: there are labcodes with nan value\n        ValueError: labcodes are not unique\n        ValueError: the provided columns do no match to the defined domain\n        ValueError: the provided columns do no match to the defined domain\n        ValueError: Input with null values\n        ValueError: Input with nan values\n\n    Returns:\n        pd.DataFrame: The provided dataframe with experimental data\n\n    \"\"\"\n    if len(experiments) == 0:\n        raise ValueError(\"no experiments provided (empty dataframe)\")\n\n    # we allow here for a column named labcode used to identify experiments\n    if \"labcode\" in experiments.columns:\n        # test that labcodes are not na\n        if experiments.labcode.isnull().to_numpy().any():\n            raise ValueError(\"there are labcodes with null value\")\n        if experiments.labcode.isna().to_numpy().any():\n            raise ValueError(\"there are labcodes with nan value\")\n        # test that labcodes are distinct\n        if (\n            len(set(experiments.labcode.to_numpy().tolist()))\n            != experiments.shape[0]\n        ):\n            raise ValueError(\"labcodes are not unique\")\n\n    # run the individual validators\n    experiments = self.inputs.validate_experiments(\n        experiments=experiments,\n        strict=strict,\n    )\n    experiments = self.outputs.validate_experiments(experiments=experiments)\n    return experiments\n</code></pre>"},{"location":"ref-domain/#bofire.data_models.domain.domain.Domain.validate_unique_feature_keys","title":"<code>validate_unique_feature_keys()</code>","text":"<p>Validates if provided input and output feature keys are unique</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>Outputs</code> <p>List of all output features of the domain.</p> required <code>value</code> <code>Dict[str, Inputs]</code> <p>Dict containing a list of input features as single entry.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>Feature keys are not unique.</p> <p>Returns:</p> Name Type Description <code>Outputs</code> <p>Keeps output features as given.</p> Source code in <code>bofire/data_models/domain/domain.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_unique_feature_keys(self):\n    \"\"\"Validates if provided input and output feature keys are unique\n\n    Args:\n        v (Outputs): List of all output features of the domain.\n        value (Dict[str, Inputs]): Dict containing a list of input features as single entry.\n\n    Raises:\n        ValueError: Feature keys are not unique.\n\n    Returns:\n        Outputs: Keeps output features as given.\n\n    \"\"\"\n    keys = self.outputs.get_keys() + self.inputs.get_keys()\n    if len(set(keys)) != len(keys):\n        raise ValueError(\"Feature keys are not unique\")\n    return self\n</code></pre>"},{"location":"ref-features/","title":"Domain","text":""},{"location":"ref-objectives/","title":"Domain","text":""},{"location":"ref-utils/","title":"Utils","text":""},{"location":"userguide_surrogates/","title":"Surrogate models","text":"<p>In Bayesian Optimization, information from previous experiments is taken into account to generate proposals for future experiments. This information is leveraged by creating a surrogate model for the black-box function that is to be optimized based on the available data. Naturally, experimental candidates for which the surrogate model makes a promising prediction (e.g., high predicted values of a quantity we want to maximize) should be chosen over ones for which this is not the case. However, since the available data might cover only a small part of the input space, the model is likely to only be able to make very uncertain predictions far away from the data. Therefore, the surrogate model should be able to express the degree to which the predictions are uncertain so that we can use this information - combining the prediction and the associated uncertainty - to select the settings for the next experimental iteration.</p> <p>The acquisition function is the object that turns the predicted distribution (you can think of this as the prediction and the prediction uncertainty) into a single quantity representing how promising a candidate experimental point seems. This function determines if one rather wants to focus on exploitation, i.e., quickly approaching a close local optimum of the black-box function, or on exploration, i.e., exploring different regions of the input space first.</p> <p>Therefore, three criteria typically determine whether any candidate is selected as experimental proposal: the value of the surrogate model, the uncertainty of the model, and the acquisition function.</p>"},{"location":"userguide_surrogates/#surrogate-model-options","title":"Surrogate model options","text":"<p>BoFire offers the following classes of surrogate models.</p> Surrogate Optimization of When to use Type SingleTaskGPSurrogate a single objective with real valued inputs Limited data and black-box function is smooth Gaussian process RandomForestSurrogate a single objective Rich data; black-box function does not have to be smooth sklearn random forest implementation MLP a single objective with real-valued inputs Rich data and black-box function is smooth Multi layer perceptron MixedSingleTaskGPSurrogate a single objective with categorical and real valued inputs Limited data and black-box function is smooth Gaussian process XGBoostSurrogate a single objective Rich data; black-box function does not have to be smooth xgboost implementation of gradient boosting trees TanimotoGP a single objective At least one input feature is a molecule represented as fingerprint Gaussian process on a molecule space for which Tanimoto similarity determines the similarity between points <p>All of these are single-objective surrogate models. For optimization of multiple objectives at the same time, a suitable Strategy has to be chosen. Then for each objective a different surrogate model can be specified. By default the SingleTaskGPSurrogate is used.</p> <p>Example:</p> <pre><code>surrogate_data_0 = SingleTaskGPSurrogate(\n        inputs=domain.inputs,\n        outputs=Outputs(features=[domain.outputs[0]]),\n)\nsurrogate_data_1 = XGBoostSurrogate(\n    inputs=domain.inputs,\n    outputs=Outputs(features=[domain.outputs[1]]),\n)\nqparego_data_model = QparegoStrategy(\n    domain=domain,\n    surrogate_specs=BotorchSurrogates(\n        surrogates=[surrogate_data_0, surrogate_data_1]\n    ),\n)\n</code></pre> <p>Note:</p> <ul> <li>The standard Kernel for all Gaussian Process (GP) surrogates is a 5/2 matern kernel with automated relevance detection and normalization of the input features.</li> <li>The tree-based models (RandomForestSurrogate and XGBoostSurrogate) do not have kernels but quantify uncertainty using the standard deviation of the predictions of their individual trees.</li> <li>MLP quantifies uncertainty using the standard deviation of multiple predictions that come from different dropout rates (randomly setting neural network weights to zero).</li> </ul>"},{"location":"userguide_surrogates/#customization","title":"Customization","text":"<p>BoFire also offers the option to customize surrogate models. In particular, it is possible to customize the SingleTaskGPSurrogate in the following ways.</p>"},{"location":"userguide_surrogates/#kernel-customization","title":"Kernel customization","text":"<p>Specify the Kernel:</p> Kernel Description Translation invariant Input variable type RBFKernel Based on Gaussian distribution Yes Continuous MaternKernel Based on Gamma function; allows setting a smoothness parameter Yes Continuous PolynomialKernel Based on dot-product of two vectors of input points No Continuous LinearKernel Equal to dot-product of two vectors of input points No Continuous TanimotoKernel Measures similarities between binary vectors using Tanimoto Similarity Not applicable MolecularInput HammingDistanceKernel Similarity is defined by the Hamming distance which considers the number of equal entries between two vectors (e.g., in One-Hot-encoding) Not applicable Categorical <p>Translational invariance means that the similarity between two input points is not affected by shifting both points by the same amount but only determined by their distance. Example: with a translationally invariant kernel, the values 10 and 20 are equally similar to each other as the values 20 and 30, while with a polynomial kernel the latter pair has potentially higher similarity. Polynomial kernels are often suitable for high-dimensional inputs while for low-dimensional inputs an RBF or Mat\u00e9rn kernel is recommended.</p> <p>Note:</p> <ul> <li>SingleTaskGPSurrogate with PolynomialKernel is equivalent to PolynomialSurrogate.</li> <li>SingleTaskGPSurrogate with LinearKernel is equivalent to LinearSurrogate.</li> <li>SingleTaskGPSurrogate with TanimotoKernel is equivalent to TanimotoGP.</li> <li>One can combine two Kernels by using AdditiveKernel or MultiplicativeKernel.</li> </ul> <p>Example:</p> <pre><code>surrogate_data_0 = SingleTaskGPSurrogate(\n        inputs=domain.inputs,\n        outputs=Outputs(features=[domain.outputs[0]]),\n        kernel=PolynomialKernel(power=2)\n)\n</code></pre>"},{"location":"userguide_surrogates/#noise-model-customization","title":"Noise model customization","text":"<p>For experimental data subject to noise, one can specify the distribution of this noise. The options are:</p> Noise Model When to use NormalPrior Noise is Gaussian GammaPrior Noise has a Gamma distribution <p>Example:</p> <pre><code>surrogate_data_0 = SingleTaskGPSurrogate(\n        inputs=domain.inputs,\n        outputs=Outputs(features=[domain.outputs[0]]),\n        kernel=PolynomialKernel(power=2),\n        noise_prior=NormalPrior(loc=0, scale=1)\n)\n</code></pre>"}]}