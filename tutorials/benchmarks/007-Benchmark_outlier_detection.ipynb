{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "papermill": {
     "duration": 0.006984,
     "end_time": "2024-10-10T20:35:08.196742",
     "exception": false,
     "start_time": "2024-10-10T20:35:08.189758",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Outlier detection benchmark\n",
    "\n",
    "Tutorial for benchmarking Robust Iterative trimming GP that detects outliers. It is benchmarked against standard GP and Student-t GP. Here, we compare on neal dataset.\n",
    "The idea is adapted from https://www.sciencedirect.com/science/article/pii/S2213133721000378?via%3Dihub. Their code is available at https://github.com/syrte/robustgp/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "papermill": {
     "duration": 0.001621,
     "end_time": "2024-10-10T20:35:08.202348",
     "exception": false,
     "start_time": "2024-10-10T20:35:08.200727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "papermill": {
     "duration": 2.847944,
     "end_time": "2024-10-10T20:35:11.051779",
     "exception": false,
     "start_time": "2024-10-10T20:35:08.203835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import os\n",
    "from typing import Annotated, Dict, Literal, Optional\n",
    "\n",
    "import botorch\n",
    "import dill\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.likelihoods import StudentTLikelihood\n",
    "from gpytorch.mlls import VariationalELBO\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "from pydantic import Extra, Field\n",
    "from scipy.stats import norm, t, uniform\n",
    "\n",
    "import bofire.kernels.api as kernels\n",
    "import bofire.outlier_detection.api as outlier_mapper\n",
    "import bofire.priors.api as priors\n",
    "import bofire.surrogates.api as surrogate_mapper\n",
    "from bofire.data_models.domain.api import Inputs, Outputs\n",
    "from bofire.data_models.enum import OutputFilteringEnum\n",
    "from bofire.data_models.features.api import ContinuousInput, ContinuousOutput\n",
    "from bofire.data_models.kernels.api import (\n",
    "    AnyKernel,\n",
    "    MaternKernel,\n",
    "    RBFKernel,\n",
    "    ScaleKernel,\n",
    ")\n",
    "from bofire.data_models.outlier_detection.api import IterativeTrimming\n",
    "from bofire.data_models.priors.api import (\n",
    "    THREESIX_LENGTHSCALE_PRIOR,\n",
    "    THREESIX_NOISE_PRIOR,\n",
    "    THREESIX_SCALE_PRIOR,\n",
    "    AnyPrior,\n",
    ")\n",
    "from bofire.data_models.surrogates.api import ScalerEnum, SingleTaskGPSurrogate\n",
    "from bofire.data_models.surrogates.botorch import BotorchSurrogate as BotorchSurrogateDM\n",
    "from bofire.surrogates.botorch import BotorchSurrogate\n",
    "from bofire.surrogates.single_task_gp import get_scaler\n",
    "from bofire.surrogates.trainable import TrainableSurrogate\n",
    "from bofire.utils.torch_tools import tkwargs\n",
    "\n",
    "\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "papermill": {
     "duration": 0.001506,
     "end_time": "2024-10-10T20:35:11.055200",
     "exception": false,
     "start_time": "2024-10-10T20:35:11.053694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Class for Student-t GP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "papermill": {
     "duration": 0.015305,
     "end_time": "2024-10-10T20:35:11.071970",
     "exception": false,
     "start_time": "2024-10-10T20:35:11.056665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataModel(BotorchSurrogateDM):\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "        extra = Extra.allow\n",
    "\n",
    "    type: Literal[\"SingleTaskVariationalGPSurrogate\"] = (\n",
    "        \"SingleTaskVariationalGPSurrogate\"\n",
    "    )\n",
    "    num_outputs: Annotated[int, Field(ge=1)] = 1\n",
    "    kernel: AnyKernel = Field(\n",
    "        default_factory=lambda: ScaleKernel(\n",
    "            base_kernel=MaternKernel(\n",
    "                ard=True,\n",
    "                nu=2.5,\n",
    "                lengthscale_prior=THREESIX_LENGTHSCALE_PRIOR(),\n",
    "            ),\n",
    "            outputscale_prior=THREESIX_SCALE_PRIOR(),\n",
    "        )\n",
    "    )\n",
    "    noise_prior: AnyPrior = Field(default_factory=lambda: THREESIX_NOISE_PRIOR())\n",
    "    scaler: ScalerEnum = ScalerEnum.NORMALIZE\n",
    "\n",
    "    @classmethod\n",
    "    def is_output_implemented(cls, my_type) -> bool:\n",
    "        \"\"\"Abstract method to check output type for surrogate models\n",
    "        Args:\n",
    "            my_type: continuous or categorical output\n",
    "        Returns:\n",
    "            bool: True if the output type is valid for the surrogate chosen, False otherwise\n",
    "        \"\"\"\n",
    "        return isinstance(my_type, type(ContinuousOutput))\n",
    "\n",
    "\n",
    "class SingleTaskVariationalGPSurrogate(BotorchSurrogate, TrainableSurrogate):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_model: DataModel,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.kernel = data_model.kernel\n",
    "        self.scaler = data_model.scaler\n",
    "        self.noise_prior = data_model.noise_prior\n",
    "        self.num_outputs = data_model.num_outputs\n",
    "        super().__init__(data_model=data_model, **kwargs)\n",
    "\n",
    "    model: Optional[botorch.models.SingleTaskVariationalGP] = None\n",
    "    _output_filtering: OutputFilteringEnum = OutputFilteringEnum.ALL\n",
    "    training_specs: Dict = {}\n",
    "\n",
    "    def _fit(self, X: pd.DataFrame, Y: pd.DataFrame):\n",
    "        scaler = get_scaler(self.inputs, self.input_preprocessing_specs, self.scaler, X)\n",
    "        transformed_X = self.inputs.transform(X, self.input_preprocessing_specs)\n",
    "\n",
    "        tX, tY = (\n",
    "            torch.from_numpy(transformed_X.values).to(**tkwargs),\n",
    "            torch.from_numpy(Y.values).to(**tkwargs),\n",
    "        )\n",
    "        self.output_transform = Standardize(m=tY.shape[-1])\n",
    "        tY, _ = self.output_transform(tY)\n",
    "        self.model = botorch.models.SingleTaskVariationalGP(  # type: ignore\n",
    "            train_X=tX,\n",
    "            train_Y=tY,\n",
    "            likelihood=StudentTLikelihood(noise_prior=priors.map(self.noise_prior)),\n",
    "            num_outputs=self.num_outputs,\n",
    "            learn_inducing_points=False,\n",
    "            inducing_points=tX,\n",
    "            covar_module=kernels.map(\n",
    "                self.kernel,\n",
    "                batch_shape=torch.Size(),\n",
    "                active_dims=list(range(tX.shape[1])),\n",
    "                ard_num_dims=1,  # this keyword is ignored\n",
    "                features_to_idx_mapper=lambda feats: self.inputs.get_feature_indices(\n",
    "                    self.input_preprocessing_specs, feats\n",
    "                ),\n",
    "            ),\n",
    "            # outcome_transform=Standardize(m=tY.shape[-1]),\n",
    "            input_transform=scaler,\n",
    "        )\n",
    "\n",
    "        # self.model.likelihood.noise_covar.noise_prior = priors.map(self.noise_prior)  # type: ignore\n",
    "\n",
    "        mll = VariationalELBO(\n",
    "            self.model.likelihood,\n",
    "            self.model.model,\n",
    "            num_data=tX.shape[-2],\n",
    "        )\n",
    "        fit_gpytorch_mll(mll, options=self.training_specs, max_attempts=10)\n",
    "\n",
    "    def _predict(self, transformed_X: pd.DataFrame):\n",
    "        # transform to tensor\n",
    "        X = torch.from_numpy(transformed_X.values).to(**tkwargs)\n",
    "        self.model.model.eval()  # type: ignore\n",
    "        self.model.likelihood.eval()  # type: ignore\n",
    "        with torch.no_grad() and gpytorch.settings.num_likelihood_samples(128):\n",
    "            preds = (\n",
    "                self.model.posterior(X=X, observation_noise=True)\n",
    "                .mean.mean(dim=0)\n",
    "                .cpu()\n",
    "                .detach()\n",
    "            )  # type: ignore\n",
    "            variance = (\n",
    "                self.model.posterior(X=X, observation_noise=True)\n",
    "                .variance.mean(dim=0)\n",
    "                .cpu()\n",
    "                .detach()\n",
    "            )  # type: ignore\n",
    "\n",
    "            preds, variance = self.output_transform.untransform(preds, variance)\n",
    "            preds = preds.numpy()\n",
    "            stds = np.sqrt(variance.numpy())  # type: ignore\n",
    "        return preds, stds\n",
    "\n",
    "    def _dumps(self) -> str:\n",
    "        \"\"\"Dumps the actual model to a string via pickle as this is not directly json serializable.\"\"\"\n",
    "        buffer = io.BytesIO()\n",
    "        torch.save(\n",
    "            {\"model\": self.model, \"output_transform\": self.output_transform},\n",
    "            buffer,\n",
    "            pickle_module=dill,\n",
    "        )\n",
    "        return base64.b64encode(buffer.getvalue()).decode()\n",
    "\n",
    "    def loads(self, data: str):\n",
    "        \"\"\"Loads the actual model from a base64 encoded pickle bytes object and writes it to the `model` attribute.\"\"\"\n",
    "        buffer = io.BytesIO(base64.b64decode(data.encode()))\n",
    "        path = torch.load(buffer, pickle_module=dill)\n",
    "        self.model = path[\"model\"]\n",
    "        self.output_transform = path[\"output_transform\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "papermill": {
     "duration": 0.001559,
     "end_time": "2024-10-10T20:35:11.075304",
     "exception": false,
     "start_time": "2024-10-10T20:35:11.073745",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## set up inputs, outputs and surrogate models for different GPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "papermill": {
     "duration": 0.004833,
     "end_time": "2024-10-10T20:35:11.081633",
     "exception": false,
     "start_time": "2024-10-10T20:35:11.076800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = Inputs(\n",
    "    features=[\n",
    "        ContinuousInput(\n",
    "            key=f\"x_{1}\",\n",
    "            bounds=(-3, 3),\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "outputs = Outputs(features=[ContinuousOutput(key=\"y\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "papermill": {
     "duration": 0.004156,
     "end_time": "2024-10-10T20:35:11.087399",
     "exception": false,
     "start_time": "2024-10-10T20:35:11.083243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kernel = ScaleKernel(base_kernel=RBFKernel(ard=True))\n",
    "scaler = ScalerEnum.NORMALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "papermill": {
     "duration": 0.005224,
     "end_time": "2024-10-10T20:35:11.094336",
     "exception": false,
     "start_time": "2024-10-10T20:35:11.089112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_GP = SingleTaskGPSurrogate(\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    kernel=kernel,\n",
    "    scaler=scaler,\n",
    ")\n",
    "model_GP = surrogate_mapper.map(model_GP)\n",
    "\n",
    "\n",
    "model_tP = DataModel(inputs=inputs, outputs=outputs, kernel=kernel, scaler=scaler)\n",
    "model_tP = SingleTaskVariationalGPSurrogate(data_model=model_tP)\n",
    "\n",
    "\n",
    "model_ideal_GP = SingleTaskGPSurrogate(\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    kernel=kernel,\n",
    "    scaler=scaler,\n",
    ")\n",
    "model_ideal_GP = surrogate_mapper.map(model_ideal_GP)\n",
    "\n",
    "\n",
    "model_ITGP = SingleTaskGPSurrogate(\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    kernel=kernel,\n",
    "    scaler=scaler,\n",
    ")\n",
    "model_ITGP_final = SingleTaskGPSurrogate(\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    kernel=kernel,\n",
    "    scaler=scaler,\n",
    ")\n",
    "model_ITGP_final = surrogate_mapper.map(model_ITGP_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "papermill": {
     "duration": 0.004286,
     "end_time": "2024-10-10T20:35:11.100260",
     "exception": false,
     "start_time": "2024-10-10T20:35:11.095974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ITGP_detector = IterativeTrimming(base_gp=model_ITGP)\n",
    "ITGP_detector = outlier_mapper.map(ITGP_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "papermill": {
     "duration": 0.001559,
     "end_time": "2024-10-10T20:35:11.103380",
     "exception": false,
     "start_time": "2024-10-10T20:35:11.101821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Neal dataset\n",
    "We create neal dataset for benchmarking from the paper  https://www.sciencedirect.com/science/article/pii/S2213133721000378?via%3Dihub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "papermill": {
     "duration": 0.006263,
     "end_time": "2024-10-10T20:35:11.111200",
     "exception": false,
     "start_time": "2024-10-10T20:35:11.104937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def neal_func(x):\n",
    "    return 0.3 + 0.4 * x + 0.5 * np.sin(2.7 * x) + 1.1 / (1 + x**2)\n",
    "\n",
    "\n",
    "def neal_dataset(\n",
    "    n=100,\n",
    "    s1=0.1,\n",
    "    s2=1,\n",
    "    m2=0,\n",
    "    f2=0.15,\n",
    "    t2=\"n\",\n",
    "    sampling=\"rand\",\n",
    "    **args_extra,\n",
    "):\n",
    "    n2 = int(n * f2)\n",
    "    n1 = n - n2\n",
    "\n",
    "    if sampling == \"randn\":\n",
    "        x = np.random.randn(n)\n",
    "    elif sampling == \"rand\":\n",
    "        x = np.random.rand(n) * 6 - 3\n",
    "    elif sampling == \"grid\":\n",
    "        x = np.linspace(-3, 3, n)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    y_tr = neal_func(x)\n",
    "\n",
    "    y_ob = np.zeros(n)\n",
    "    label = np.zeros(n, dtype=int)\n",
    "\n",
    "    ix1 = np.zeros(n, dtype=bool)\n",
    "    ix1[np.random.choice(n, n1, replace=False)] = True\n",
    "    ix2 = ~ix1\n",
    "\n",
    "    y_ob[ix1] = y_tr[ix1] + norm(0, s1).rvs(n1)\n",
    "    if t2 == \"n\":\n",
    "        y_ob[ix2] = y_tr[ix2] + norm(m2, s2).rvs(n2)\n",
    "    elif t2 == \"t1\":\n",
    "        y_ob[ix2] = y_tr[ix2] + t(1, m2, s2).rvs(n2)\n",
    "    elif t2 == \"t3\":\n",
    "        y_ob[ix2] = y_tr[ix2] + t(3, m2, s2).rvs(n2)\n",
    "    elif t2 == \"u\":\n",
    "        y_ob[ix2] = uniform(m2, s2).rvs(n2)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    label[ix1] = 0\n",
    "    label[ix2] = 1\n",
    "\n",
    "    dic = {\"x\": x, \"y_ob\": y_ob, \"y_tr\": y_tr, \"label\": label}\n",
    "    return dic\n",
    "\n",
    "\n",
    "# np.random.seed(5)\n",
    "sample = 10 if not SMOKE_TEST else 1\n",
    "n = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "papermill": {
     "duration": 0.001655,
     "end_time": "2024-10-10T20:35:11.114651",
     "exception": false,
     "start_time": "2024-10-10T20:35:11.112996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Adding outliers\n",
    "We use 9 outlier noise conditions to test our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "papermill": {
     "duration": 0.005192,
     "end_time": "2024-10-10T20:35:11.121527",
     "exception": false,
     "start_time": "2024-10-10T20:35:11.116335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args_list = [\n",
    "    (\"zero\", {\"n\": n, \"s1\": 0.1, \"s2\": 1.0, \"m2\": 0, \"f2\": 0, \"t2\": \"n\"}),\n",
    "    (\"rare\", {\"n\": n, \"s1\": 0.1, \"s2\": 1.0, \"m2\": 0, \"f2\": 0.05, \"t2\": \"n\"}),\n",
    "    (\"fiducial\", {\"n\": n, \"s1\": 0.1, \"s2\": 1.0, \"m2\": 0, \"f2\": 0.15, \"t2\": \"n\"}),\n",
    "    (\"abundant\", {\"n\": n, \"s1\": 0.1, \"s2\": 1.0, \"m2\": 0, \"f2\": 0.45, \"t2\": \"n\"}),\n",
    "    (\"skewed\", {\"n\": n, \"s1\": 0.1, \"s2\": 1.0, \"m2\": 2, \"f2\": 0.15, \"t2\": \"n\"}),\n",
    "    (\"extreme\", {\"n\": n, \"s1\": 0.1, \"s2\": 5.0, \"m2\": 0, \"f2\": 0.15, \"t2\": \"n\"}),\n",
    "    (\"uniform\", {\"n\": n, \"s1\": 0.1, \"s2\": 6.0, \"m2\": -3, \"f2\": 0.3, \"t2\": \"u\"}),\n",
    "    (\"t3\", {\"n\": n, \"s1\": 0.1, \"s2\": 0.1, \"m2\": 0, \"f2\": 1, \"t2\": \"t3\"}),\n",
    "    (\"t1\", {\"n\": n, \"s1\": 0.1, \"s2\": 0.1, \"m2\": 0, \"f2\": 1, \"t2\": \"t1\"}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "papermill": {
     "duration": 0.376773,
     "end_time": "2024-10-10T20:35:11.500130",
     "exception": false,
     "start_time": "2024-10-10T20:35:11.123357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(10, 10))\n",
    "k = 0\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        d = neal_dataset(**args_list[k][1])\n",
    "        ax[i, j].scatter(\n",
    "            d[\"x\"],\n",
    "            d[\"y_ob\"],\n",
    "            facecolor=cm.tab20.colors[1],\n",
    "            edgecolor=cm.tab20.colors[0],\n",
    "            vmin=-0.5,\n",
    "            vmax=1.5,\n",
    "            s=5,\n",
    "            lw=0.5,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "        x = np.linspace(-3, 3, 51)\n",
    "        ax[i, j].plot(x, neal_func(x), \"k-\", lw=1.5, zorder=-1)\n",
    "        ax[i, j].set_ylim(-3.5, 3.5)\n",
    "        ax[i, j].text(0.7, 0.1, args_list[k][0], transform=ax[i, j].transAxes)\n",
    "        k = k + 1\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "papermill": {
     "duration": 0.002078,
     "end_time": "2024-10-10T20:35:11.504645",
     "exception": false,
     "start_time": "2024-10-10T20:35:11.502567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run fitting\n",
    "We use standard GP for dataset without outliers, standard GP for outliers, Iterative gp (ITGP) and student-t GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "papermill": {
     "duration": 0.182817,
     "end_time": "2024-10-10T20:35:11.689455",
     "exception": true,
     "start_time": "2024-10-10T20:35:11.506638",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_RMSE(y, y0):\n",
    "    return np.sqrt(np.mean((y - y0) ** 2))\n",
    "\n",
    "\n",
    "cols = [\n",
    "    \"zero\",\n",
    "    \"rare\",\n",
    "    \"fiducial\",\n",
    "    \"abundant\",\n",
    "    \"skewed\",\n",
    "    \"extreme\",\n",
    "    \"uniform\",\n",
    "    \"t3\",\n",
    "    \"t1\",\n",
    "]\n",
    "rmse_GP, rmse_ideal, rmse_ITGP, rmse_tP = (\n",
    "    pd.DataFrame(columns=cols),\n",
    "    pd.DataFrame(columns=cols),\n",
    "    pd.DataFrame(columns=cols),\n",
    "    pd.DataFrame(columns=cols),\n",
    ")\n",
    "test_data = neal_dataset(n=1000, s1=0, s2=0, m2=0, f2=0, sampling=\"grid\", mode=\"test\")\n",
    "test_experiments = pd.DataFrame()\n",
    "test_experiments[\"x_1\"] = test_data[\"x\"]\n",
    "test_experiments[\"y\"] = test_data[\"y_tr\"]\n",
    "\n",
    "for j in range(len(cols)):\n",
    "    GP, ideal_GP, ITGP, tP = [], [], [], []\n",
    "    for _ in range(sample):\n",
    "        train_data = neal_dataset(**args_list[j][1])\n",
    "        experiments = pd.DataFrame()\n",
    "        experiments[\"x_1\"] = train_data[\"x\"]\n",
    "        experiments[\"y\"] = train_data[\"y_ob\"]\n",
    "        experiments[\"valid_y\"] = 1\n",
    "        ideal_experiments = experiments.copy()\n",
    "        ideal_experiments.loc[train_data[\"label\"] == 1, \"valid_y\"] = 0\n",
    "        experiments_trimmed = ITGP_detector.detect(experiments)\n",
    "        model_GP.fit(experiments)\n",
    "        model_tP.fit(experiments)\n",
    "        GP_test = model_GP.predict(test_experiments)\n",
    "        tP_test = model_tP.predict(test_experiments)\n",
    "        if cols[j] != \"t3\" and cols[j] != \"t1\":\n",
    "            model_ideal_GP.fit(ideal_experiments)\n",
    "            ideal_GP_test = model_ideal_GP.predict(test_experiments)\n",
    "            ideal_GP.append(loss_RMSE(ideal_GP_test[\"y_pred\"], test_experiments[\"y\"]))\n",
    "        else:\n",
    "            ideal_GP.append(np.nan)\n",
    "        model_ITGP_final.fit(experiments_trimmed)\n",
    "        ITGP_test = model_ITGP_final.predict(test_experiments)\n",
    "\n",
    "        GP.append(loss_RMSE(GP_test[\"y_pred\"], test_experiments[\"y\"]))\n",
    "\n",
    "        ITGP.append(loss_RMSE(ITGP_test[\"y_pred\"], test_experiments[\"y\"]))\n",
    "\n",
    "        tP.append(loss_RMSE(tP_test[\"y_pred\"], test_experiments[\"y\"]))\n",
    "\n",
    "    rmse_GP[cols[j]] = np.array(GP) / 0.032\n",
    "    rmse_ideal[cols[j]] = np.array(ideal_GP) / 0.032\n",
    "    rmse_ITGP[cols[j]] = np.array(ITGP) / 0.032\n",
    "    rmse_tP[cols[j]] = np.array(tP) / 0.032"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Performance comparison\n",
    "Here we plot the performance comparison similar to fig 4 in paper  https://www.sciencedirect.com/science/article/pii/S2213133721000378?via%3Dihub. ITGP performs better than other GPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import ticker\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "\n",
    "# Define the groups\n",
    "groups = [\"GP\", \"ITGP\", \"Ideal\", \"t GP\"]\n",
    "\n",
    "datasets = [rmse_GP, rmse_ITGP, rmse_ideal, rmse_tP]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "# Set x-positions for boxes\n",
    "x_pos_range = np.arange(len(datasets)) / (len(datasets) - 1)\n",
    "x_pos = (x_pos_range * 0.5) + 0.75\n",
    "# Plot\n",
    "colours = [\"blue\", \"green\", \"red\", \"black\"]\n",
    "for i, data in enumerate(datasets):\n",
    "    bp = plt.boxplot(\n",
    "        np.array(data),\n",
    "        sym=\"\",  # whis=[0, 100],\n",
    "        widths=0.6 / len(datasets),\n",
    "        tick_labels=list(datasets[0]),\n",
    "        patch_artist=True,\n",
    "        positions=[x_pos[i] + j * 1 for j in range(len(data.T))],\n",
    "    )\n",
    "    k = i % len(colours)\n",
    "    for box in bp[\"boxes\"]:\n",
    "        box.set(facecolor=colours[k])\n",
    "    for element in [\"boxes\", \"fliers\", \"means\"]:\n",
    "        plt.setp(bp[element], color=colours[k])\n",
    "# Titles\n",
    "plt.title(\"Test case (n=100)\")\n",
    "plt.ylabel(\"RMSE/ 0.032\")\n",
    "# Axis ticks and labels\n",
    "plt.xticks(np.arange(len(list(datasets[0]))) + 1)\n",
    "plt.gca().xaxis.set_minor_locator(\n",
    "    ticker.FixedLocator(np.array(range(len(list(datasets[0])) + 1)) + 0.5),\n",
    ")\n",
    "plt.gca().tick_params(axis=\"x\", which=\"minor\", length=4)\n",
    "plt.gca().tick_params(axis=\"x\", which=\"major\", length=0)\n",
    "# Change the limits of the x-axis\n",
    "plt.xlim([0.5, len(list(datasets[0])) + 0.5])\n",
    "# plt.ylim(0.25,16)\n",
    "plt.yscale(\"log\", base=2)\n",
    "legend_elements = []\n",
    "for i in range(len(datasets)):\n",
    "    j = i % len(groups)\n",
    "    k = i % len(colours)\n",
    "    legend_elements.append(Patch(facecolor=colours[k], label=groups[j]))\n",
    "plt.legend(handles=legend_elements, fontsize=8)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.000931,
   "end_time": "2024-10-10T20:35:12.312449",
   "environment_variables": {},
   "exception": true,
   "parameters": {},
   "start_time": "2024-10-10T20:35:07.311518",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
