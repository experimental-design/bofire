{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "papermill": {
     "duration": 0.007193,
     "end_time": "2024-10-10T20:35:13.603877",
     "exception": false,
     "start_time": "2024-10-10T20:35:13.596684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Himmelblau Benchmark with outliers\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "papermill": {
     "duration": 3.140419,
     "end_time": "2024-10-10T20:35:16.748383",
     "exception": false,
     "start_time": "2024-10-10T20:35:13.607964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import bofire.strategies.api as strategies\n",
    "from bofire.benchmarks.benchmark import UniformOutlierPrior\n",
    "from bofire.benchmarks.single import Himmelblau\n",
    "from bofire.data_models.acquisition_functions.api import qLogEI\n",
    "from bofire.data_models.domain.api import Domain, Outputs\n",
    "from bofire.data_models.features.api import CategoricalInput\n",
    "from bofire.data_models.outlier_detection.api import (\n",
    "    IterativeTrimming,\n",
    "    OutlierDetections,\n",
    ")\n",
    "from bofire.data_models.strategies.api import RandomStrategy, SoboStrategy\n",
    "from bofire.data_models.surrogates.api import (\n",
    "    MixedSingleTaskGPSurrogate,\n",
    "    SingleTaskGPSurrogate,\n",
    ")\n",
    "from bofire.runners.api import run\n",
    "\n",
    "\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "papermill": {
     "duration": 0.001489,
     "end_time": "2024-10-10T20:35:16.751719",
     "exception": false,
     "start_time": "2024-10-10T20:35:16.750230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## sample set of Himmelblau example to start optimization\n",
    "we use the same set of example as initial data for comparison of three models. One case is where there is no outlier, while for other two models, we introduced outliers at a fixed probability. Using same initial example data helps us to compare the efficiency of outlier detection compared to the no outlier model that works on the dataset with no outliers. Further, using same sampled set with same outliers help starting both models with and without outlier detection from same value and we can see their evolution with iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "papermill": {
     "duration": 0.012394,
     "end_time": "2024-10-10T20:35:16.765597",
     "exception": false,
     "start_time": "2024-10-10T20:35:16.753203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample(domain):\n",
    "    datamodel = RandomStrategy(domain=domain)\n",
    "    sampler = strategies.map(data_model=datamodel)\n",
    "    sampled = sampler.ask(10)\n",
    "    return sampled\n",
    "\n",
    "\n",
    "def best(domain: Domain, experiments: pd.DataFrame) -> float:\n",
    "    return experiments.y.min()\n",
    "\n",
    "\n",
    "bo_results_set = []  # stores progress of model on data with no outliers (no outliers model)\n",
    "bo_results_outliers_set = []  # stores progress of model with no outlier detection on data with outliers (baseline model)\n",
    "bo_results_no_outliers_set = []  # stores progress of model with the outlier detection on data with outliers (our model)\n",
    "\n",
    "Benchmark = Himmelblau()\n",
    "sampled = sample(Benchmark.domain)\n",
    "sampled_xy = Benchmark.f(sampled, return_complete=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "papermill": {
     "duration": 0.001445,
     "end_time": "2024-10-10T20:35:16.768785",
     "exception": false,
     "start_time": "2024-10-10T20:35:16.767340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Adding outliers\n",
    "Here we show an example of adding outliers with uniform priors between range of 50 and 100. We consider three cases of outliers; outliers not outrageous with range of 50 to 100, outliers moderately outrageous with range of 500 to 1000 and outliers too outrageous with brange of 5000 to 10000. The model should detect the more outrageous outliers easily and vice versa. Here is an example of not outrageous outlier addition with a probability of 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "papermill": {
     "duration": 0.007811,
     "end_time": "2024-10-10T20:35:16.778005",
     "exception": false,
     "start_time": "2024-10-10T20:35:16.770194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Benchmark = Himmelblau(\n",
    "    outlier_rate=0.2,\n",
    "    outlier_prior=UniformOutlierPrior(bounds=(50, 100)),\n",
    ")  # not outrageous\n",
    "sampled_xy1 = Benchmark.f(sampled, return_complete=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "papermill": {
     "duration": 0.001468,
     "end_time": "2024-10-10T20:35:16.781245",
     "exception": false,
     "start_time": "2024-10-10T20:35:16.779777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Outliers not outrageous\n",
    "Now we run optimization to compare the three models for not outrageous outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "papermill": {
     "duration": 0.504179,
     "end_time": "2024-10-10T20:35:17.286857",
     "exception": true,
     "start_time": "2024-10-10T20:35:16.782678",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bo_results_set = []\n",
    "bo_results_outliers_set = []\n",
    "bo_results_no_outliers_set = []\n",
    "n_iterations = 10 if not SMOKE_TEST else 1\n",
    "\n",
    "\n",
    "def sobo_factory(domain: Domain):\n",
    "    return strategies.map(SoboStrategy(domain=domain, acquisition_function=qLogEI()))\n",
    "\n",
    "\n",
    "def sobo_factory_outlier(domain: Domain, outlier_detection_specs: OutlierDetections):\n",
    "    return strategies.map(\n",
    "        SoboStrategy(\n",
    "            domain=domain,\n",
    "            acquisition_function=qLogEI(),\n",
    "            outlier_detection_specs=outlier_detection_specs,\n",
    "            min_experiments_before_outlier_check=10,\n",
    "            frequency_check=2,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "for _kk in range(n_iterations):\n",
    "    Benchmark = Himmelblau()\n",
    "    sampled = sample(Benchmark.domain)\n",
    "    sampled_xy = Benchmark.f(sampled, return_complete=True)\n",
    "    random_results = run(\n",
    "        Himmelblau(),\n",
    "        strategy_factory=lambda domain: strategies.map(RandomStrategy(domain=domain)),\n",
    "        n_iterations=50,  # random strategy\n",
    "        metric=best,\n",
    "        initial_sampler=sampled_xy,\n",
    "        n_runs=1,\n",
    "        n_procs=1,\n",
    "    )\n",
    "\n",
    "    bo_results = run(\n",
    "        Himmelblau(),\n",
    "        strategy_factory=sobo_factory,\n",
    "        n_iterations=50 if not SMOKE_TEST else 1,\n",
    "        metric=best,\n",
    "        initial_sampler=sampled_xy,\n",
    "        n_runs=1,\n",
    "        n_procs=1,\n",
    "    )\n",
    "\n",
    "    Benchmark = Himmelblau(\n",
    "        outlier_rate=0.2,\n",
    "        outlier_prior=UniformOutlierPrior(bounds=(50, 100)),\n",
    "    )\n",
    "    sampled_xy1 = Benchmark.f(sampled, return_complete=True)\n",
    "\n",
    "    bo_results_outliers = run(\n",
    "        Benchmark,\n",
    "        strategy_factory=sobo_factory,\n",
    "        n_iterations=50 if not SMOKE_TEST else 1,\n",
    "        metric=best,\n",
    "        initial_sampler=sampled_xy1,\n",
    "        n_runs=1,\n",
    "        n_procs=1,\n",
    "    )\n",
    "\n",
    "    domain = Benchmark.domain\n",
    "\n",
    "    detectors = []\n",
    "    for output_feature in domain.outputs.get_keys():\n",
    "        if len(domain.inputs.get(CategoricalInput, exact=True)):\n",
    "            detectors.append(\n",
    "                IterativeTrimming(\n",
    "                    base_gp=MixedSingleTaskGPSurrogate(\n",
    "                        inputs=domain.inputs,\n",
    "                        outputs=Outputs(\n",
    "                            features=[domain.outputs.get_by_key(output_feature)],\n",
    "                        ),  # type: ignore\n",
    "                    ),\n",
    "                ),\n",
    "            )\n",
    "        else:\n",
    "            detectors.append(\n",
    "                IterativeTrimming(\n",
    "                    base_gp=SingleTaskGPSurrogate(\n",
    "                        inputs=domain.inputs,\n",
    "                        outputs=Outputs(\n",
    "                            features=[domain.outputs.get_by_key(output_feature)],\n",
    "                        ),  # type: ignore\n",
    "                    ),\n",
    "                ),\n",
    "            )\n",
    "    outlier_detection_specs = OutlierDetections(detectors=detectors)\n",
    "\n",
    "    bo_results_no_outliers = run(\n",
    "        Benchmark,\n",
    "        strategy_factory=partial(\n",
    "            sobo_factory_outlier,\n",
    "            outlier_detection_specs=outlier_detection_specs,\n",
    "        ),\n",
    "        n_iterations=50 if not SMOKE_TEST else 1,\n",
    "        metric=best,\n",
    "        initial_sampler=sampled_xy1,\n",
    "        n_runs=1,\n",
    "        n_procs=1,\n",
    "    )\n",
    "\n",
    "    bo_results_set.append(bo_results[0])\n",
    "    bo_results_outliers_set.append(bo_results_outliers[0])\n",
    "    bo_results_no_outliers_set.append(bo_results_no_outliers[0])\n",
    "\n",
    "## Collecting data evolution over iterations\n",
    "\n",
    "bo_results_itr = np.zeros((len(bo_results_set), 50))\n",
    "bo_results_outliers_itr = np.zeros((len(bo_results_set), 50))\n",
    "bo_results_no_outliers_itr = np.zeros((len(bo_results_set), 50))\n",
    "for i in range(len(bo_results_set)):\n",
    "    bo_results_itr[i] = bo_results_set[i][1].to_numpy()\n",
    "    bo_results_outliers_itr[i] = bo_results_outliers_set[i][1].to_numpy()\n",
    "    bo_results_no_outliers_itr[i] = bo_results_no_outliers_set[i][1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Performance of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not SMOKE_TEST:\n",
    "    plt.plot(bo_results_itr.mean(axis=0), color=\"red\", label=\"no outliers\")\n",
    "    plt.scatter(range(50), bo_results_itr.mean(axis=0), color=\"red\")\n",
    "    plt.fill_between(\n",
    "        range(50),\n",
    "        (bo_results_itr.mean(axis=0) - bo_results_itr.std(axis=0)),\n",
    "        (bo_results_itr.mean(axis=0) + bo_results_itr.std(axis=0)),\n",
    "        alpha=0.3,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    plt.plot(bo_results_outliers_itr.mean(axis=0), color=\"blue\", label=\"baseline\")\n",
    "    plt.scatter(range(50), bo_results_outliers_itr.mean(axis=0), color=\"blue\")\n",
    "    plt.fill_between(\n",
    "        range(50),\n",
    "        (bo_results_outliers_itr.mean(axis=0) - bo_results_outliers_itr.std(axis=0)),\n",
    "        (bo_results_outliers_itr.mean(axis=0) + bo_results_outliers_itr.std(axis=0)),\n",
    "        alpha=0.3,\n",
    "        color=\"blue\",\n",
    "    )\n",
    "    plt.plot(bo_results_no_outliers_itr.mean(axis=0), color=\"green\", label=\"ITGP model\")\n",
    "    plt.scatter(range(50), bo_results_no_outliers_itr.mean(axis=0), color=\"green\")\n",
    "    plt.fill_between(\n",
    "        range(50),\n",
    "        (\n",
    "            bo_results_no_outliers_itr.mean(axis=0)\n",
    "            - bo_results_no_outliers_itr.std(axis=0)\n",
    "        ),\n",
    "        (\n",
    "            bo_results_no_outliers_itr.mean(axis=0)\n",
    "            + bo_results_no_outliers_itr.std(axis=0)\n",
    "        ),\n",
    "        alpha=0.3,\n",
    "        color=\"green\",\n",
    "    )\n",
    "\n",
    "    plt.ylabel(\"function value\")\n",
    "    # plt.yscale('log',base=10)\n",
    "    plt.legend()\n",
    "    plt.title(\"outliers not outrageous\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Outliers moderately outrageous\n",
    "Now we run optimization to compare the three models for moderately outrageous outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bo_results_set = []\n",
    "bo_results_outliers_set = []\n",
    "bo_results_no_outliers_set = []\n",
    "n_iterations = 10 if not SMOKE_TEST else 1\n",
    "\n",
    "for _kk in range(n_iterations):\n",
    "    Benchmark = Himmelblau()\n",
    "    sampled = sample(Benchmark.domain)\n",
    "    sampled_xy = Benchmark.f(sampled, return_complete=True)\n",
    "    random_results = run(\n",
    "        Himmelblau(),\n",
    "        strategy_factory=lambda domain: strategies.map(RandomStrategy(domain=domain)),\n",
    "        n_iterations=50,  # random strategy\n",
    "        metric=best,\n",
    "        initial_sampler=sampled_xy,\n",
    "        n_runs=1,\n",
    "        n_procs=1,\n",
    "    )\n",
    "\n",
    "    bo_results = run(\n",
    "        Himmelblau(),\n",
    "        strategy_factory=sobo_factory,\n",
    "        n_iterations=50 if not SMOKE_TEST else 1,\n",
    "        metric=best,\n",
    "        initial_sampler=sampled_xy,\n",
    "        n_runs=1,\n",
    "        n_procs=1,\n",
    "    )\n",
    "\n",
    "    Benchmark = Himmelblau(\n",
    "        outlier_rate=0.2,\n",
    "        outlier_prior=UniformOutlierPrior(bounds=(500, 1000)),\n",
    "    )\n",
    "    sampled_xy1 = Benchmark.f(sampled, return_complete=True)\n",
    "\n",
    "    bo_results_outliers = run(\n",
    "        Benchmark,\n",
    "        strategy_factory=sobo_factory,\n",
    "        n_iterations=50 if not SMOKE_TEST else 1,\n",
    "        metric=best,\n",
    "        initial_sampler=sampled_xy1,\n",
    "        n_runs=1,\n",
    "        n_procs=1,\n",
    "    )\n",
    "\n",
    "    domain = Benchmark.domain\n",
    "    detectors = []\n",
    "    for output_feature in domain.outputs.get_keys():\n",
    "        if len(domain.inputs.get(CategoricalInput, exact=True)):\n",
    "            detectors.append(\n",
    "                IterativeTrimming(\n",
    "                    base_gp=MixedSingleTaskGPSurrogate(\n",
    "                        inputs=domain.inputs,\n",
    "                        outputs=Outputs(\n",
    "                            features=[domain.outputs.get_by_key(output_feature)],\n",
    "                        ),  # type: ignore\n",
    "                    ),\n",
    "                ),\n",
    "            )\n",
    "        else:\n",
    "            detectors.append(\n",
    "                IterativeTrimming(\n",
    "                    base_gp=SingleTaskGPSurrogate(\n",
    "                        inputs=domain.inputs,\n",
    "                        outputs=Outputs(\n",
    "                            features=[domain.outputs.get_by_key(output_feature)],\n",
    "                        ),  # type: ignore\n",
    "                    ),\n",
    "                ),\n",
    "            )\n",
    "    outlier_detection_specs = OutlierDetections(detectors=detectors)\n",
    "\n",
    "    bo_results_no_outliers = run(\n",
    "        Benchmark,\n",
    "        strategy_factory=partial(\n",
    "            sobo_factory_outlier,\n",
    "            outlier_detection_specs=outlier_detection_specs,\n",
    "        ),\n",
    "        n_iterations=50 if not SMOKE_TEST else 1,\n",
    "        metric=best,\n",
    "        initial_sampler=sampled_xy1,\n",
    "        n_runs=1,\n",
    "        n_procs=1,\n",
    "    )\n",
    "\n",
    "    bo_results_set.append(bo_results[0])\n",
    "    bo_results_outliers_set.append(bo_results_outliers[0])\n",
    "    bo_results_no_outliers_set.append(bo_results_no_outliers[0])\n",
    "\n",
    "## Collecting data evolution over iterations\n",
    "\n",
    "bo_results_itr = np.zeros((len(bo_results_set), 50))\n",
    "bo_results_outliers_itr = np.zeros((len(bo_results_set), 50))\n",
    "bo_results_no_outliers_itr = np.zeros((len(bo_results_set), 50))\n",
    "for i in range(len(bo_results_set)):\n",
    "    bo_results_itr[i] = bo_results_set[i][1].to_numpy()\n",
    "    bo_results_outliers_itr[i] = bo_results_outliers_set[i][1].to_numpy()\n",
    "    bo_results_no_outliers_itr[i] = bo_results_no_outliers_set[i][1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Performance of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not SMOKE_TEST:\n",
    "    plt.plot(bo_results_itr.mean(axis=0), color=\"red\", label=\"no outliers\")\n",
    "    plt.scatter(range(50), bo_results_itr.mean(axis=0), color=\"red\")\n",
    "    plt.fill_between(\n",
    "        range(50),\n",
    "        (bo_results_itr.mean(axis=0) - bo_results_itr.std(axis=0)),\n",
    "        (bo_results_itr.mean(axis=0) + bo_results_itr.std(axis=0)),\n",
    "        alpha=0.3,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    plt.plot(bo_results_outliers_itr.mean(axis=0), color=\"blue\", label=\"baseline\")\n",
    "    plt.scatter(range(50), bo_results_outliers_itr.mean(axis=0), color=\"blue\")\n",
    "    plt.fill_between(\n",
    "        range(50),\n",
    "        (bo_results_outliers_itr.mean(axis=0) - bo_results_outliers_itr.std(axis=0)),\n",
    "        (bo_results_outliers_itr.mean(axis=0) + bo_results_outliers_itr.std(axis=0)),\n",
    "        alpha=0.3,\n",
    "        color=\"blue\",\n",
    "    )\n",
    "    plt.plot(bo_results_no_outliers_itr.mean(axis=0), color=\"green\", label=\"ITGP model\")\n",
    "    plt.scatter(range(50), bo_results_no_outliers_itr.mean(axis=0), color=\"green\")\n",
    "    plt.fill_between(\n",
    "        range(50),\n",
    "        (\n",
    "            bo_results_no_outliers_itr.mean(axis=0)\n",
    "            - bo_results_no_outliers_itr.std(axis=0)\n",
    "        ),\n",
    "        (\n",
    "            bo_results_no_outliers_itr.mean(axis=0)\n",
    "            + bo_results_no_outliers_itr.std(axis=0)\n",
    "        ),\n",
    "        alpha=0.3,\n",
    "        color=\"green\",\n",
    "    )\n",
    "\n",
    "    plt.ylabel(\"function value\")\n",
    "    # plt.yscale('log',base=10)\n",
    "    plt.legend()\n",
    "    plt.title(\"outliers moderately outrageous\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Outliers too outrageous\n",
    "Now we run optimization to compare the three models for too outrageous outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bo_results_set = []\n",
    "bo_results_outliers_set = []\n",
    "bo_results_no_outliers_set = []\n",
    "n_iterations = 10 if not SMOKE_TEST else 1\n",
    "for _kk in range(n_iterations):\n",
    "    Benchmark = Himmelblau()\n",
    "    sampled = sample(Benchmark.domain)\n",
    "    sampled_xy = Benchmark.f(sampled, return_complete=True)\n",
    "    random_results = run(\n",
    "        Himmelblau(),\n",
    "        strategy_factory=lambda domain: strategies.map(RandomStrategy(domain=domain)),\n",
    "        n_iterations=50,  # random strategy\n",
    "        metric=best,\n",
    "        initial_sampler=sampled_xy,\n",
    "        n_runs=1,\n",
    "        n_procs=1,\n",
    "    )\n",
    "\n",
    "    bo_results = run(\n",
    "        Himmelblau(),\n",
    "        strategy_factory=sobo_factory,\n",
    "        n_iterations=50 if not SMOKE_TEST else 1,\n",
    "        metric=best,\n",
    "        initial_sampler=sampled_xy,\n",
    "        n_runs=1,\n",
    "        n_procs=1,\n",
    "    )\n",
    "\n",
    "    Benchmark = Himmelblau(\n",
    "        outlier_rate=0.2,\n",
    "        outlier_prior=UniformOutlierPrior(bounds=(5000, 10000)),\n",
    "    )\n",
    "    sampled_xy1 = Benchmark.f(sampled, return_complete=True)\n",
    "\n",
    "    bo_results_outliers = run(\n",
    "        Benchmark,\n",
    "        strategy_factory=sobo_factory,\n",
    "        n_iterations=50 if not SMOKE_TEST else 1,\n",
    "        metric=best,\n",
    "        initial_sampler=sampled_xy1,\n",
    "        n_runs=1,\n",
    "        n_procs=1,\n",
    "    )\n",
    "\n",
    "    domain = Benchmark.domain\n",
    "    detectors = []\n",
    "    for output_feature in domain.outputs.get_keys():\n",
    "        if len(domain.inputs.get(CategoricalInput, exact=True)):\n",
    "            detectors.append(\n",
    "                IterativeTrimming(\n",
    "                    base_gp=MixedSingleTaskGPSurrogate(\n",
    "                        inputs=domain.inputs,\n",
    "                        outputs=Outputs(\n",
    "                            features=[domain.outputs.get_by_key(output_feature)],\n",
    "                        ),  # type: ignore\n",
    "                    ),\n",
    "                ),\n",
    "            )\n",
    "        else:\n",
    "            detectors.append(\n",
    "                IterativeTrimming(\n",
    "                    base_gp=SingleTaskGPSurrogate(\n",
    "                        inputs=domain.inputs,\n",
    "                        outputs=Outputs(\n",
    "                            features=[domain.outputs.get_by_key(output_feature)],\n",
    "                        ),  # type: ignore\n",
    "                    ),\n",
    "                ),\n",
    "            )\n",
    "    outlier_detection_specs = OutlierDetections(detectors=detectors)\n",
    "\n",
    "    bo_results_no_outliers = run(\n",
    "        Benchmark,\n",
    "        strategy_factory=partial(\n",
    "            sobo_factory_outlier,\n",
    "            outlier_detection_specs=outlier_detection_specs,\n",
    "        ),\n",
    "        n_iterations=50 if not SMOKE_TEST else 1,\n",
    "        metric=best,\n",
    "        initial_sampler=sampled_xy1,\n",
    "        n_runs=1,\n",
    "        n_procs=1,\n",
    "    )\n",
    "\n",
    "    bo_results_set.append(bo_results[0])\n",
    "    bo_results_outliers_set.append(bo_results_outliers[0])\n",
    "    bo_results_no_outliers_set.append(bo_results_no_outliers[0])\n",
    "\n",
    "## Collecting data evolution over iterations\n",
    "\n",
    "bo_results_itr = np.zeros((len(bo_results_set), 50))\n",
    "bo_results_outliers_itr = np.zeros((len(bo_results_set), 50))\n",
    "bo_results_no_outliers_itr = np.zeros((len(bo_results_set), 50))\n",
    "for i in range(len(bo_results_set)):\n",
    "    bo_results_itr[i] = bo_results_set[i][1].to_numpy()\n",
    "    bo_results_outliers_itr[i] = bo_results_outliers_set[i][1].to_numpy()\n",
    "    bo_results_no_outliers_itr[i] = bo_results_no_outliers_set[i][1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Performance of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not SMOKE_TEST:\n",
    "    plt.plot(bo_results_itr.mean(axis=0), color=\"red\", label=\"no outliers\")\n",
    "    plt.scatter(range(50), bo_results_itr.mean(axis=0), color=\"red\")\n",
    "    plt.fill_between(\n",
    "        range(50),\n",
    "        (bo_results_itr.mean(axis=0) - bo_results_itr.std(axis=0)),\n",
    "        (bo_results_itr.mean(axis=0) + bo_results_itr.std(axis=0)),\n",
    "        alpha=0.3,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    plt.plot(bo_results_outliers_itr.mean(axis=0), color=\"blue\", label=\"baseline\")\n",
    "    plt.scatter(range(50), bo_results_outliers_itr.mean(axis=0), color=\"blue\")\n",
    "    plt.fill_between(\n",
    "        range(50),\n",
    "        (bo_results_outliers_itr.mean(axis=0) - bo_results_outliers_itr.std(axis=0)),\n",
    "        (bo_results_outliers_itr.mean(axis=0) + bo_results_outliers_itr.std(axis=0)),\n",
    "        alpha=0.3,\n",
    "        color=\"blue\",\n",
    "    )\n",
    "    plt.plot(bo_results_no_outliers_itr.mean(axis=0), color=\"green\", label=\"ITGP model\")\n",
    "    plt.scatter(range(50), bo_results_no_outliers_itr.mean(axis=0), color=\"green\")\n",
    "    plt.fill_between(\n",
    "        range(50),\n",
    "        (\n",
    "            bo_results_no_outliers_itr.mean(axis=0)\n",
    "            - bo_results_no_outliers_itr.std(axis=0)\n",
    "        ),\n",
    "        (\n",
    "            bo_results_no_outliers_itr.mean(axis=0)\n",
    "            + bo_results_no_outliers_itr.std(axis=0)\n",
    "        ),\n",
    "        alpha=0.3,\n",
    "        color=\"green\",\n",
    "    )\n",
    "\n",
    "    plt.ylabel(\"function value\")\n",
    "    # plt.yscale('log',base=10)\n",
    "    plt.legend()\n",
    "    plt.title(\"outliers too outrageous\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.184033,
   "end_time": "2024-10-10T20:35:19.909885",
   "environment_variables": {},
   "exception": true,
   "parameters": {},
   "start_time": "2024-10-10T20:35:12.725852",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
