{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "papermill": {
     "duration": 0.006592,
     "end_time": "2024-10-10T20:34:45.612403",
     "exception": false,
     "start_time": "2024-10-10T20:34:45.605811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DTLZ2 Benchmark\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "papermill": {
     "duration": 2.877548,
     "end_time": "2024-10-10T20:34:48.494020",
     "exception": false,
     "start_time": "2024-10-10T20:34:45.616472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import bofire.strategies.api as strategies\n",
    "from bofire.benchmarks.multi import DTLZ2\n",
    "from bofire.data_models.api import Domain, Inputs, Outputs\n",
    "from bofire.data_models.features.api import ContinuousInput, ContinuousOutput\n",
    "from bofire.data_models.objectives.api import MinimizeObjective\n",
    "from bofire.data_models.strategies.api import (\n",
    "    MoboStrategy,\n",
    "    QparegoStrategy,\n",
    "    RandomStrategy,\n",
    ")\n",
    "from bofire.runners.api import run\n",
    "from bofire.utils.multiobjective import compute_hypervolume\n",
    "\n",
    "\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "papermill": {
     "duration": 0.00141,
     "end_time": "2024-10-10T20:34:48.497362",
     "exception": false,
     "start_time": "2024-10-10T20:34:48.495952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Manual setup of the optimization domain\n",
    "\n",
    "The following cell shows how to manually setup the optimization problem in BoFire for didactic purposes. In the following the implemented benchmark module is then used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "papermill": {
     "duration": 0.006199,
     "end_time": "2024-10-10T20:34:48.504930",
     "exception": false,
     "start_time": "2024-10-10T20:34:48.498731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_features = Inputs(\n",
    "    features=[ContinuousInput(key=f\"x_{i}\", bounds=(0, 1)) for i in range(6)],\n",
    ")\n",
    "# here the minimize objective is used, if you want to maximize you have to use the maximize objective.\n",
    "output_features = Outputs(\n",
    "    features=[\n",
    "        ContinuousOutput(key=f\"f_{i}\", objective=MinimizeObjective(w=1.0))\n",
    "        for i in range(2)\n",
    "    ],\n",
    ")\n",
    "# no constraints are present so we can create the domain\n",
    "domain = Domain(inputs=input_features, outputs=output_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "papermill": {
     "duration": 0.001393,
     "end_time": "2024-10-10T20:34:48.507974",
     "exception": false,
     "start_time": "2024-10-10T20:34:48.506581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Random Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "papermill": {
     "duration": 0.324348,
     "end_time": "2024-10-10T20:34:48.833702",
     "exception": true,
     "start_time": "2024-10-10T20:34:48.509354",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample(domain):\n",
    "    datamodel = RandomStrategy(domain=domain)\n",
    "    sampler = strategies.map(data_model=datamodel)\n",
    "    sampled = sampler.ask(10)\n",
    "    return sampled\n",
    "\n",
    "\n",
    "def hypervolume(domain: Domain, experiments: pd.DataFrame) -> float:\n",
    "    return compute_hypervolume(domain, experiments, ref_point={\"f_0\": 1.1, \"f_1\": 1.1})\n",
    "\n",
    "\n",
    "random_results = run(\n",
    "    DTLZ2(dim=6),\n",
    "    strategy_factory=lambda domain: strategies.map(RandomStrategy(domain=domain)),\n",
    "    n_iterations=50 if not SMOKE_TEST else 1,\n",
    "    metric=hypervolume,\n",
    "    initial_sampler=sample,\n",
    "    n_runs=1,\n",
    "    n_procs=1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## MOBO Strategy\n",
    "### Automatic run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def strategy_factory(domain: Domain):\n",
    "    data_model = MoboStrategy(domain=domain, ref_point={\"f_0\": 1.1, \"f_1\": 1.1})\n",
    "    return strategies.map(data_model)\n",
    "\n",
    "\n",
    "results = run(\n",
    "    DTLZ2(dim=6),\n",
    "    strategy_factory=strategy_factory,\n",
    "    n_iterations=50 if not SMOKE_TEST else 1,\n",
    "    metric=hypervolume,\n",
    "    initial_sampler=sample,\n",
    "    n_runs=1,\n",
    "    n_procs=1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Manual setup\n",
    "\n",
    "#### Using the default Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we get the domain from the benchmark module, in real use case we have to build it on our own\n",
    "# make sure that the objective is set correctly\n",
    "domain = DTLZ2(dim=6).domain\n",
    "# we generate training data\n",
    "experiments = DTLZ2(dim=6).f(domain.inputs.sample(10), return_complete=True)\n",
    "# we setup the strategy\n",
    "# providing of a reference point is not mandatory but can help\n",
    "# the reference point has to be wrt to the assigned objective always worse than the points on the paretofront.\n",
    "data_model = MoboStrategy(domain=domain, ref_point={\"f_0\": 1.1, \"f_1\": 1.1})\n",
    "recommender = strategies.map(data_model=data_model)\n",
    "# we tell the strategy our historical data\n",
    "recommender.tell(experiments=experiments)\n",
    "# we ask for a new point to evaluate\n",
    "candidates = recommender.ask(candidate_count=1)\n",
    "# we show the candidate\n",
    "display(candidates)\n",
    "# this candidate has to be then provided to the benchmark function and evaluated and then told back to the optimizer to get the next candidate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Setup specific models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bofire.data_models.kernels.api import RBFKernel, ScaleKernel\n",
    "from bofire.data_models.surrogates.api import BotorchSurrogates, SingleTaskGPSurrogate\n",
    "\n",
    "\n",
    "# in this case you would use non default kernels for the different outputs\n",
    "# it is also possible to build the models for a subset of the complete features\n",
    "data_model = MoboStrategy(\n",
    "    domain=domain,\n",
    "    ref_point={\"f_0\": 1.1, \"f_1\": 1.1},\n",
    "    surrogate_specs=BotorchSurrogates(\n",
    "        surrogates=[\n",
    "            SingleTaskGPSurrogate(\n",
    "                inputs=domain.inputs,\n",
    "                outputs=Outputs(features=[domain.outputs[0]]),\n",
    "                kernel=ScaleKernel(base_kernel=RBFKernel(ard=True)),\n",
    "            ),\n",
    "            SingleTaskGPSurrogate(\n",
    "                inputs=domain.inputs,\n",
    "                outputs=Outputs(features=[domain.outputs[1]]),\n",
    "                kernel=ScaleKernel(base_kernel=RBFKernel(ard=False)),\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "recommender = strategies.map(data_model=data_model)\n",
    "# we tell the strategy our historical data\n",
    "recommender.tell(experiments=experiments)\n",
    "# we ask for a new point to evaluate\n",
    "candidates = recommender.ask(candidate_count=1)\n",
    "# we show the candidate\n",
    "display(candidates)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## QPAREGO Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_qparego = run(\n",
    "    DTLZ2(dim=6),\n",
    "    strategy_factory=lambda domain: strategies.map(QparegoStrategy(domain=domain)),\n",
    "    n_iterations=50 if not SMOKE_TEST else 1,\n",
    "    metric=hypervolume,\n",
    "    initial_sampler=sample,\n",
    "    n_runs=1,\n",
    "    n_procs=1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Performance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(results[0][0].f_0, results[0][0].f_1, label=\"qehvi\")\n",
    "ax.scatter(results_qparego[0][0].f_0, results_qparego[0][0].f_1, label=\"qparego\")\n",
    "ax.scatter(random_results[0][0].f_0, random_results[0][0].f_1, label=\"random\")\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlabel(\"f_0\")\n",
    "ax.set_ylabel(\"f_1\")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.725766,
   "end_time": "2024-10-10T20:34:51.455486",
   "environment_variables": {},
   "exception": true,
   "parameters": {},
   "start_time": "2024-10-10T20:34:44.729720",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
