{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "papermill": {
     "duration": 0.005701,
     "end_time": "2024-10-10T20:35:54.265955",
     "exception": false,
     "start_time": "2024-10-10T20:35:54.260254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "papermill": {
     "duration": 0.002595,
     "end_time": "2024-10-10T20:35:54.273132",
     "exception": false,
     "start_time": "2024-10-10T20:35:54.270537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Showcase of active learning in bofire. Active learning per definition focusses on fitting the model to the experimental observations best possible in an iterative manner reducing some kind of uncertainty. The ActiveLearningStrategy proposes a set of evaluation points that will gain the most information about the problem each iteration. Thus, an unknown black-box-function can be approximated without optimization. It represents an exploration-only strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "papermill": {
     "duration": 3.229388,
     "end_time": "2024-10-10T20:35:57.504196",
     "exception": false,
     "start_time": "2024-10-10T20:35:54.274808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "\n",
    "import bofire.strategies.api as strategies\n",
    "from bofire.benchmarks.api import GenericBenchmark\n",
    "from bofire.benchmarks.single import Himmelblau\n",
    "from bofire.data_models.api import Domain, Inputs, Outputs\n",
    "from bofire.data_models.features.api import ContinuousInput, ContinuousOutput\n",
    "from bofire.data_models.objectives.api import MinimizeObjective\n",
    "from bofire.data_models.strategies.api import RandomStrategy\n",
    "from bofire.runners.api import run\n",
    "\n",
    "\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "papermill": {
     "duration": 0.001621,
     "end_time": "2024-10-10T20:35:57.508002",
     "exception": false,
     "start_time": "2024-10-10T20:35:57.506381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1-D Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "papermill": {
     "duration": 0.001794,
     "end_time": "2024-10-10T20:35:57.511378",
     "exception": false,
     "start_time": "2024-10-10T20:35:57.509584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For a 1-D objective function. The Himmelblau benchmark is used.\n",
    "\\begin{equation}\n",
    "    f: \\mathbb{R}^2 \\rightarrow \\mathbb{R} \\quad | \\quadÂ f(x_1, x_2) = (x_1^2 + x_2 - 11)^2 + (x_1 + x_2^2) ^2\n",
    "\\end{equation}\n",
    "To start the active learning strategy we need to supply some initial data points to set up the Gaussian Regression Model in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "papermill": {
     "duration": 0.017059,
     "end_time": "2024-10-10T20:35:57.530124",
     "exception": false,
     "start_time": "2024-10-10T20:35:57.513065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "himmelblau = Himmelblau()\n",
    "\n",
    "\n",
    "def sample(domain: Domain):\n",
    "    datamodel = RandomStrategy(domain=domain)\n",
    "    sampler = strategies.map(data_model=datamodel)\n",
    "    sampled = sampler.ask(10)\n",
    "    return sampled\n",
    "\n",
    "\n",
    "initial_points = sample(domain=himmelblau.domain)\n",
    "initial_experiments = pd.concat([initial_points, himmelblau.f(initial_points)], axis=1)\n",
    "display(initial_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "papermill": {
     "duration": 0.001809,
     "end_time": "2024-10-10T20:35:57.534043",
     "exception": false,
     "start_time": "2024-10-10T20:35:57.532234",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### ActiveLearningStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "papermill": {
     "duration": 0.001855,
     "end_time": "2024-10-10T20:35:57.537853",
     "exception": false,
     "start_time": "2024-10-10T20:35:57.535998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The `ActiveLearningstrategy` can be set up just as other BO strategies implemented in bofire. Just take a look into the other tutorials. Basic calls are `ask()` to retrieve new evaluation candidates from the acquisition function and `tell()` to train the model with a new observation.\n",
    "\n",
    "Currently, the default active learning acquisition function implemented is `qNegIntegratedPosteriorVariance`. It focuses on minimizing the overall posterior variance by choosing a new candidate.\n",
    "\n",
    "The `ActiveLearningStrategy` uses Monte-Carlo-integration to evaluate the acquisition function. The number of integration nodes significantly influences the speed of the integration. These can be adjusted by changing the parameter `data_model.num_sobol_samples`. Note that a sample size representing a power of $2$ increases performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "papermill": {
     "duration": 0.19008,
     "end_time": "2024-10-10T20:35:57.729662",
     "exception": true,
     "start_time": "2024-10-10T20:35:57.539582",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Manual set up of ActiveLearning\n",
    "from bofire.data_models.acquisition_functions.api import qNegIntPosVar\n",
    "from bofire.data_models.strategies.api import ActiveLearningStrategy\n",
    "from bofire.data_models.surrogates.api import BotorchSurrogates, SingleTaskGPSurrogate\n",
    "\n",
    "\n",
    "af = qNegIntPosVar(\n",
    "    n_mc_samples=64,  # lower the number of monte carlo samples to improve speed\n",
    ")\n",
    "\n",
    "data_model = ActiveLearningStrategy(domain=himmelblau.domain, acquisition_function=af)\n",
    "recommender = strategies.map(data_model=data_model)\n",
    "recommender.tell(experiments=initial_experiments)\n",
    "candidates = recommender.ask(candidate_count=1)\n",
    "display(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running the active learning strategy\n",
    "max_iter = 20\n",
    "results = initial_experiments\n",
    "\n",
    "for _ in range(max_iter):\n",
    "    # run active learning strategy\n",
    "    X = recommender.ask(candidate_count=1)[himmelblau.domain.inputs.get_keys()]\n",
    "    Y = himmelblau.f(X)\n",
    "    XY = pd.concat([X, Y], axis=1)\n",
    "    recommender.tell(experiments=XY)  # pass new experimental data\n",
    "    results = pd.concat([results, XY], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running a random strategy for comparison\n",
    "def strategy_factory(domain: Domain):\n",
    "    data_model = RandomStrategy(domain=domain)\n",
    "    return strategies.map(data_model)\n",
    "\n",
    "\n",
    "random_results = run(\n",
    "    himmelblau,\n",
    "    strategy_factory=strategy_factory,\n",
    "    n_iterations=max_iter if not SMOKE_TEST else 1,\n",
    "    metric=lambda domain, experiments: 1.0,\n",
    "    initial_sampler=sample,\n",
    "    n_runs=1,\n",
    "    n_procs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "\n",
    "# contour plot of himmelblau\n",
    "def f(grid):\n",
    "    return (grid[0] ** 2 + grid[1] - 11) ** 2 + (grid[0] + grid[1] ** 2) ** 2\n",
    "\n",
    "\n",
    "X_grid = np.arange(-7, 7, 0.01)\n",
    "Y_grid = np.arange(-7, 7, 0.01)\n",
    "mesh = np.meshgrid(X_grid, Y_grid)\n",
    "Z = f(grid=mesh)\n",
    "levels = np.linspace(Z.min(), Z.max(), 6)\n",
    "\n",
    "\n",
    "ax[0].contourf(X_grid, Y_grid, Z, cmap=cm.viridis)\n",
    "ax[0].scatter(random_results[0][0].x_1, random_results[0][0].x_2, c=\"white\")\n",
    "ax[1].contourf(X_grid, Y_grid, Z, cmap=cm.viridis)\n",
    "ax[1].scatter(results.x_1, results.x_2, c=\"white\")\n",
    "\n",
    "ax[0].axis([-7, 7, -7, 7])\n",
    "ax[0].set_xlabel(\"$x_1$\")\n",
    "ax[1].set_xlabel(\"$x_1$\")\n",
    "ax[0].set_ylabel(\"$x_2$\")\n",
    "ax[0].set_title(\"random strategy\")\n",
    "ax[1].set_title(\"active learning strategy\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The plot shows the exploratory behavior of the `ActiveLearningStrategy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### 2-D (n-D) Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Now, we want to actively learn an objective function with a multi-dimensional output space. This is shown by an example function with $2$ output variables. For this, we again utilize the Himmelblau benchmark function and the Ackley function.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\bm{f}: \\mathbb{R}^2 \\rightarrow \\mathbb{R}^2   \\quad | \\quadÂ \n",
    "    \\bm{f}(x_1, x_2) = \n",
    "        \\begin{pmatrix}\n",
    "            (x_1^2 + x_2 - 11)^2 + (x_1 + x_2^2) ^2 \\\\\n",
    "            -20\\exp \\left[-0.2{\\sqrt {0.5\\left(x_1^{2}+x_2^{2}\\right)}}\\right]\n",
    "            -\\exp \\left[0.5\\left(\\cos 2\\pi x_1+\\cos 2\\pi x_2\\right)\\right]+e+20\n",
    "\n",
    "        \\end{pmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = Inputs(\n",
    "    features=[\n",
    "        ContinuousInput(key=\"x_1\", bounds=(-6, 6)),\n",
    "        ContinuousInput(key=\"x_2\", bounds=(-6, 6)),\n",
    "    ],\n",
    ")\n",
    "outputs = Outputs(\n",
    "    features=[\n",
    "        ContinuousOutput(key=\"f_0\", objective=MinimizeObjective()),\n",
    "        ContinuousOutput(key=\"f_1\", objective=MinimizeObjective()),\n",
    "    ],\n",
    ")\n",
    "domain = Domain(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "def benchmark_function(candidates):\n",
    "    f0 = (candidates[\"x_1\"] ** 2 + candidates[\"x_2\"] - 11) ** 2 + (\n",
    "        candidates[\"x_1\"] + candidates[\"x_2\"] ** 2\n",
    "    ) ** 2\n",
    "    f1 = -20 * np.exp(\n",
    "        -0.2 * np.sqrt(0.5 * (candidates[\"x_1\"] ** 2 + candidates[\"x_2\"] ** 2)),\n",
    "    ) + (\n",
    "        -np.exp(\n",
    "            0.5\n",
    "            * (\n",
    "                np.cos(2 * np.pi * candidates[\"x_1\"])\n",
    "                + np.cos(2 * np.pi * candidates[\"x_2\"])\n",
    "            ),\n",
    "        )\n",
    "        + np.exp(1)\n",
    "        + 20\n",
    "    )\n",
    "    return pd.DataFrame({\"f_0\": f0, \"f_1\": f1})\n",
    "\n",
    "\n",
    "function = GenericBenchmark(domain=domain, func=benchmark_function)\n",
    "initial_experiments = pd.concat(\n",
    "    [initial_points, function.f(candidates=initial_points)],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "For the multi-objective function we need to pass two models to the strategy as each individual output is represented by a separate model.\n",
    "By default, the `ActiveLearningStrategy` focusses on minimizing the negative integrated posterior variance of each model equally. To minimize the variances in a more specific way certain weights can be provided for each output feature. This can be done by passing a `dictionary` containing the individual weights for each output feature with its corresponding key to the parameter `weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Manual set up of ActiveLearning\n",
    "weights = {\n",
    "    \"f_0\": 0.4,\n",
    "    \"f_1\": 0.6,\n",
    "}\n",
    "# create an instance of the acquisition function with distinct weights\n",
    "af = qNegIntPosVar(weights=weights, n_mc_samples=16)\n",
    "\n",
    "data_model = ActiveLearningStrategy(\n",
    "    domain=domain,\n",
    "    surrogate_specs=BotorchSurrogates(\n",
    "        surrogates=[\n",
    "            SingleTaskGPSurrogate(\n",
    "                inputs=domain.inputs,\n",
    "                outputs=Outputs(features=[domain.outputs[0]]),\n",
    "            ),\n",
    "            SingleTaskGPSurrogate(\n",
    "                inputs=domain.inputs,\n",
    "                outputs=Outputs(features=[domain.outputs[1]]),\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    acquisition_function=af,\n",
    ")\n",
    "recommender = strategies.map(data_model=data_model)\n",
    "recommender.tell(experiments=initial_experiments)\n",
    "candidates = recommender.ask(candidate_count=1)\n",
    "display(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running the active learning strategy\n",
    "max_iter = 20\n",
    "results = initial_experiments\n",
    "\n",
    "for _ in range(max_iter):\n",
    "    # run active learning strategy\n",
    "    X = recommender.ask(candidate_count=1)[domain.inputs.get_keys()]\n",
    "    Y = function.f(candidates=X)\n",
    "    XY = pd.concat([X, Y], axis=1)\n",
    "    recommender.tell(experiments=XY)  # pass new experimental data\n",
    "    results = pd.concat([results, XY], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_results = run(\n",
    "    function,\n",
    "    strategy_factory=strategy_factory,\n",
    "    n_iterations=max_iter if not SMOKE_TEST else 1,\n",
    "    metric=lambda domain, experiments: 1.0,\n",
    "    initial_sampler=sample,\n",
    "    n_runs=1,\n",
    "    n_procs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 8)\n",
    "fig, ax = plt.subplots(2, 2)\n",
    "\n",
    "\n",
    "def f1(grid):\n",
    "    return (\n",
    "        -20 * np.exp(-0.2 * np.sqrt(0.5 * (grid[0] ** 2 + grid[1] ** 2)))\n",
    "        - np.exp(0.5 * (np.cos(2 * np.pi * grid[0]) + np.cos(2 * np.pi * grid[1])))\n",
    "        + np.exp(1)\n",
    "        + 20\n",
    "    )\n",
    "\n",
    "\n",
    "Z1 = f1(mesh)\n",
    "levels = np.linspace(Z1.min(), Z1.max(), 10)\n",
    "ax[0, 0].contourf(\n",
    "    X_grid,\n",
    "    Y_grid,\n",
    "    Z,\n",
    "    cmap=cm.viridis,\n",
    ")\n",
    "ax[0, 0].scatter(random_results[0][0].x_1, random_results[0][0].x_2, c=\"white\")\n",
    "ax[0, 1].contourf(\n",
    "    X_grid,\n",
    "    Y_grid,\n",
    "    Z,\n",
    "    cmap=cm.viridis,\n",
    ")\n",
    "ax[0, 1].scatter(results.x_1, results.x_2, c=\"white\")\n",
    "ax[1, 0].contourf(X_grid, Y_grid, Z1, cmap=cm.viridis, levels=levels)\n",
    "ax[1, 0].scatter(\n",
    "    random_results[0][0].x_1,\n",
    "    random_results[0][0].x_2,\n",
    "    c=\"white\",\n",
    "    edgecolors=\"black\",\n",
    ")\n",
    "ax[1, 1].contourf(X_grid, Y_grid, Z1, cmap=cm.viridis, levels=levels)\n",
    "ax[1, 1].scatter(results.x_1, results.x_2, c=\"white\", edgecolors=\"black\")\n",
    "\n",
    "ax[0, 0].axis([-7, 7, -7, 7])\n",
    "ax[1, 0].set_xlabel(\"$x_1$\")\n",
    "ax[1, 1].set_xlabel(\"$x_1$\")\n",
    "ax[0, 0].set_ylabel(\"$x_2$\")\n",
    "ax[1, 0].set_ylabel(\"$x_2$\")\n",
    "ax[0, 0].set_title(\"random strategy\")\n",
    "ax[0, 1].set_title(\"active learning strategy\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.075886,
   "end_time": "2024-10-10T20:35:58.452743",
   "environment_variables": {},
   "exception": true,
   "parameters": {},
   "start_time": "2024-10-10T20:35:53.376857",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
