{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building with BoFire\n",
    "\n",
    "This notebooks shows how to setup and analyze models trained with BoFire. It is stil WIP."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/bofire/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bofire.data_models.domain.api import Inputs, Outputs\n",
    "from bofire.data_models.surrogates.api import SingleTaskGPSurrogate, RandomForestSurrogate, MixedSingleTaskGPSurrogate, AnySurrogate, RandomForestSurrogate, EmpiricalSurrogate, MLPEnsemble\n",
    "from bofire.benchmarks.single import Himmelblau\n",
    "from bofire.benchmarks.multi import CrossCoupling\n",
    "import bofire.surrogates.api as surrogates\n",
    "import json\n",
    "from bofire.data_models.enum import CategoricalEncodingEnum\n",
    "\n",
    "from pydantic import parse_obj_as"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Setup\n",
    "\n",
    "For didactic purposes, we sample data from a Himmelblau benchmark function and use them to train a SingleTaskGP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y</th>\n",
       "      <th>valid_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.189148</td>\n",
       "      <td>-0.843587</td>\n",
       "      <td>142.329504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.548556</td>\n",
       "      <td>-2.351760</td>\n",
       "      <td>63.155820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.089940</td>\n",
       "      <td>-2.448055</td>\n",
       "      <td>154.706964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.870975</td>\n",
       "      <td>-3.246683</td>\n",
       "      <td>201.393531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.098456</td>\n",
       "      <td>5.981887</td>\n",
       "      <td>1587.949784</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.968824</td>\n",
       "      <td>3.817305</td>\n",
       "      <td>206.611937</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.432720</td>\n",
       "      <td>-3.051569</td>\n",
       "      <td>38.146483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-3.577077</td>\n",
       "      <td>0.099487</td>\n",
       "      <td>115.256187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.776818</td>\n",
       "      <td>5.169825</td>\n",
       "      <td>447.728824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.928474</td>\n",
       "      <td>-4.601601</td>\n",
       "      <td>440.418108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_1       x_2            y  valid_y\n",
       "0 -4.189148 -0.843587   142.329504        1\n",
       "1 -2.548556 -2.351760    63.155820        1\n",
       "2 -1.089940 -2.448055   154.706964        1\n",
       "3  0.870975 -3.246683   201.393531        1\n",
       "4  5.098456  5.981887  1587.949784        1\n",
       "5  3.968824  3.817305   206.611937        1\n",
       "6  3.432720 -3.051569    38.146483        1\n",
       "7 -3.577077  0.099487   115.256187        1\n",
       "8  0.776818  5.169825   447.728824        1\n",
       "9  4.928474 -4.601601   440.418108        1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = Himmelblau()\n",
    "samples = benchmark.domain.inputs.sample(n=50)\n",
    "experiments = benchmark.f(samples, return_complete=True)\n",
    "\n",
    "experiments.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = benchmark.domain.inputs\n",
    "output_features = benchmark.domain.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"unit\": null, \"bounds\": [-6.0, 6.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"unit\": null, \"bounds\": [-6.0, 6.0]}]}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"y\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}, \"unit\": null}]}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_features.json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Task GP\n",
    "\n",
    "Generate the json spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"SingleTaskGPSurrogate\", \"inputs\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"unit\": null, \"bounds\": [-6.0, 6.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"unit\": null, \"bounds\": [-6.0, 6.0]}]}, \"outputs\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"y\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}, \"unit\": null}]}, \"input_preprocessing_specs\": {}, \"dump\": null, \"kernel\": {\"type\": \"ScaleKernel\", \"base_kernel\": {\"type\": \"MaternKernel\", \"ard\": true, \"nu\": 2.5, \"lengthscale_prior\": {\"type\": \"GammaPrior\", \"concentration\": 3.0, \"rate\": 6.0}}, \"outputscale_prior\": {\"type\": \"GammaPrior\", \"concentration\": 2.0, \"rate\": 0.15}}, \"scaler\": \"NORMALIZE\"}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we setup the data model, here a Single Task GP\n",
    "surrogate_data = SingleTaskGPSurrogate(\n",
    "    inputs=input_features,\n",
    "    outputs=output_features\n",
    ")\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = surrogate_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load it from the spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_data = parse_obj_as(AnySurrogate, json.loads(jspec))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = surrogates.map(surrogate_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit it. This is not 100% finished. In the future we will call here hyperfit which will return the CV results etc. This has to be finished. So ignore this for now and just call fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.fit(experiments=experiments)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump it\n",
    "dump = surrogate.dumps()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with it\n",
    "df_predictions = surrogate.predict(experiments)\n",
    "# transform to spec\n",
    "predictions = surrogate.to_predictions(predictions=df_predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load again from spec and dump and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surrogate_data = parse_obj_as(AnySurrogate, json.loads(jspec))\n",
    "surrogate = surrogates.map(surrogate_data)\n",
    "surrogate.loads(dump)\n",
    "\n",
    "# predict with it\n",
    "df_predictions2 = surrogate.predict(experiments)\n",
    "# transform to spec\n",
    "predictions2 = surrogate.to_predictions(predictions=df_predictions2)\n",
    "\n",
    "# check for equality\n",
    "predictions==predictions2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Generate the json spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"RandomForestSurrogate\", \"inputs\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"unit\": null, \"bounds\": [-6.0, 6.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"unit\": null, \"bounds\": [-6.0, 6.0]}]}, \"outputs\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"y\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}, \"unit\": null}]}, \"input_preprocessing_specs\": {}, \"dump\": null, \"n_estimators\": 100, \"criterion\": \"squared_error\", \"max_depth\": null, \"min_samples_split\": 2, \"min_samples_leaf\": 1, \"min_weight_fraction_leaf\": 0.0, \"max_features\": 1.0, \"max_leaf_nodes\": null, \"min_impurity_decrease\": 0.0, \"bootstrap\": true, \"oob_score\": false, \"random_state\": 42, \"ccp_alpha\": 0.0, \"max_samples\": null}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we setup the data model, here a Single Task GP\n",
    "surrogate_data = RandomForestSurrogate(\n",
    "    inputs=input_features,\n",
    "    outputs=output_features,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = surrogate_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load it from the spec\n",
    "surrogate_data = parse_obj_as(AnySurrogate, json.loads(jspec))\n",
    "# Map it \n",
    "surrogate = surrogates.map(surrogate_data)\n",
    "# Fit it\n",
    "surrogate.fit(experiments=experiments)\n",
    "# dump it\n",
    "dump = surrogate.dumps()\n",
    "# predict with it\n",
    "df_predictions = surrogate.predict(experiments)\n",
    "# transform to spec\n",
    "predictions = surrogate.to_predictions(predictions=df_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surrogate_data = parse_obj_as(AnySurrogate, json.loads(jspec))\n",
    "surrogate = surrogates.map(surrogate_data)\n",
    "surrogate.loads(dump)\n",
    "\n",
    "# predict with it\n",
    "df_predictions2 = surrogate.predict(experiments)\n",
    "# transform to spec\n",
    "predictions2 = surrogate.to_predictions(predictions=df_predictions2)\n",
    "\n",
    "# check for equality\n",
    "predictions==predictions2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Ensemble\n",
    "\n",
    "Generate the json spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"MLPEnsemble\", \"inputs\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"unit\": null, \"bounds\": [-6.0, 6.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"unit\": null, \"bounds\": [-6.0, 6.0]}]}, \"outputs\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"y\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}, \"unit\": null}]}, \"input_preprocessing_specs\": {}, \"dump\": null, \"n_estimators\": 2, \"hidden_layer_sizes\": [100], \"activation\": \"relu\", \"dropout\": 0.0, \"batch_size\": 10, \"n_epochs\": 200, \"lr\": 0.0001, \"weight_decay\": 0.0, \"subsample_fraction\": 1.0, \"shuffle\": true, \"scaler\": \"NORMALIZE\"}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we setup the data model, here a Single Task GP\n",
    "surrogate_data = MLPEnsemble(\n",
    "    inputs=input_features,\n",
    "    outputs=output_features,\n",
    "    n_estimators=2\n",
    ")\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = surrogate_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/j30607/sandbox/botorch/botorch/models/model.py:212: RuntimeWarning: Could not update `train_inputs` with transformed inputs since _MLPEnsemble does not have a `train_inputs` attribute. Make sure that the `input_transform` is applied to both the train inputs and test inputs.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load it from the spec\n",
    "surrogate_data = parse_obj_as(AnySurrogate, json.loads(jspec))\n",
    "# Map it \n",
    "surrogate = surrogates.map(surrogate_data)\n",
    "# Fit it\n",
    "surrogate.fit(experiments=experiments)\n",
    "# dump it\n",
    "dump = surrogate.dumps()\n",
    "# predict with it\n",
    "df_predictions = surrogate.predict(experiments)\n",
    "# transform to spec\n",
    "predictions = surrogate.to_predictions(predictions=df_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/j30607/sandbox/botorch/botorch/models/model.py:212: RuntimeWarning: Could not update `train_inputs` with transformed inputs since _MLPEnsemble does not have a `train_inputs` attribute. Make sure that the `input_transform` is applied to both the train inputs and test inputs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surrogate_data = parse_obj_as(AnySurrogate, json.loads(jspec))\n",
    "surrogate = surrogates.map(surrogate_data)\n",
    "surrogate.loads(dump)\n",
    "\n",
    "# predict with it\n",
    "df_predictions2 = surrogate.predict(experiments)\n",
    "# transform to spec\n",
    "predictions2 = surrogate.to_predictions(predictions=df_predictions2)\n",
    "\n",
    "# check for equality\n",
    "predictions==predictions2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical Surrogate\n",
    "\n",
    "The empirical model is special as it has per default no fit and you need cloudpickle. There can be empirical models which implement a fit, but for this they also have to inherit from `Trainable`. The current example is the default without any fit functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models.deterministic import DeterministicModel\n",
    "from torch import Tensor\n",
    "\n",
    "class HimmelblauModel(DeterministicModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._num_outputs = 1\n",
    "\n",
    "    def forward(self, X: Tensor) -> Tensor:\n",
    "        return (\n",
    "            (X[..., 0] ** 2 + X[..., 1] - 11.0) ** 2\n",
    "            + (X[..., 0] + X[..., 1] ** 2 - 7.0) ** 2\n",
    "        ).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"EmpiricalSurrogate\", \"inputs\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"unit\": null, \"bounds\": [-6.0, 6.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"unit\": null, \"bounds\": [-6.0, 6.0]}]}, \"outputs\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"y\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}, \"unit\": null}]}, \"input_preprocessing_specs\": {}, \"dump\": null}'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we setup the data model, here a Single Task GP\n",
    "surrogate_data = EmpiricalSurrogate(\n",
    "    inputs=input_features,\n",
    "    outputs=output_features,\n",
    ")\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = surrogate_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load it from the spec\n",
    "surrogate_data = parse_obj_as(AnySurrogate, json.loads(jspec))\n",
    "# Map it \n",
    "surrogate = surrogates.map(surrogate_data)\n",
    "# attach the actual model to it\n",
    "surrogate.model = HimmelblauModel()\n",
    "# dump it\n",
    "dump = surrogate.dumps()\n",
    "# predict with it\n",
    "df_predictions = surrogate.predict(experiments)\n",
    "# transform to spec\n",
    "predictions = surrogate.to_predictions(predictions=df_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surrogate_data = parse_obj_as(AnySurrogate, json.loads(jspec))\n",
    "surrogate = surrogates.map(surrogate_data)\n",
    "surrogate.loads(dump)\n",
    "\n",
    "# predict with it\n",
    "df_predictions2 = surrogate.predict(experiments)\n",
    "# transform to spec\n",
    "predictions2 = surrogate.to_predictions(predictions=df_predictions2)\n",
    "\n",
    "# check for equality\n",
    "predictions==predictions2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed GP\n",
    "\n",
    "Generate the json spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for MixedSingleTaskGPSurrogate\ninput_preprocessing_specs\n  MixedSingleTaskGPSurrogate can only be used if at least one one-hot encoded categorical feature is present. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# we setup the data model, here a Single Task GP\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m surrogate_data \u001b[39m=\u001b[39m MixedSingleTaskGPSurrogate(\n\u001b[1;32m      3\u001b[0m     inputs\u001b[39m=\u001b[39;49minput_features,\n\u001b[1;32m      4\u001b[0m     outputs\u001b[39m=\u001b[39;49moutput_features,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[39m# we generate the json spec\u001b[39;00m\n\u001b[1;32m      8\u001b[0m jspec \u001b[39m=\u001b[39m surrogate_data\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/bofire/lib/python3.10/site-packages/pydantic/main.py:342\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for MixedSingleTaskGPSurrogate\ninput_preprocessing_specs\n  MixedSingleTaskGPSurrogate can only be used if at least one one-hot encoded categorical feature is present. (type=value_error)"
     ]
    }
   ],
   "source": [
    "# we setup the data model, here a Single Task GP\n",
    "surrogate_data = MixedSingleTaskGPSurrogate(\n",
    "    inputs=input_features,\n",
    "    outputs=output_features,\n",
    ")\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = surrogate_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected this fails, as we do not have any categorical feature in the dataset. So we have to setup another problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_eq</th>\n",
       "      <th>t_res</th>\n",
       "      <th>temperature</th>\n",
       "      <th>base</th>\n",
       "      <th>catalyst</th>\n",
       "      <th>yield</th>\n",
       "      <th>cost</th>\n",
       "      <th>valid_cost</th>\n",
       "      <th>valid_yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000929</td>\n",
       "      <td>640.729785</td>\n",
       "      <td>63.578259</td>\n",
       "      <td>DBU</td>\n",
       "      <td>AlPhos</td>\n",
       "      <td>0.860773</td>\n",
       "      <td>0.420104</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.848292</td>\n",
       "      <td>219.006008</td>\n",
       "      <td>91.659600</td>\n",
       "      <td>DBU</td>\n",
       "      <td>AlPhos</td>\n",
       "      <td>0.985511</td>\n",
       "      <td>0.421029</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.949376</td>\n",
       "      <td>239.685059</td>\n",
       "      <td>95.291403</td>\n",
       "      <td>DBU</td>\n",
       "      <td>tBuBrettPhos</td>\n",
       "      <td>1.001262</td>\n",
       "      <td>0.280399</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.215942</td>\n",
       "      <td>140.311163</td>\n",
       "      <td>95.770730</td>\n",
       "      <td>BTMG</td>\n",
       "      <td>tBuXPhos</td>\n",
       "      <td>0.942617</td>\n",
       "      <td>0.301352</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.401418</td>\n",
       "      <td>1076.142758</td>\n",
       "      <td>78.363599</td>\n",
       "      <td>TEA</td>\n",
       "      <td>tBuBrettPhos</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>0.278780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.205043</td>\n",
       "      <td>1047.478169</td>\n",
       "      <td>64.571328</td>\n",
       "      <td>DBU</td>\n",
       "      <td>tBuXPhos</td>\n",
       "      <td>0.788471</td>\n",
       "      <td>0.250647</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.011124</td>\n",
       "      <td>1434.620903</td>\n",
       "      <td>37.719431</td>\n",
       "      <td>BTMG</td>\n",
       "      <td>tBuXPhos</td>\n",
       "      <td>0.888348</td>\n",
       "      <td>0.336085</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.145737</td>\n",
       "      <td>434.494016</td>\n",
       "      <td>45.861940</td>\n",
       "      <td>DBU</td>\n",
       "      <td>tBuXPhos</td>\n",
       "      <td>0.218362</td>\n",
       "      <td>0.249490</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.998180</td>\n",
       "      <td>1758.219855</td>\n",
       "      <td>50.362649</td>\n",
       "      <td>TEA</td>\n",
       "      <td>tBuXPhos</td>\n",
       "      <td>0.119502</td>\n",
       "      <td>0.248967</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.370598</td>\n",
       "      <td>856.919234</td>\n",
       "      <td>54.740152</td>\n",
       "      <td>BTMG</td>\n",
       "      <td>tBuBrettPhos</td>\n",
       "      <td>1.000151</td>\n",
       "      <td>0.338138</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    base_eq        t_res  temperature  base      catalyst     yield      cost  \\\n",
       "0  1.000929   640.729785    63.578259   DBU        AlPhos  0.860773  0.420104   \n",
       "1  1.848292   219.006008    91.659600   DBU        AlPhos  0.985511  0.421029   \n",
       "2  1.949376   239.685059    95.291403   DBU  tBuBrettPhos  1.001262  0.280399   \n",
       "3  1.215942   140.311163    95.770730  BTMG      tBuXPhos  0.942617  0.301352   \n",
       "4  1.401418  1076.142758    78.363599   TEA  tBuBrettPhos  0.016274  0.278780   \n",
       "5  2.205043  1047.478169    64.571328   DBU      tBuXPhos  0.788471  0.250647   \n",
       "6  2.011124  1434.620903    37.719431  BTMG      tBuXPhos  0.888348  0.336085   \n",
       "7  1.145737   434.494016    45.861940   DBU      tBuXPhos  0.218362  0.249490   \n",
       "8  1.998180  1758.219855    50.362649   TEA      tBuXPhos  0.119502  0.248967   \n",
       "9  1.370598   856.919234    54.740152  BTMG  tBuBrettPhos  1.000151  0.338138   \n",
       "\n",
       "   valid_cost  valid_yield  \n",
       "0           1            1  \n",
       "1           1            1  \n",
       "2           1            1  \n",
       "3           1            1  \n",
       "4           1            1  \n",
       "5           1            1  \n",
       "6           1            1  \n",
       "7           1            1  \n",
       "8           1            1  \n",
       "9           1            1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = CrossCoupling()\n",
    "samples = benchmark.domain.inputs.sample(n=50)\n",
    "experiments = benchmark.f(samples, return_complete=True)\n",
    "\n",
    "experiments.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"MixedSingleTaskGPSurrogate\", \"inputs\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"CategoricalDescriptorInput\", \"key\": \"catalyst\", \"categories\": [\"tBuXPhos\", \"tBuBrettPhos\", \"AlPhos\"], \"allowed\": [true, true, true], \"descriptors\": [\"area_cat\", \"M2_cat\"], \"values\": [[460.7543, 67.2057], [518.8408, 89.8738], [819.933, 129.0808]]}, {\"type\": \"CategoricalDescriptorInput\", \"key\": \"base\", \"categories\": [\"TEA\", \"TMG\", \"BTMG\", \"DBU\"], \"allowed\": [true, true, true, true], \"descriptors\": [\"area\", \"M2\"], \"values\": [[162.2992, 25.8165], [165.5447, 81.4847], [227.3523, 30.554], [192.4693, 59.8367]]}, {\"type\": \"ContinuousInput\", \"key\": \"base_eq\", \"unit\": null, \"bounds\": [1.0, 2.5]}, {\"type\": \"ContinuousInput\", \"key\": \"temperature\", \"unit\": null, \"bounds\": [30.0, 100.0]}, {\"type\": \"ContinuousInput\", \"key\": \"t_res\", \"unit\": null, \"bounds\": [60.0, 1800.0]}]}, \"outputs\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"yield\", \"objective\": {\"type\": \"MaximizeObjective\", \"w\": 1.0, \"lower_bound\": 0.0, \"upper_bound\": 1.0}, \"unit\": null}]}, \"input_preprocessing_specs\": {\"catalyst\": \"ONE_HOT\", \"base\": \"DESCRIPTOR\"}, \"dump\": null, \"continuous_kernel\": {\"type\": \"MaternKernel\", \"ard\": true, \"nu\": 2.5, \"lengthscale_prior\": null}, \"categorical_kernel\": {\"type\": \"HammondDistanceKernel\", \"ard\": true}, \"scaler\": \"NORMALIZE\"}'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we setup the data model, here a Single Task GP\n",
    "surrogate_data = MixedSingleTaskGPSurrogate(\n",
    "    inputs=benchmark.domain.inputs,\n",
    "    outputs=Outputs(features=[benchmark.domain.outputs.features[0]]),\n",
    "    input_preprocessing_specs={\"catalyst\": CategoricalEncodingEnum.ONE_HOT}\n",
    ")\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = surrogate_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load it from the spec\n",
    "surrogate_data = parse_obj_as(AnySurrogate, json.loads(jspec))\n",
    "# Map it \n",
    "surrogate = surrogates.map(surrogate_data)\n",
    "# Fit it\n",
    "surrogate.fit(experiments=experiments)\n",
    "# dump it\n",
    "dump = surrogate.dumps()\n",
    "# predict with it\n",
    "df_predictions = surrogate.predict(experiments)\n",
    "# transform to spec\n",
    "predictions = surrogate.to_predictions(predictions=df_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surrogate_data = parse_obj_as(AnySurrogate, json.loads(jspec))\n",
    "surrogate = surrogates.map(surrogate_data)\n",
    "surrogate.loads(dump)\n",
    "\n",
    "# predict with it\n",
    "df_predictions2 = surrogate.predict(experiments)\n",
    "# transform to spec\n",
    "predictions2 = surrogate.to_predictions(predictions=df_predictions2)\n",
    "\n",
    "# check for equality\n",
    "predictions==predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bofire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f21737eef49beedf03d74399b47fe38d73eff760737ca33d38b9fe616638e91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
