{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy Serialization with BoFire"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pydantic import parse_obj_as\n",
    "\n",
    "\n",
    "from bofire.data_models.domain.api import Inputs, Outputs, Domain\n",
    "from bofire.benchmarks.single import Himmelblau\n",
    "from bofire.benchmarks.multi import DTLZ2\n",
    "from bofire.data_models.strategies.api import SoboStrategy as SoboStrategyDataModel\n",
    "from bofire.data_models.strategies.api import QnehviStrategy as QnehviStrategyDataModel\n",
    "from bofire.data_models.strategies.api import RandomStrategy as RandomStrategyDataModel\n",
    "from bofire.data_models.strategies.api import AnyStrategy\n",
    "from bofire.data_models.acquisition_functions.api import qNEI\n",
    "import bofire.strategies.api as stategies\n",
    "from bofire.data_models.surrogates.api import BotorchSurrogates, AnySurrogate, SingleTaskGPSurrogate\n",
    "from bofire.data_models.kernels.api import ScaleKernel, RBFKernel\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Objective Problem Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = Himmelblau()\n",
    "samples = benchmark.domain.inputs.sample(n=10)\n",
    "experiments = benchmark.f(samples, return_complete=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Strategy\n",
    "\n",
    "The random strategy and other strategies that just inherit from `Strategy` and not `PredictiveStrategy` are special as they do not need defined output features in the domain and they do not need a call to `tell` before the `ask`. Furthermore they online provide input features in the candidates and no predictions for output features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"RandomStrategy\", \"domain\": {\"type\": \"Domain\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"lower_bound\": -4.0, \"upper_bound\": 4.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"lower_bound\": -4.0, \"upper_bound\": 4.0}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": []}, \"constraints\": {\"type\": \"Constraints\", \"constraints\": []}}, \"seed\": 256}'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup the data model\n",
    "domain = Domain(input_features=benchmark.domain.input_features)\n",
    "strategy_data = RandomStrategyDataModel(domain=domain)\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = strategy_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Candidate(inputValues={'x_1': InputValue(value=-1.2325343376159328), 'x_2': InputValue(value=-3.1869720129999273)}, outputValues=None),\n",
       " Candidate(inputValues={'x_1': InputValue(value=2.8172878246860407), 'x_2': InputValue(value=3.3265172127152063)}, outputValues=None),\n",
       " Candidate(inputValues={'x_1': InputValue(value=1.8054911073833129), 'x_2': InputValue(value=-2.9451929437162274)}, outputValues=None),\n",
       " Candidate(inputValues={'x_1': InputValue(value=-1.1907462496383197), 'x_2': InputValue(value=-2.966009463557924)}, outputValues=None),\n",
       " Candidate(inputValues={'x_1': InputValue(value=0.2076155277831946), 'x_2': InputValue(value=-3.9212687100549504)}, outputValues=None)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load it\n",
    "strategy_data = parse_obj_as(AnyStrategy, json.loads(jspec))\n",
    "\n",
    "# map it\n",
    "strategy = stategies.map(strategy_data)\n",
    "\n",
    "# ask it\n",
    "df_candidates = strategy.ask(candidate_count=5)\n",
    "\n",
    "# transform to spec\n",
    "candidates = strategy.to_candidates(df_candidates)\n",
    "\n",
    "candidates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOBO Strategy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will fail as SOBO is a predictive strategy which needs also output feature definitions, which is missing in the domain from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for SoboStrategy\ndomain\n  no output feature specified (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# setup the data model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m strategy_data \u001b[39m=\u001b[39m SoboStrategyDataModel(domain\u001b[39m=\u001b[39;49mdomain, acquisition_function\u001b[39m=\u001b[39;49mqNEI())\n\u001b[1;32m      4\u001b[0m \u001b[39m# we generate the json spec\u001b[39;00m\n\u001b[1;32m      5\u001b[0m jspec \u001b[39m=\u001b[39m strategy_data\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/bofire/lib/python3.10/site-packages/pydantic/main.py:342\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for SoboStrategy\ndomain\n  no output feature specified (type=value_error)"
     ]
    }
   ],
   "source": [
    "# setup the data model\n",
    "strategy_data = SoboStrategyDataModel(domain=domain, acquisition_function=qNEI())\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = strategy_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next try with a correct domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"SoboStrategy\", \"domain\": {\"type\": \"Domain\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"lower_bound\": -4.0, \"upper_bound\": 4.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"lower_bound\": -4.0, \"upper_bound\": 4.0}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"y\", \"objective\": {\"type\": \"MaximizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}}]}, \"constraints\": {\"type\": \"Constraints\", \"constraints\": []}}, \"seed\": 742, \"num_sobol_samples\": 512, \"num_restarts\": 8, \"num_raw_samples\": 1024, \"descriptor_method\": \"EXHAUSTIVE\", \"categorical_method\": \"EXHAUSTIVE\", \"discrete_method\": \"EXHAUSTIVE\", \"surrogate_specs\": {\"surrogates\": [{\"type\": \"SingleTaskGPSurrogate\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"lower_bound\": -4.0, \"upper_bound\": 4.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"lower_bound\": -4.0, \"upper_bound\": 4.0}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"y\", \"objective\": {\"type\": \"MaximizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}}]}, \"input_preprocessing_specs\": {}, \"kernel\": {\"type\": \"ScaleKernel\", \"base_kernel\": {\"type\": \"MaternKernel\", \"ard\": true, \"nu\": 2.5, \"lengthscale_prior\": {\"type\": \"GammaPrior\", \"concentration\": 3.0, \"rate\": 6.0}}, \"outputscale_prior\": {\"type\": \"GammaPrior\", \"concentration\": 2.0, \"rate\": 0.15}}, \"scaler\": \"NORMALIZE\"}]}, \"acquisition_function\": {\"type\": \"qNEI\"}}'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup the data model\n",
    "strategy_data = SoboStrategyDataModel(domain=benchmark.domain, acquisition_function=qNEI())\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = strategy_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will fail as SOBO is a predictive strategy which means we have to provide training data before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not enough experiments available to execute the strategy.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m strategy \u001b[39m=\u001b[39m stategies\u001b[39m.\u001b[39mmap(strategy_data)\n\u001b[1;32m      7\u001b[0m \u001b[39m# ask it\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m df_candidates \u001b[39m=\u001b[39m strategy\u001b[39m.\u001b[39;49mask(candidate_count\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m~/sandbox/bofire/bofire/strategies/predictives/predictive.py:51\u001b[0m, in \u001b[0;36mPredictiveStrategy.ask\u001b[0;34m(self, candidate_count, add_pending, candidate_pool)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mask\u001b[39m(\n\u001b[1;32m     36\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     37\u001b[0m     candidate_count: Optional[PositiveInt] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     38\u001b[0m     add_pending: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     39\u001b[0m     candidate_pool: Optional[pd\u001b[39m.\u001b[39mDataFrame] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m     41\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Function to generate new candidates.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m        pd.DataFrame: DataFrame with candidates (proposed experiments)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     candidates \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mask(\n\u001b[1;32m     52\u001b[0m         candidate_count\u001b[39m=\u001b[39;49mcandidate_count,\n\u001b[1;32m     53\u001b[0m         add_pending\u001b[39m=\u001b[39;49madd_pending,\n\u001b[1;32m     54\u001b[0m         candidate_pool\u001b[39m=\u001b[39;49mcandidate_pool,\n\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m     \u001b[39m# we have to generate predictions for the candidate pool candidates\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[39mif\u001b[39;00m candidate_pool \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/sandbox/bofire/bofire/strategies/strategy.py:103\u001b[0m, in \u001b[0;36mStrategy.ask\u001b[0;34m(self, candidate_count, add_pending, candidate_pool)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    100\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCandidate_count has to be at least 1 but got \u001b[39m\u001b[39m{\u001b[39;00mcandidate_count\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_sufficient_experiments():\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    104\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNot enough experiments available to execute the strategy.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m     )\n\u001b[1;32m    107\u001b[0m \u001b[39mif\u001b[39;00m candidate_pool \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m     candidates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ask(candidate_count\u001b[39m=\u001b[39mcandidate_count)\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough experiments available to execute the strategy."
     ]
    }
   ],
   "source": [
    "# load it\n",
    "strategy_data = parse_obj_as(AnyStrategy, json.loads(jspec))\n",
    "\n",
    "# map it\n",
    "strategy = stategies.map(strategy_data)\n",
    "\n",
    "# ask it\n",
    "df_candidates = strategy.ask(candidate_count=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is done by using the `tell` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Candidate(inputValues={'x_1': InputValue(value=-0.2588482202321763), 'x_2': InputValue(value=-4.0)}, outputValues={'y': OutputValue(predictedValue=181.01282121894124, standardDeviation=24.64999493071629, objective=181.01282121894124)}),\n",
       " Candidate(inputValues={'x_1': InputValue(value=0.20055265244293544), 'x_2': InputValue(value=-2.2730259435818407)}, outputValues={'y': OutputValue(predictedValue=183.32953981882224, standardDeviation=22.250343695582654, objective=183.32953981882224)})]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load it\n",
    "strategy_data = parse_obj_as(AnyStrategy, json.loads(jspec))\n",
    "\n",
    "# map it\n",
    "strategy = stategies.map(strategy_data)\n",
    "\n",
    "# tell it\n",
    "strategy.tell(experiments=experiments)\n",
    "\n",
    "# ask it\n",
    "df_candidates = strategy.ask(candidate_count=2)\n",
    "\n",
    "# transform to spec\n",
    "candidates = strategy.to_candidates(df_candidates)\n",
    "\n",
    "candidates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save the trained models of the strategy, for more info look at the `model_serial.ipynb` notebook. It could be that the `dumps` command fails here. But this is already fixed in the main branch of the `linear_operator` package, and if not yet, it should be available in main soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsurrogate_spec = strategy_data.surrogate_specs.surrogates[0].json()\n",
    "dump = strategy.surrogate_specs.surrogates[0].dumps()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOBO Strategy\n",
    "\n",
    "As example for a multiobjective strategy we are using here the Qnehvi stratey. Related strategies would be Qparego, MultiplicativeSobo etc. To use it, we have to first generate a multiobjective domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = DTLZ2(dim=6)\n",
    "samples = benchmark.domain.inputs.sample(n=10)\n",
    "experiments = benchmark.f(samples, return_complete=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the strategy spec is setup. Note that we can define there exactly which model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"QnehviStrategy\", \"domain\": {\"type\": \"Domain\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_0\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_3\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_4\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_5\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"f_0\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}}, {\"type\": \"ContinuousOutput\", \"key\": \"f_1\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}}]}, \"constraints\": {\"type\": \"Constraints\", \"constraints\": []}}, \"seed\": 649, \"num_sobol_samples\": 512, \"num_restarts\": 8, \"num_raw_samples\": 1024, \"descriptor_method\": \"EXHAUSTIVE\", \"categorical_method\": \"EXHAUSTIVE\", \"discrete_method\": \"EXHAUSTIVE\", \"surrogate_specs\": {\"surrogates\": [{\"type\": \"SingleTaskGPSurrogate\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_0\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_3\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_4\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_5\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"f_0\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}}]}, \"input_preprocessing_specs\": {}, \"kernel\": {\"type\": \"ScaleKernel\", \"base_kernel\": {\"type\": \"RBFKernel\", \"ard\": false, \"lengthscale_prior\": null}, \"outputscale_prior\": null}, \"scaler\": \"NORMALIZE\"}, {\"type\": \"SingleTaskGPSurrogate\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_0\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_3\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_4\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}, {\"type\": \"ContinuousInput\", \"key\": \"x_5\", \"lower_bound\": 0.0, \"upper_bound\": 1.0}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"f_1\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}}]}, \"input_preprocessing_specs\": {}, \"kernel\": {\"type\": \"ScaleKernel\", \"base_kernel\": {\"type\": \"MaternKernel\", \"ard\": true, \"nu\": 2.5, \"lengthscale_prior\": {\"type\": \"GammaPrior\", \"concentration\": 3.0, \"rate\": 6.0}}, \"outputscale_prior\": {\"type\": \"GammaPrior\", \"concentration\": 2.0, \"rate\": 0.15}}, \"scaler\": \"NORMALIZE\"}]}, \"ref_point\": null, \"alpha\": 0.0}'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup the data model\n",
    "strategy_data = QnehviStrategyDataModel(\n",
    "    domain=benchmark.domain,\n",
    "    surrogate_specs=BotorchSurrogates(\n",
    "        surrogates=[\n",
    "            SingleTaskGPSurrogate(\n",
    "                input_features=benchmark.domain.input_features,\n",
    "                output_features=Outputs(features=[benchmark.domain.outputs[0]]),\n",
    "                kernel=ScaleKernel(base_kernel=RBFKernel(ard=False))\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = strategy_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Candidate(inputValues={'x_0': InputValue(value=0.34451258412632535), 'x_1': InputValue(value=0.2021898805014269), 'x_2': InputValue(value=0.9130968117758534), 'x_3': InputValue(value=0.3012002108665261), 'x_4': InputValue(value=0.0), 'x_5': InputValue(value=0.0)}, outputValues={'f_0': OutputValue(predictedValue=0.6777183521800488, standardDeviation=0.2366029815403661, objective=-0.6777183521800488), 'f_1': OutputValue(predictedValue=0.877560768553107, standardDeviation=0.532737213995751, objective=-0.877560768553107)})]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load it\n",
    "strategy_data = parse_obj_as(AnyStrategy, json.loads(jspec))\n",
    "\n",
    "# map it\n",
    "strategy = stategies.map(strategy_data)\n",
    "\n",
    "# tell it\n",
    "strategy.tell(experiments=experiments)\n",
    "\n",
    "# ask it\n",
    "df_candidates = strategy.ask(candidate_count=1)\n",
    "\n",
    "# transform to spec\n",
    "candidates = strategy.to_candidates(df_candidates)\n",
    "\n",
    "candidates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the models can be saved. Note that we have two models here as we have two features in `domain.output_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsurrogate_specs = [surrogate.json() for surrogate in strategy_data.surrogate_specs.surrogates]\n",
    "dumps = [surrogate.dumps() for surrogate in strategy.surrogate_specs.surrogates]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the general setup of how it should work. What is missing and still needs to be implemented into bofire is to sideload already fitted models which is important for deterministic ones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bofire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
