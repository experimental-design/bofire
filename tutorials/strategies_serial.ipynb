{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy Serialization with BoFire"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/bofire/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pydantic import parse_obj_as, BaseModel\n",
    "from typing import List, Dict, Optional, Literal\n",
    "\n",
    "\n",
    "from bofire.data_models.domain.api import Inputs, Outputs, Domain\n",
    "from bofire.benchmarks.single import Himmelblau\n",
    "from bofire.benchmarks.multi import DTLZ2\n",
    "from bofire.data_models.strategies.api import SoboStrategy as SoboStrategyDataModel\n",
    "from bofire.data_models.strategies.api import QnehviStrategy as QnehviStrategyDataModel\n",
    "from bofire.data_models.strategies.api import RandomStrategy as RandomStrategyDataModel\n",
    "from bofire.data_models.strategies.api import AnyStrategy\n",
    "from bofire.data_models.acquisition_functions.api import qNEI\n",
    "import bofire.strategies.api as stategies\n",
    "from bofire.data_models.surrogates.api import BotorchSurrogates, AnySurrogate, SingleTaskGPSurrogate\n",
    "from bofire.data_models.kernels.api import ScaleKernel, RBFKernel\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Objective Problem Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = Himmelblau()\n",
    "samples = benchmark.domain.inputs.sample(n=10)\n",
    "\n",
    "# this is the training data\n",
    "experiments = benchmark.f(samples, return_complete=True)\n",
    "\n",
    "# this are the pending candidates\n",
    "pending_candidates = benchmark.domain.inputs.sample(2)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Strategy\n",
    "\n",
    "The random strategy and other strategies that just inherit from `Strategy` and not `PredictiveStrategy` are special as they do not need defined output features in the domain and they do not need a call to `tell` before the `ask`. Furthermore they online provide input features in the candidates and no predictions for output features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"RandomStrategy\", \"domain\": {\"type\": \"Domain\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"unit\": null, \"bounds\": [-6.0, 6.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"unit\": null, \"bounds\": [-6.0, 6.0]}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": []}, \"constraints\": {\"type\": \"Constraints\", \"constraints\": []}}, \"seed\": 696}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup the data model\n",
    "domain = Domain(input_features=benchmark.domain.input_features)\n",
    "strategy_data = RandomStrategyDataModel(domain=domain)\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = strategy_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Candidate(inputValues={'x_1': InputValue(value=5.788180450670685), 'x_2': InputValue(value=4.007899870247898)}, outputValues=None),\n",
       " Candidate(inputValues={'x_1': InputValue(value=4.814648686938762), 'x_2': InputValue(value=-0.32807166770742846)}, outputValues=None),\n",
       " Candidate(inputValues={'x_1': InputValue(value=-5.743313685687972), 'x_2': InputValue(value=3.6680928599086116)}, outputValues=None),\n",
       " Candidate(inputValues={'x_1': InputValue(value=-2.004589623914832), 'x_2': InputValue(value=-5.152624582882828)}, outputValues=None),\n",
       " Candidate(inputValues={'x_1': InputValue(value=0.6130215781704162), 'x_2': InputValue(value=-2.068679875423895)}, outputValues=None)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load it\n",
    "strategy_data = parse_obj_as(AnyStrategy, json.loads(jspec))\n",
    "\n",
    "# map it\n",
    "strategy = stategies.map(strategy_data)\n",
    "\n",
    "# ask it\n",
    "df_candidates = strategy.ask(candidate_count=5)\n",
    "\n",
    "# transform to spec\n",
    "candidates = strategy.to_candidates(df_candidates)\n",
    "\n",
    "candidates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOBO Strategy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will fail as SOBO is a predictive strategy which needs also output feature definitions, which is missing in the domain from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for SoboStrategy\ndomain\n  no output feature specified (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# setup the data model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m strategy_data \u001b[39m=\u001b[39m SoboStrategyDataModel(domain\u001b[39m=\u001b[39;49mdomain, acquisition_function\u001b[39m=\u001b[39;49mqNEI())\n\u001b[1;32m      4\u001b[0m \u001b[39m# we generate the json spec\u001b[39;00m\n\u001b[1;32m      5\u001b[0m jspec \u001b[39m=\u001b[39m strategy_data\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/bofire/lib/python3.10/site-packages/pydantic/main.py:342\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for SoboStrategy\ndomain\n  no output feature specified (type=value_error)"
     ]
    }
   ],
   "source": [
    "# setup the data model\n",
    "strategy_data = SoboStrategyDataModel(domain=domain, acquisition_function=qNEI())\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = strategy_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next try with a correct domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"SoboStrategy\", \"domain\": {\"type\": \"Domain\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"unit\": null, \"bounds\": [-6.0, 6.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"unit\": null, \"bounds\": [-6.0, 6.0]}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"y\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}, \"unit\": null}]}, \"constraints\": {\"type\": \"Constraints\", \"constraints\": []}}, \"seed\": 3, \"num_sobol_samples\": 512, \"num_restarts\": 8, \"num_raw_samples\": 1024, \"descriptor_method\": \"EXHAUSTIVE\", \"categorical_method\": \"EXHAUSTIVE\", \"discrete_method\": \"EXHAUSTIVE\", \"surrogate_specs\": {\"surrogates\": [{\"type\": \"SingleTaskGPSurrogate\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"unit\": null, \"bounds\": [-6.0, 6.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"unit\": null, \"bounds\": [-6.0, 6.0]}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"y\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}, \"unit\": null}]}, \"input_preprocessing_specs\": {}, \"dump\": null, \"kernel\": {\"type\": \"ScaleKernel\", \"base_kernel\": {\"type\": \"MaternKernel\", \"ard\": true, \"nu\": 2.5, \"lengthscale_prior\": {\"type\": \"GammaPrior\", \"concentration\": 3.0, \"rate\": 6.0}}, \"outputscale_prior\": {\"type\": \"GammaPrior\", \"concentration\": 2.0, \"rate\": 0.15}}, \"scaler\": \"NORMALIZE\"}]}, \"acquisition_function\": {\"type\": \"qNEI\"}}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup the data model\n",
    "strategy_data = SoboStrategyDataModel(domain=benchmark.domain, acquisition_function=qNEI())\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = strategy_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will fail as SOBO is a predictive strategy which means we have to provide training data before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not enough experiments available to execute the strategy.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m strategy \u001b[39m=\u001b[39m stategies\u001b[39m.\u001b[39mmap(strategy_data)\n\u001b[1;32m      7\u001b[0m \u001b[39m# ask it\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m df_candidates \u001b[39m=\u001b[39m strategy\u001b[39m.\u001b[39;49mask(candidate_count\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m~/sandbox/bofire/bofire/strategies/predictives/predictive.py:51\u001b[0m, in \u001b[0;36mPredictiveStrategy.ask\u001b[0;34m(self, candidate_count, add_pending, candidate_pool)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mask\u001b[39m(\n\u001b[1;32m     36\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     37\u001b[0m     candidate_count: Optional[PositiveInt] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     38\u001b[0m     add_pending: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     39\u001b[0m     candidate_pool: Optional[pd\u001b[39m.\u001b[39mDataFrame] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m     41\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Function to generate new candidates.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m        pd.DataFrame: DataFrame with candidates (proposed experiments)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     candidates \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mask(\n\u001b[1;32m     52\u001b[0m         candidate_count\u001b[39m=\u001b[39;49mcandidate_count,\n\u001b[1;32m     53\u001b[0m         add_pending\u001b[39m=\u001b[39;49madd_pending,\n\u001b[1;32m     54\u001b[0m         candidate_pool\u001b[39m=\u001b[39;49mcandidate_pool,\n\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m     \u001b[39m# we have to generate predictions for the candidate pool candidates\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[39mif\u001b[39;00m candidate_pool \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/sandbox/bofire/bofire/strategies/strategy.py:114\u001b[0m, in \u001b[0;36mStrategy.ask\u001b[0;34m(self, candidate_count, add_pending, candidate_pool)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    111\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCandidate_count has to be at least 1 but got \u001b[39m\u001b[39m{\u001b[39;00mcandidate_count\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_sufficient_experiments():\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    115\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNot enough experiments available to execute the strategy.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m candidate_pool \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     candidates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ask(candidate_count\u001b[39m=\u001b[39mcandidate_count)\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough experiments available to execute the strategy."
     ]
    }
   ],
   "source": [
    "# load it\n",
    "strategy_data = parse_obj_as(AnyStrategy, json.loads(jspec))\n",
    "\n",
    "# map it\n",
    "strategy = stategies.map(strategy_data)\n",
    "\n",
    "# ask it\n",
    "df_candidates = strategy.ask(candidate_count=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is done by using the `tell` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "missing column y_pred",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m strategy \u001b[39m=\u001b[39m stategies\u001b[39m.\u001b[39mmap(strategy_data)\n\u001b[1;32m      7\u001b[0m \u001b[39m# tell it the pending candidates if present\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m strategy\u001b[39m.\u001b[39;49madd_candidates(pending_candidates)\n\u001b[1;32m     10\u001b[0m \u001b[39m# tell it\u001b[39;00m\n\u001b[1;32m     11\u001b[0m strategy\u001b[39m.\u001b[39mtell(experiments\u001b[39m=\u001b[39mexperiments)\n",
      "File \u001b[0;32m~/sandbox/bofire/bofire/strategies/strategy.py:216\u001b[0m, in \u001b[0;36mStrategy.add_candidates\u001b[0;34m(self, candidates)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_candidates\u001b[39m(\u001b[39mself\u001b[39m, candidates: pd\u001b[39m.\u001b[39mDataFrame):\n\u001b[1;32m    211\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Add candidates to the strategy. Appends to existing ones.\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \n\u001b[1;32m    213\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[39m        experiments (pd.DataFrame): Dataframe with candidates.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     candidates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mvalidate_candidates(candidates)\n\u001b[1;32m    217\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcandidates \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_candidates \u001b[39m=\u001b[39m candidates\n",
      "File \u001b[0;32m~/sandbox/bofire/bofire/data_models/domain/domain.py:633\u001b[0m, in \u001b[0;36mDomain.validate_candidates\u001b[0;34m(self, candidates, only_inputs, tol)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m_pred\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m_sd\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m_des\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    632\u001b[0m     \u001b[39mif\u001b[39;00m col \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m candidates:\n\u001b[0;32m--> 633\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmissing column \u001b[39m\u001b[39m{\u001b[39;00mcol\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    634\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m is_numeric(candidates[col])) \u001b[39mand\u001b[39;00m (\n\u001b[1;32m    635\u001b[0m         \u001b[39mnot\u001b[39;00m candidates[col]\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39mto_numpy()\u001b[39m.\u001b[39mall()\n\u001b[1;32m    636\u001b[0m     ):\n\u001b[1;32m    637\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    638\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnot all values of output feature `\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m` are numerical\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    639\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: missing column y_pred"
     ]
    }
   ],
   "source": [
    "# load it\n",
    "strategy_data = parse_obj_as(AnyStrategy, json.loads(jspec))\n",
    "\n",
    "# map it\n",
    "strategy = stategies.map(strategy_data)\n",
    "\n",
    "# tell it the pending candidates if present\n",
    "strategy.add_candidates(pending_candidates)\n",
    "\n",
    "# tell it\n",
    "strategy.tell(experiments=experiments)\n",
    "\n",
    "# ask it\n",
    "df_candidates = strategy.ask(candidate_count=2)\n",
    "\n",
    "# transform to spec\n",
    "candidates = strategy.to_candidates(df_candidates)\n",
    "\n",
    "candidates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save the trained models of the strategy, for more info look at the `model_serial.ipynb` notebook. It could be that the `dumps` command fails here. But this is already fixed in the main branch of the `linear_operator` package, and if not yet, it should be available in main soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsurrogate_spec = strategy_data.surrogate_specs.surrogates[0].json()\n",
    "dump = strategy.surrogate_specs.surrogates[0].dumps()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOBO Strategy\n",
    "\n",
    "As example for a multiobjective strategy we are using here the Qnehvi stratey. Related strategies would be Qparego, MultiplicativeSobo etc. To use it, we have to first generate a multiobjective domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = DTLZ2(dim=6)\n",
    "samples = benchmark.domain.inputs.sample(n=20)\n",
    "experiments = benchmark.f(samples, return_complete=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the strategy spec is setup. Note that we can define there exactly which model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"QnehviStrategy\", \"domain\": {\"type\": \"Domain\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_0\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_3\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_4\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_5\", \"unit\": null, \"bounds\": [0.0, 1.0]}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"f_0\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}, \"unit\": null}, {\"type\": \"ContinuousOutput\", \"key\": \"f_1\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}, \"unit\": null}]}, \"constraints\": {\"type\": \"Constraints\", \"constraints\": []}}, \"seed\": 812, \"num_sobol_samples\": 512, \"num_restarts\": 8, \"num_raw_samples\": 1024, \"descriptor_method\": \"EXHAUSTIVE\", \"categorical_method\": \"EXHAUSTIVE\", \"discrete_method\": \"EXHAUSTIVE\", \"surrogate_specs\": {\"surrogates\": [{\"type\": \"SingleTaskGPSurrogate\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_0\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_3\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_4\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_5\", \"unit\": null, \"bounds\": [0.0, 1.0]}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"f_0\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}, \"unit\": null}]}, \"input_preprocessing_specs\": {}, \"kernel\": {\"type\": \"ScaleKernel\", \"base_kernel\": {\"type\": \"RBFKernel\", \"ard\": false, \"lengthscale_prior\": null}, \"outputscale_prior\": null}, \"scaler\": \"NORMALIZE\"}, {\"type\": \"SingleTaskGPSurrogate\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_0\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_3\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_4\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_5\", \"unit\": null, \"bounds\": [0.0, 1.0]}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"f_1\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}, \"unit\": null}]}, \"input_preprocessing_specs\": {}, \"kernel\": {\"type\": \"ScaleKernel\", \"base_kernel\": {\"type\": \"MaternKernel\", \"ard\": true, \"nu\": 2.5, \"lengthscale_prior\": {\"type\": \"GammaPrior\", \"concentration\": 3.0, \"rate\": 6.0}}, \"outputscale_prior\": {\"type\": \"GammaPrior\", \"concentration\": 2.0, \"rate\": 0.15}}, \"scaler\": \"NORMALIZE\"}]}, \"ref_point\": null, \"alpha\": 0.0}'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup the data model\n",
    "strategy_data = QnehviStrategyDataModel(\n",
    "    domain=benchmark.domain,\n",
    "    surrogate_specs=BotorchSurrogates(\n",
    "        surrogates=[\n",
    "            SingleTaskGPSurrogate(\n",
    "                input_features=benchmark.domain.input_features,\n",
    "                output_features=Outputs(features=[benchmark.domain.outputs[0]]),\n",
    "                kernel=ScaleKernel(base_kernel=RBFKernel(ard=False))\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = strategy_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Candidate(inputValues={'x_0': InputValue(value=1.0), 'x_1': InputValue(value=0.0), 'x_2': InputValue(value=0.0), 'x_3': InputValue(value=0.26778854448283496), 'x_4': InputValue(value=0.3845219911447761), 'x_5': InputValue(value=1.0)}, outputValues={'f_0': OutputValue(predictedValue=0.08972119036798198, standardDeviation=0.21218810974443847, objective=-0.08972119036798198), 'f_1': OutputValue(predictedValue=1.2433746467198457, standardDeviation=0.30556287125819065, objective=-1.2433746467198457)})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load it\n",
    "strategy_data = parse_obj_as(AnyStrategy, json.loads(jspec))\n",
    "\n",
    "# map it\n",
    "strategy = stategies.map(strategy_data)\n",
    "\n",
    "# tell it\n",
    "strategy.tell(experiments=experiments)\n",
    "\n",
    "# ask it\n",
    "df_candidates = strategy.ask(candidate_count=1)\n",
    "\n",
    "# transform to spec\n",
    "candidates = strategy.to_candidates(df_candidates)\n",
    "\n",
    "candidates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the models can be saved. Note that we have two models here as we have two features in `domain.output_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsurrogate_specs = [surrogate.json() for surrogate in strategy_data.surrogate_specs.surrogates]\n",
    "dumps = [surrogate.dumps() for surrogate in strategy.surrogate_specs.surrogates]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fill the model info section accordingly, the following snippet has to be executed for every surrogate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidationValues(BaseModel):\n",
    "    observed: List[float]\n",
    "    predicted: List[float]\n",
    "    standardDeviation: Optional[List[float]]\n",
    "\n",
    "class TestMethod(BaseModel):\n",
    "    type: str\n",
    "\n",
    "class CrossValidation(TestMethod):\n",
    "    type: Literal[\"CrossValidation\"] = \"CrossValidation\"\n",
    "    foldCount: int\n",
    "\n",
    "surrogate = strategy.surrogate_specs.surrogates[0]\n",
    "\n",
    "cv_train, cv_test, _ = surrogate.cross_validate(strategy.experiments, folds=5)\n",
    "\n",
    "testMethod = CrossValidation(foldCount=5) \n",
    "metricsTrain = cv_train.get_metrics(combine_folds=False).describe().loc[\"mean\"].to_dict()\n",
    "metricsTest = cv_test.get_metrics(combine_folds=True).describe().loc[\"mean\"].to_dict()\n",
    "\n",
    "cv_train = cv_train._combine_folds()\n",
    "cv_test = cv_test._combine_folds()\n",
    "\n",
    "cvResultsTrain = {surrogate.output_features[0].key: CrossValidationValues(\n",
    "    observed=cv_train.observed.tolist(),\n",
    "    predicted=cv_train.predicted.tolist(),\n",
    "    standardDeviation=cv_train.standard_deviation.tolist(),\n",
    "    )\n",
    "}\n",
    "cvResultsTest = {surrogate.output_features[0].key: CrossValidationValues(\n",
    "    observed=cv_test.observed.tolist(),\n",
    "    predicted=cv_test.predicted.tolist(),\n",
    "    standardDeviation=cv_test.standard_deviation.tolist(),\n",
    "    )\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fields of interest are `cvResultsTrain`, `cvResultsTest`, `metricsTrain`, `metricsTest` and `testMethod`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bofire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
