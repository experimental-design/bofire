{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy Serialization with BoFire"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pydantic import parse_obj_as, BaseModel, Field\n",
    "from typing import List, Dict, Optional, Literal\n",
    "\n",
    "\n",
    "from bofire.data_models.domain.api import Inputs, Outputs, Domain\n",
    "from bofire.benchmarks.single import Himmelblau\n",
    "from bofire.benchmarks.multi import DTLZ2\n",
    "from bofire.data_models.strategies.api import SoboStrategy as SoboStrategyDataModel\n",
    "from bofire.data_models.strategies.api import QnehviStrategy as QnehviStrategyDataModel\n",
    "from bofire.data_models.strategies.api import RandomStrategy as RandomStrategyDataModel\n",
    "from bofire.data_models.strategies.api import AnyStrategy\n",
    "from bofire.data_models.acquisition_functions.api import qNEI\n",
    "import bofire.strategies.api as stategies\n",
    "from bofire.data_models.surrogates.api import BotorchSurrogates, AnySurrogate, SingleTaskGPSurrogate\n",
    "from bofire.data_models.kernels.api import ScaleKernel, RBFKernel\n",
    "from bofire.surrogates.trainable import TrainableSurrogate\n",
    "from bofire.surrogates.diagnostics import CvResults2CrossValidationValues, CrossValidationValues\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Objective Problem Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = Himmelblau()\n",
    "samples = benchmark.domain.inputs.sample(n=10)\n",
    "\n",
    "# this is the training data\n",
    "experiments = benchmark.f(samples, return_complete=True)\n",
    "\n",
    "# this are the pending candidates\n",
    "pending_candidates = benchmark.domain.inputs.sample(2)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Strategy\n",
    "\n",
    "The random strategy and other strategies that just inherit from `Strategy` and not `PredictiveStrategy` are special as they do not need defined output features in the domain and they do not need a call to `tell` before the `ask`. Furthermore they online provide input features in the candidates and no predictions for output features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the data model\n",
    "domain = Domain(inputs=benchmark.domain.inputs)\n",
    "strategy_data = RandomStrategyDataModel(domain=domain)\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = strategy_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it\n",
    "strategy_data = parse_obj_as(AnyStrategy, json.loads(jspec))\n",
    "\n",
    "# map it\n",
    "strategy = stategies.map(strategy_data)\n",
    "\n",
    "# ask it\n",
    "df_candidates = strategy.ask(candidate_count=5)\n",
    "\n",
    "# transform to spec\n",
    "candidates = strategy.to_candidates(df_candidates)\n",
    "\n",
    "candidates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOBO Strategy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the strategies data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the data model\n",
    "strategy_data = SoboStrategyDataModel(domain=benchmark.domain, acquisition_function=qNEI())\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = strategy_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As SOBO is a predictive strategy, training data has to be provided before candidated can be requested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it\n",
    "strategy_data = parse_obj_as(AnyStrategy, json.loads(jspec))\n",
    "\n",
    "# map it\n",
    "strategy = stategies.map(strategy_data)\n",
    "\n",
    "# tell it the pending candidates if present\n",
    "if pending_candidates is not None:\n",
    "    strategy.add_candidates(pending_candidates)\n",
    "\n",
    "# tell it\n",
    "strategy.tell(experiments=experiments)\n",
    "\n",
    "# ask it\n",
    "df_candidates = strategy.ask(candidate_count=2)\n",
    "\n",
    "# transform to spec\n",
    "candidates = strategy.to_candidates(df_candidates)\n",
    "\n",
    "candidates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save the trained models of the strategy, for more info look at the `model_serial.ipynb` notebook. It could be that the `dumps` command fails here. But this is already fixed in the main branch of the `linear_operator` package, and if not yet, it should be available in main soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsurrogate_spec = strategy_data.surrogate_specs.surrogates[0].json()\n",
    "dump = strategy.surrogate_specs.surrogates[0].dumps()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOBO Strategy\n",
    "\n",
    "As example for a multiobjective strategy we are using here the Qnehvi stratey. Related strategies would be Qparego, MultiplicativeSobo etc. To use it, we have to first generate a multiobjective domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = DTLZ2(dim=6)\n",
    "samples = benchmark.domain.inputs.sample(n=20)\n",
    "experiments = benchmark.f(samples, return_complete=True)\n",
    "pending_candidates = benchmark.domain.inputs.sample(2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the strategy spec is setup. Note that we can define there exactly which model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the data model\n",
    "strategy_data = QnehviStrategyDataModel(\n",
    "    domain=benchmark.domain,\n",
    "    surrogate_specs=BotorchSurrogates(\n",
    "        surrogates=[\n",
    "            SingleTaskGPSurrogate(\n",
    "                inputs=benchmark.domain.inputs,\n",
    "                outputs=Outputs(features=[benchmark.domain.outputs[0]]),\n",
    "                kernel=ScaleKernel(base_kernel=RBFKernel(ard=False))\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = strategy_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it\n",
    "strategy_data = parse_obj_as(AnyStrategy, json.loads(jspec))\n",
    "\n",
    "# map it\n",
    "strategy = stategies.map(strategy_data)\n",
    "\n",
    "# tell it the pending candidates if available\n",
    "if pending_candidates is not None:\n",
    "    strategy.add_candidates(pending_candidates)\n",
    "\n",
    "# tell it\n",
    "strategy.tell(experiments=experiments)\n",
    "\n",
    "# ask it\n",
    "df_candidates = strategy.ask(candidate_count=1)\n",
    "\n",
    "# transform to spec\n",
    "candidates = strategy.to_candidates(df_candidates)\n",
    "\n",
    "candidates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fill the model info section accordingly, the following snippet has to be executed for every surrogate, incldung saving the actual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMethod(BaseModel):\n",
    "    type: str\n",
    "\n",
    "class CrossValidation(TestMethod):\n",
    "    type: Literal[\"CrossValidation\"] = \"CrossValidation\"\n",
    "    foldCount: int\n",
    "\n",
    "\n",
    "for i in range(len(strategy_data.surrogate_specs.surrogates)):\n",
    "    surrogate_data = strategy_data.surrogate_specs.surrogates[i]\n",
    "    surrogate = strategy.surrogate_specs.surrogates[i]\n",
    "    # get the spec\n",
    "    jsurrogate_spec = surrogate_data.json()\n",
    "    # get the dump\n",
    "    dump = surrogate.dumps()\n",
    "    # do the cross validation, only if we have a trainable model under the hood\n",
    "    if isinstance(surrogate,TrainableSurrogate):\n",
    "        cv_train, cv_test, _ = surrogate.cross_validate(strategy.experiments, folds=5)\n",
    "        # transform the bofire objects to the backend objects\n",
    "        testMethod = CrossValidation(foldCount=5)\n",
    "        cvResultsTrain = CvResults2CrossValidationValues(cv_train)\n",
    "        cvResultsTest = CvResults2CrossValidationValues(cv_test)\n",
    "        metricsTrain = {surrogate.outputs[0].key: cv_train.get_metrics(combine_folds=False).describe().loc[\"mean\"].to_dict()}\n",
    "        metricsTest = {surrogate.outputs[0].key: cv_test.get_metrics(combine_folds=True).describe().loc[\"mean\"].to_dict()}\n",
    "        # save to backend\n",
    "        # - jsurrogate_spec\n",
    "        # - dump\n",
    "        # - testMethod\n",
    "        # - cvResultsTrain\n",
    "        # - cvResultsTest\n",
    "        # - metricsTrain\n",
    "        # - metricsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bofire_devel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "b9bdc9e617e457afdaedd2563eddde9c04c87768cb2f63795a1786b83528ca68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
