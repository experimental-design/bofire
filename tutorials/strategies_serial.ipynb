{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy Serialization with BoFire"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/bofire/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pydantic import parse_obj_as, BaseModel, Field\n",
    "from typing import List, Dict, Optional, Literal\n",
    "\n",
    "\n",
    "from bofire.data_models.domain.api import Inputs, Outputs, Domain\n",
    "from bofire.benchmarks.single import Himmelblau\n",
    "from bofire.benchmarks.multi import DTLZ2\n",
    "from bofire.data_models.strategies.api import SoboStrategy as SoboStrategyDataModel\n",
    "from bofire.data_models.strategies.api import QnehviStrategy as QnehviStrategyDataModel\n",
    "from bofire.data_models.strategies.api import RandomStrategy as RandomStrategyDataModel\n",
    "from bofire.data_models.strategies.api import AnyStrategy\n",
    "from bofire.data_models.acquisition_functions.api import qNEI\n",
    "import bofire.strategies.api as stategies\n",
    "from bofire.data_models.surrogates.api import BotorchSurrogates, AnySurrogate, SingleTaskGPSurrogate\n",
    "from bofire.data_models.kernels.api import ScaleKernel, RBFKernel\n",
    "from bofire.surrogates.trainable import TrainableSurrogate\n",
    "from bofire.surrogates.diagnostics import CvResults2CrossValidationValues, CrossValidationValues\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Objective Problem Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = Himmelblau()\n",
    "samples = benchmark.domain.inputs.sample(n=10)\n",
    "\n",
    "# this is the training data\n",
    "experiments = benchmark.f(samples, return_complete=True)\n",
    "\n",
    "# this are the pending candidates\n",
    "pending_candidates = benchmark.domain.inputs.sample(2)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Strategy\n",
    "\n",
    "The random strategy and other strategies that just inherit from `Strategy` and not `PredictiveStrategy` are special as they do not need defined output features in the domain and they do not need a call to `tell` before the `ask`. Furthermore they online provide input features in the candidates and no predictions for output features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"RandomStrategy\", \"domain\": {\"type\": \"Domain\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"unit\": null, \"bounds\": [-6.0, 6.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"unit\": null, \"bounds\": [-6.0, 6.0]}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": []}, \"constraints\": {\"type\": \"Constraints\", \"constraints\": []}}, \"seed\": 632}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup the data model\n",
    "domain = Domain(input_features=benchmark.domain.input_features)\n",
    "strategy_data = RandomStrategyDataModel(domain=domain)\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = strategy_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Candidate(inputValues={'x_1': InputValue(value=-0.39832076260392757), 'x_2': InputValue(value=-0.7609607369925802)}, outputValues=None),\n",
       " Candidate(inputValues={'x_1': InputValue(value=0.5497314129320796), 'x_2': InputValue(value=-5.046732447716293)}, outputValues=None),\n",
       " Candidate(inputValues={'x_1': InputValue(value=1.3452722401899244), 'x_2': InputValue(value=1.597640790269045)}, outputValues=None),\n",
       " Candidate(inputValues={'x_1': InputValue(value=-3.9037743321454013), 'x_2': InputValue(value=0.3398091702288455)}, outputValues=None),\n",
       " Candidate(inputValues={'x_1': InputValue(value=4.6989467277800205), 'x_2': InputValue(value=-1.7212722298533234)}, outputValues=None)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load it\n",
    "strategy_data = parse_obj_as(AnyStrategy, json.loads(jspec))\n",
    "\n",
    "# map it\n",
    "strategy = stategies.map(strategy_data)\n",
    "\n",
    "# ask it\n",
    "df_candidates = strategy.ask(candidate_count=5)\n",
    "\n",
    "# transform to spec\n",
    "candidates = strategy.to_candidates(df_candidates)\n",
    "\n",
    "candidates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOBO Strategy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will fail as SOBO is a predictive strategy which needs also output feature definitions, which is missing in the domain from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for SoboStrategy\ndomain\n  no output feature specified (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# setup the data model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m strategy_data \u001b[39m=\u001b[39m SoboStrategyDataModel(domain\u001b[39m=\u001b[39;49mdomain, acquisition_function\u001b[39m=\u001b[39;49mqNEI())\n\u001b[1;32m      4\u001b[0m \u001b[39m# we generate the json spec\u001b[39;00m\n\u001b[1;32m      5\u001b[0m jspec \u001b[39m=\u001b[39m strategy_data\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/bofire/lib/python3.10/site-packages/pydantic/main.py:342\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for SoboStrategy\ndomain\n  no output feature specified (type=value_error)"
     ]
    }
   ],
   "source": [
    "# setup the data model\n",
    "strategy_data = SoboStrategyDataModel(domain=domain, acquisition_function=qNEI())\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = strategy_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next try with a correct domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"SoboStrategy\", \"domain\": {\"type\": \"Domain\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"unit\": null, \"bounds\": [-6.0, 6.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"unit\": null, \"bounds\": [-6.0, 6.0]}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"y\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}, \"unit\": null}]}, \"constraints\": {\"type\": \"Constraints\", \"constraints\": []}}, \"seed\": 253, \"num_sobol_samples\": 512, \"num_restarts\": 8, \"num_raw_samples\": 1024, \"descriptor_method\": \"EXHAUSTIVE\", \"categorical_method\": \"EXHAUSTIVE\", \"discrete_method\": \"EXHAUSTIVE\", \"surrogate_specs\": {\"surrogates\": [{\"type\": \"SingleTaskGPSurrogate\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"unit\": null, \"bounds\": [-6.0, 6.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"unit\": null, \"bounds\": [-6.0, 6.0]}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"y\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}, \"unit\": null}]}, \"input_preprocessing_specs\": {}, \"dump\": null, \"kernel\": {\"type\": \"ScaleKernel\", \"base_kernel\": {\"type\": \"MaternKernel\", \"ard\": true, \"nu\": 2.5, \"lengthscale_prior\": {\"type\": \"GammaPrior\", \"concentration\": 3.0, \"rate\": 6.0}}, \"outputscale_prior\": {\"type\": \"GammaPrior\", \"concentration\": 2.0, \"rate\": 0.15}}, \"scaler\": \"NORMALIZE\"}]}, \"acquisition_function\": {\"type\": \"qNEI\"}}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup the data model\n",
    "strategy_data = SoboStrategyDataModel(domain=benchmark.domain, acquisition_function=qNEI())\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = strategy_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will fail as SOBO is a predictive strategy which means we have to provide training data before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not enough experiments available to execute the strategy.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m strategy \u001b[39m=\u001b[39m stategies\u001b[39m.\u001b[39mmap(strategy_data)\n\u001b[1;32m      7\u001b[0m \u001b[39m# ask it\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m df_candidates \u001b[39m=\u001b[39m strategy\u001b[39m.\u001b[39;49mask(candidate_count\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m~/sandbox/bofire/bofire/strategies/predictives/predictive.py:51\u001b[0m, in \u001b[0;36mPredictiveStrategy.ask\u001b[0;34m(self, candidate_count, add_pending, candidate_pool)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mask\u001b[39m(\n\u001b[1;32m     36\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     37\u001b[0m     candidate_count: Optional[PositiveInt] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     38\u001b[0m     add_pending: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     39\u001b[0m     candidate_pool: Optional[pd\u001b[39m.\u001b[39mDataFrame] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m     41\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Function to generate new candidates.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m        pd.DataFrame: DataFrame with candidates (proposed experiments)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     candidates \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mask(\n\u001b[1;32m     52\u001b[0m         candidate_count\u001b[39m=\u001b[39;49mcandidate_count,\n\u001b[1;32m     53\u001b[0m         add_pending\u001b[39m=\u001b[39;49madd_pending,\n\u001b[1;32m     54\u001b[0m         candidate_pool\u001b[39m=\u001b[39;49mcandidate_pool,\n\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m     \u001b[39m# we have to generate predictions for the candidate pool candidates\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[39mif\u001b[39;00m candidate_pool \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/sandbox/bofire/bofire/strategies/strategy.py:114\u001b[0m, in \u001b[0;36mStrategy.ask\u001b[0;34m(self, candidate_count, add_pending, candidate_pool)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    111\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCandidate_count has to be at least 1 but got \u001b[39m\u001b[39m{\u001b[39;00mcandidate_count\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_sufficient_experiments():\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    115\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNot enough experiments available to execute the strategy.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m candidate_pool \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     candidates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ask(candidate_count\u001b[39m=\u001b[39mcandidate_count)\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough experiments available to execute the strategy."
     ]
    }
   ],
   "source": [
    "# load it\n",
    "strategy_data = parse_obj_as(AnyStrategy, json.loads(jspec))\n",
    "\n",
    "# map it\n",
    "strategy = stategies.map(strategy_data)\n",
    "\n",
    "# ask it\n",
    "df_candidates = strategy.ask(candidate_count=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is done by using the `tell` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Candidate(inputValues={'x_1': InputValue(value=-1.2012287772870565), 'x_2': InputValue(value=2.3839681325410282)}, outputValues={'y': OutputValue(predictedValue=-27.03056758938328, standardDeviation=169.00815870878822, objective=27.03056758938328)}),\n",
       " Candidate(inputValues={'x_1': InputValue(value=5.58215853323273), 'x_2': InputValue(value=-0.6109173766848464)}, outputValues={'y': OutputValue(predictedValue=43.317914949450596, standardDeviation=242.31451628448355, objective=-43.317914949450596)})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load it\n",
    "strategy_data = parse_obj_as(AnyStrategy, json.loads(jspec))\n",
    "\n",
    "# map it\n",
    "strategy = stategies.map(strategy_data)\n",
    "\n",
    "# tell it the pending candidates if present\n",
    "if pending_candidates is not None:\n",
    "    strategy.add_candidates(pending_candidates)\n",
    "\n",
    "# tell it\n",
    "strategy.tell(experiments=experiments)\n",
    "\n",
    "# ask it\n",
    "df_candidates = strategy.ask(candidate_count=2)\n",
    "\n",
    "# transform to spec\n",
    "candidates = strategy.to_candidates(df_candidates)\n",
    "\n",
    "candidates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save the trained models of the strategy, for more info look at the `model_serial.ipynb` notebook. It could be that the `dumps` command fails here. But this is already fixed in the main branch of the `linear_operator` package, and if not yet, it should be available in main soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsurrogate_spec = strategy_data.surrogate_specs.surrogates[0].json()\n",
    "dump = strategy.surrogate_specs.surrogates[0].dumps()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOBO Strategy\n",
    "\n",
    "As example for a multiobjective strategy we are using here the Qnehvi stratey. Related strategies would be Qparego, MultiplicativeSobo etc. To use it, we have to first generate a multiobjective domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = DTLZ2(dim=6)\n",
    "samples = benchmark.domain.inputs.sample(n=20)\n",
    "experiments = benchmark.f(samples, return_complete=True)\n",
    "pending_candidates = benchmark.domain.inputs.sample(2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the strategy spec is setup. Note that we can define there exactly which model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"QnehviStrategy\", \"domain\": {\"type\": \"Domain\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_0\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_3\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_4\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_5\", \"unit\": null, \"bounds\": [0.0, 1.0]}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"f_0\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}, \"unit\": null}, {\"type\": \"ContinuousOutput\", \"key\": \"f_1\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}, \"unit\": null}]}, \"constraints\": {\"type\": \"Constraints\", \"constraints\": []}}, \"seed\": 555, \"num_sobol_samples\": 512, \"num_restarts\": 8, \"num_raw_samples\": 1024, \"descriptor_method\": \"EXHAUSTIVE\", \"categorical_method\": \"EXHAUSTIVE\", \"discrete_method\": \"EXHAUSTIVE\", \"surrogate_specs\": {\"surrogates\": [{\"type\": \"SingleTaskGPSurrogate\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_0\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_3\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_4\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_5\", \"unit\": null, \"bounds\": [0.0, 1.0]}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"f_0\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}, \"unit\": null}]}, \"input_preprocessing_specs\": {}, \"dump\": null, \"kernel\": {\"type\": \"ScaleKernel\", \"base_kernel\": {\"type\": \"RBFKernel\", \"ard\": false, \"lengthscale_prior\": null}, \"outputscale_prior\": null}, \"scaler\": \"NORMALIZE\"}, {\"type\": \"SingleTaskGPSurrogate\", \"input_features\": {\"type\": \"Inputs\", \"features\": [{\"type\": \"ContinuousInput\", \"key\": \"x_0\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_1\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_2\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_3\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_4\", \"unit\": null, \"bounds\": [0.0, 1.0]}, {\"type\": \"ContinuousInput\", \"key\": \"x_5\", \"unit\": null, \"bounds\": [0.0, 1.0]}]}, \"output_features\": {\"type\": \"Outputs\", \"features\": [{\"type\": \"ContinuousOutput\", \"key\": \"f_1\", \"objective\": {\"type\": \"MinimizeObjective\", \"w\": 1.0, \"lower_bound\": 0, \"upper_bound\": 1}, \"unit\": null}]}, \"input_preprocessing_specs\": {}, \"dump\": null, \"kernel\": {\"type\": \"ScaleKernel\", \"base_kernel\": {\"type\": \"MaternKernel\", \"ard\": true, \"nu\": 2.5, \"lengthscale_prior\": {\"type\": \"GammaPrior\", \"concentration\": 3.0, \"rate\": 6.0}}, \"outputscale_prior\": {\"type\": \"GammaPrior\", \"concentration\": 2.0, \"rate\": 0.15}}, \"scaler\": \"NORMALIZE\"}]}, \"ref_point\": null, \"alpha\": 0.0}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup the data model\n",
    "strategy_data = QnehviStrategyDataModel(\n",
    "    domain=benchmark.domain,\n",
    "    surrogate_specs=BotorchSurrogates(\n",
    "        surrogates=[\n",
    "            SingleTaskGPSurrogate(\n",
    "                input_features=benchmark.domain.input_features,\n",
    "                output_features=Outputs(features=[benchmark.domain.outputs[0]]),\n",
    "                kernel=ScaleKernel(base_kernel=RBFKernel(ard=False))\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# we generate the json spec\n",
    "jspec = strategy_data.json()\n",
    "\n",
    "jspec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Candidate(inputValues={'x_0': InputValue(value=1.0), 'x_1': InputValue(value=0.0), 'x_2': InputValue(value=1.0), 'x_3': InputValue(value=0.208562612543878), 'x_4': InputValue(value=0.0), 'x_5': InputValue(value=0.2329520868935282)}, outputValues={'f_0': OutputValue(predictedValue=-0.1475980614994069, standardDeviation=0.24772132745479597, objective=0.1475980614994069), 'f_1': OutputValue(predictedValue=1.1182802266356866, standardDeviation=0.3141427969914292, objective=-1.1182802266356866)})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load it\n",
    "strategy_data = parse_obj_as(AnyStrategy, json.loads(jspec))\n",
    "\n",
    "# map it\n",
    "strategy = stategies.map(strategy_data)\n",
    "\n",
    "# tell it the pending candidates if available\n",
    "if pending_candidates is not None:\n",
    "    strategy.add_candidates(pending_candidates)\n",
    "\n",
    "# tell it\n",
    "strategy.tell(experiments=experiments)\n",
    "\n",
    "# ask it\n",
    "df_candidates = strategy.ask(candidate_count=1)\n",
    "\n",
    "# transform to spec\n",
    "candidates = strategy.to_candidates(df_candidates)\n",
    "\n",
    "candidates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fill the model info section accordingly, the following snippet has to be executed for every surrogate, incldung saving the actual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMethod(BaseModel):\n",
    "    type: str\n",
    "\n",
    "class CrossValidation(TestMethod):\n",
    "    type: Literal[\"CrossValidation\"] = \"CrossValidation\"\n",
    "    foldCount: int\n",
    "\n",
    "\n",
    "for i in range(len(strategy_data.surrogate_specs.surrogates)):\n",
    "    surrogate_data = strategy_data.surrogate_specs.surrogates[i]\n",
    "    surrogate = strategy.surrogate_specs.surrogates[i]\n",
    "    # get the spec\n",
    "    jsurrogate_spec = surrogate_data.json()\n",
    "    # get the dump\n",
    "    dump = surrogate.dumps()\n",
    "    # do the cross validation, only if we have a trainable model under the hood\n",
    "    if isinstance(surrogate,TrainableSurrogate):\n",
    "        cv_train, cv_test, _ = surrogate.cross_validate(strategy.experiments, folds=5)\n",
    "        # transform the bofire objects to the backend objects\n",
    "        testMethod = CrossValidation(foldCount=5)\n",
    "        cvResultsTrain = CvResults2CrossValidationValues(cv_train)\n",
    "        cvResultsTest = CvResults2CrossValidationValues(cv_test)\n",
    "        metricsTrain = cv_train.get_metrics(combine_folds=False).describe().loc[\"mean\"].to_dict()\n",
    "        metricsTest = cv_test.get_metrics(combine_folds=True).describe().loc[\"mean\"].to_dict()\n",
    "        # save to backend\n",
    "        # - jsurrogate_spec\n",
    "        # - dump\n",
    "        # - testMethod\n",
    "        # - cvResultsTrain\n",
    "        # - cvResultsTest\n",
    "        # - metricsTrain\n",
    "        # - metricsTest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bofire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
