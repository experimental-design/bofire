{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "papermill": {
     "duration": 0.00373,
     "end_time": "2024-10-10T20:33:46.707729",
     "exception": false,
     "start_time": "2024-10-10T20:33:46.703999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Random Forest in BoFire\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "papermill": {
     "duration": 26.862628,
     "end_time": "2024-10-10T20:34:13.573982",
     "exception": false,
     "start_time": "2024-10-10T20:33:46.711354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bofire.strategies.api as strategies\n",
    "import bofire.surrogates.api as surrogates\n",
    "from bofire.benchmarks.multi import DTLZ2\n",
    "from bofire.data_models.domain.api import Outputs\n",
    "from bofire.data_models.strategies.api import QnehviStrategy\n",
    "from bofire.data_models.surrogates.api import BotorchSurrogates, RandomForestSurrogate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "papermill": {
     "duration": 0.000881,
     "end_time": "2024-10-10T20:34:13.576230",
     "exception": false,
     "start_time": "2024-10-10T20:34:13.575349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup a RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "papermill": {
     "duration": 0.249081,
     "end_time": "2024-10-10T20:34:13.826056",
     "exception": true,
     "start_time": "2024-10-10T20:34:13.576975",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "benchmark = DTLZ2(dim=6)\n",
    "\n",
    "experiments = benchmark.f(benchmark.domain.inputs.sample(20), return_complete=True)\n",
    "\n",
    "# you can use the hyperparams from sklearn\n",
    "rf_data_model = RandomForestSurrogate(\n",
    "    inputs=benchmark.domain.inputs,\n",
    "    outputs=Outputs(features=[benchmark.domain.outputs[0]]),\n",
    "    n_estimators=100,\n",
    ")\n",
    "\n",
    "rf = surrogates.map(rf_data_model)\n",
    "\n",
    "cv_train, cv_test, _ = rf.cross_validate(experiments)\n",
    "\n",
    "cv_test.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Setup an optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "benchmark = DTLZ2(dim=6)\n",
    "\n",
    "data_model = QnehviStrategy(\n",
    "    domain=benchmark.domain,\n",
    "    ref_point={\"f_0\": 1.1, \"f_1\": 1.1},\n",
    "    surrogate_specs=BotorchSurrogates(\n",
    "        surrogates=[\n",
    "            RandomForestSurrogate(\n",
    "                inputs=benchmark.domain.inputs,\n",
    "                outputs=Outputs(features=[benchmark.domain.outputs[0]]),\n",
    "            ),\n",
    "            RandomForestSurrogate(\n",
    "                inputs=benchmark.domain.inputs,\n",
    "                outputs=Outputs(features=[benchmark.domain.outputs[1]]),\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "\n",
    "recommender = strategies.map(data_model=data_model)\n",
    "\n",
    "experiments = benchmark.f(benchmark.domain.inputs.sample(10), return_complete=True)\n",
    "recommender.tell(experiments=experiments)\n",
    "\n",
    "\n",
    "# currently not supported\n",
    "# for i in range(10):\n",
    "#     samples = benchmark.domain.inputs.sample(512, method=SamplingMethodEnum.SOBOL)\n",
    "#     candidates = recommender.ask(1, candidate_pool=samples)\n",
    "#     candidates = candidates.reset_index(drop=True)\n",
    "#     new_experiments = benchmark.f(candidates[benchmark.domain.inputs.get_keys().copy()], return_complete=True)\n",
    "#     recommender.tell(experiments=new_experiments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28.794119,
   "end_time": "2024-10-10T20:34:14.649993",
   "environment_variables": {},
   "exception": true,
   "parameters": {},
   "start_time": "2024-10-10T20:33:45.855874",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
