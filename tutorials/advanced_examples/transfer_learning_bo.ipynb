{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "papermill": {
     "duration": 2.980124,
     "end_time": "2024-10-10T20:34:18.797038",
     "exception": false,
     "start_time": "2024-10-10T20:34:15.816914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import bofire.strategies.api as strategies\n",
    "import bofire.surrogates.api as surrogates\n",
    "from bofire.benchmarks.api import Ackley, Branin\n",
    "from bofire.data_models.acquisition_functions.api import qLogEI\n",
    "from bofire.data_models.domain.api import Domain, Inputs, Outputs\n",
    "from bofire.data_models.features.api import ContinuousInput, ContinuousOutput, TaskInput\n",
    "from bofire.data_models.objectives.api import MaximizeObjective\n",
    "from bofire.data_models.strategies.api import SoboStrategy\n",
    "from bofire.data_models.surrogates.api import (\n",
    "    BotorchSurrogates,\n",
    "    MultiTaskGPSurrogate,\n",
    "    SingleTaskGPSurrogate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "papermill": {
     "duration": 0.262804,
     "end_time": "2024-10-10T20:34:19.062415",
     "exception": false,
     "start_time": "2024-10-10T20:34:18.799611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "papermill": {
     "duration": 0.002045,
     "end_time": "2024-10-10T20:34:19.066803",
     "exception": false,
     "start_time": "2024-10-10T20:34:19.064758",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this notebook we show how to use BoFire for the purposes of transfer learning Bayesian optimization. In particular, we assume we have a task $f_2$ with data that is relevant to the optimization of our current task $f_1$. The procedure is simple, we fit a MultiTask GP to both data-sets, however only carry out the BO on $f_1$, i.e., we optimize the acquisition functions on on the task $f_1$.\n",
    "\n",
    "We build a small data-set using the target task:\n",
    "\n",
    "$$ f_1(x) = \\sin(2 \\pi x) $$\n",
    "\n",
    "And we will have data the second related task:\n",
    "\n",
    "$$ f_2 = 0.9 \\sin(2 \\pi x) + 0.2 \\cos(3 \\pi x) - 0.2 $$\n",
    "\n",
    "We begin by defining the functions, generating some data, and plotting it. We generate 15 data-points for Task 2 and just 4 data-points for Task 1, all the data-points in Task 1 will be in a restricted area of the space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "papermill": {
     "duration": 0.663407,
     "end_time": "2024-10-10T20:34:19.732148",
     "exception": false,
     "start_time": "2024-10-10T20:34:19.068741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def task_1_f(x):\n",
    "    return np.sin(x * 2 * np.pi)\n",
    "\n",
    "\n",
    "def task_2_f(x):\n",
    "    return 0.9 * np.sin(x * 2 * np.pi) - 0.2 + 0.2 * np.cos(x * 3 * np.pi)\n",
    "\n",
    "\n",
    "x = np.linspace(0, 1, 101)\n",
    "\n",
    "# generate lots of low fidelity data and a few high fidelity data\n",
    "\n",
    "task_1_x = np.linspace(0.6, 1, 4)\n",
    "task_1_y = task_1_f(task_1_x)\n",
    "\n",
    "task_2_x = np.linspace(0, 1, 15)\n",
    "task_2_y = task_2_f(task_2_x)\n",
    "\n",
    "# set the data in the pandas format\n",
    "experiments = pd.DataFrame(\n",
    "    {\n",
    "        \"x\": np.concatenate([task_1_x, task_2_x]),\n",
    "        \"y\": np.concatenate([task_1_y, task_2_y]),\n",
    "        \"task\": [\"task_1\"] * len(task_1_x) + [\"task_2\"] * len(task_2_x),\n",
    "    },\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.scatter(task_1_x, task_1_y, label=\"Task 1 data\", color=\"red\")\n",
    "plt.scatter(task_2_x, task_2_y, label=\"Task 2 data\", color=\"blue\")\n",
    "\n",
    "plt.plot(x, task_1_f(x), label=\"Task 1\", color=\"red\")\n",
    "plt.plot(x, task_2_f(x), label=\"Task 2\", color=\"blue\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "papermill": {
     "duration": 0.002194,
     "end_time": "2024-10-10T20:34:19.736993",
     "exception": false,
     "start_time": "2024-10-10T20:34:19.734799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "papermill": {
     "duration": 0.002196,
     "end_time": "2024-10-10T20:34:19.741349",
     "exception": false,
     "start_time": "2024-10-10T20:34:19.739153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "At first we will show to do inference with the model and see make predictions using multiple data-sets.\n",
    "\n",
    "We first set-up the model according to BoFire's API, by defining the set of input and output features and the corresponding bounds, and create a surrogate data model:\n",
    "\n",
    "- To define the task we choose the `TaskInput` feature, everything else follows standard BoFire procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "papermill": {
     "duration": 0.006739,
     "end_time": "2024-10-10T20:34:19.750236",
     "exception": false,
     "start_time": "2024-10-10T20:34:19.743497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set-up the task model with allowed variable as [\"True\"] for the target task and [\"False\"] for the other task\n",
    "task_input = TaskInput(key=\"task\", categories=[\"task_1\", \"task_2\"])\n",
    "# define the input features\n",
    "input_features = [ContinuousInput(key=\"x\", bounds=(0, 1)), task_input]\n",
    "\n",
    "objective = MaximizeObjective(w=1)\n",
    "output_features = [ContinuousOutput(key=\"y\", objective=objective)]\n",
    "\n",
    "inputs = Inputs(features=input_features)\n",
    "outputs = Outputs(features=output_features)\n",
    "\n",
    "surrogate_data = MultiTaskGPSurrogate(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "papermill": {
     "duration": 0.002114,
     "end_time": "2024-10-10T20:34:19.754890",
     "exception": false,
     "start_time": "2024-10-10T20:34:19.752776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We map from the surrogate data into the surrogate model and fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "papermill": {
     "duration": 0.152004,
     "end_time": "2024-10-10T20:34:19.909174",
     "exception": true,
     "start_time": "2024-10-10T20:34:19.757170",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "surrogate = surrogates.map(surrogate_data)\n",
    "\n",
    "surrogate.fit(experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Plot to see how we are able to predict outside of the region where there is data for Task 1, since we can use the data from Task 2 and the learnt correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predict the high fidelity data\n",
    "x_predict = np.linspace(0, 1, 101)\n",
    "y_predict = surrogate.predict(\n",
    "    pd.DataFrame({\"x\": x_predict, \"task\": [\"task_1\"] * len(x_predict)}),\n",
    ")\n",
    "\n",
    "# plot data and predictions\n",
    "plt.plot(x_predict, y_predict[\"y_pred\"], label=\"Predictions\", color=\"green\")\n",
    "plt.fill_between(\n",
    "    x_predict,\n",
    "    y_predict[\"y_pred\"] - 2 * y_predict[\"y_sd\"],\n",
    "    y_predict[\"y_pred\"] + 2 * y_predict[\"y_sd\"],\n",
    "    color=\"green\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# plot the high fidelity function\n",
    "plt.plot(x, task_1_f(x), label=\"Task 1\", color=\"red\")\n",
    "\n",
    "# plot the data too\n",
    "plt.scatter(\n",
    "    experiments[experiments[\"task\"] == \"task_1\"][\"x\"],\n",
    "    experiments[experiments[\"task\"] == \"task_1\"][\"y\"],\n",
    "    label=\"Task 1 data\",\n",
    "    color=\"red\",\n",
    ")\n",
    "plt.scatter(\n",
    "    experiments[experiments[\"task\"] == \"task_2\"][\"x\"],\n",
    "    experiments[experiments[\"task\"] == \"task_2\"][\"y\"],\n",
    "    label=\"Task 2 data\",\n",
    "    color=\"blue\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Transfer Learning Bayesian Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Let us now integrate this into BoFire's `SOBO` strategy. This can be done by following the standard BoFire syntax with a small modification.\n",
    "\n",
    "- For `TaskInput` we must set the variable `allowed` as a list, with each element in the list corresponding to one of the `categories` such that all auxiliary tasks have `False` and target task has `True`. For example, we have `categories = [\"task_1, task_2\"]` and the goal of our optimization is to optimize `task_1` therefore we set `allowed = [True, False]`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_features = [\n",
    "    ContinuousInput(key=\"x\", bounds=(0, 1)),\n",
    "    TaskInput(key=\"task\", categories=[\"task_1\", \"task_2\"], allowed=[True, False]),\n",
    "]\n",
    "\n",
    "objective = MaximizeObjective(w=1)\n",
    "output_features = [ContinuousOutput(key=\"y\", objective=objective)]\n",
    "\n",
    "inputs = Inputs(features=input_features)\n",
    "outputs = Outputs(features=output_features)\n",
    "\n",
    "surrogate_data = MultiTaskGPSurrogate(inputs=inputs, outputs=outputs)\n",
    "surrogate_specs = BotorchSurrogates(surrogates=[surrogate_data])\n",
    "\n",
    "# define the acquisition function\n",
    "acquisition = qLogEI()\n",
    "\n",
    "sobo_strategy_data_model = SoboStrategy(\n",
    "    domain=Domain(\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "    ),\n",
    "    acquisition_function=acquisition,\n",
    "    surrogate_specs=surrogate_specs,\n",
    ")\n",
    "\n",
    "sobo_strategy = strategies.map(sobo_strategy_data_model)\n",
    "\n",
    "sobo_strategy.tell(experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We can now generate experimental candidates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "candidates = sobo_strategy.ask(3)\n",
    "\n",
    "candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "If we instead wanted to optimize `task_2` instead of `task_1`, we simply change `allowed = [False, True]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_features = [\n",
    "    ContinuousInput(key=\"x\", bounds=(0, 1)),\n",
    "    TaskInput(key=\"task\", categories=[\"task_1\", \"task_2\"], allowed=[False, True]),\n",
    "]\n",
    "\n",
    "objective = MaximizeObjective(w=1)\n",
    "output_features = [ContinuousOutput(key=\"y\", objective=objective)]\n",
    "\n",
    "inputs = Inputs(features=input_features)\n",
    "outputs = Outputs(features=output_features)\n",
    "\n",
    "surrogate_data = MultiTaskGPSurrogate(inputs=inputs, outputs=outputs)\n",
    "surrogate_specs = BotorchSurrogates(surrogates=[surrogate_data])\n",
    "\n",
    "# define the acquisition function\n",
    "acquisition = qLogEI()\n",
    "\n",
    "sobo_strategy_data_model = SoboStrategy(\n",
    "    domain=Domain(\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "    ),\n",
    "    acquisition_function=acquisition,\n",
    "    surrogate_specs=surrogate_specs,\n",
    ")\n",
    "\n",
    "sobo_strategy = strategies.map(sobo_strategy_data_model)\n",
    "\n",
    "sobo_strategy.tell(experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We  now obtain candidates for `task_2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "candidate = sobo_strategy.ask(1)\n",
    "\n",
    "candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Let us now run a Bayesian optimization loop on the Branin benchmark to show the usefulness of transfer learning Bayesian optimization in a practical setting. We create a small data-set composed of the Branin benchmark itself, and a large one composed of the Branin function with a small amount of bias added by summing the Branin and Ackley functions.\n",
    "\n",
    "We begin by defining a function that creates random initial data-sets, and create as many data-sets as the number of runs we want to average over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "benchmark = Branin()\n",
    "bias = Ackley()\n",
    "\n",
    "\n",
    "def create_data_set():\n",
    "    # choose the initial data-sets\n",
    "    low_fidelity_x = benchmark.domain.inputs.sample(25)\n",
    "    high_fidelity_x = benchmark.domain.inputs.sample(4)\n",
    "\n",
    "    # create the observations\n",
    "    high_fidelity_data = benchmark.f(high_fidelity_x, return_complete=True)\n",
    "    low_fidelity_bias = bias.f(low_fidelity_x, return_complete=True)\n",
    "\n",
    "    low_fidelity_data = benchmark.f(low_fidelity_x, return_complete=True)\n",
    "    low_fidelity_data[\"y\"] = low_fidelity_data[\"y\"] + 0.15 * low_fidelity_bias[\"y\"]\n",
    "\n",
    "    # create a joint data-set, with the task variable\n",
    "    high_fidelity_data[\"task\"] = \"task_1\"\n",
    "    low_fidelity_data[\"task\"] = \"task_2\"\n",
    "\n",
    "    experiments_joint = pd.concat([low_fidelity_data, high_fidelity_data])\n",
    "\n",
    "    return high_fidelity_data, experiments_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "single_task_all_regrets = []\n",
    "\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")\n",
    "if SMOKE_TEST:\n",
    "    num_runs = 5\n",
    "    num_iters = 2\n",
    "    verbose = False\n",
    "else:\n",
    "    num_runs = 10\n",
    "    num_iters = 10\n",
    "    verbose = True\n",
    "\n",
    "# create the initial data-sets for each run\n",
    "\n",
    "high_fidelity_datasets = []\n",
    "experiments_joint_datasets = []\n",
    "\n",
    "for _ in range(num_runs):\n",
    "    high_fidelity_data, experiments_joint = create_data_set()\n",
    "    high_fidelity_datasets.append(high_fidelity_data)\n",
    "    experiments_joint_datasets.append(experiments_joint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Let us now run a Bayesian optimization loop only using the high-fidelity data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for run in range(num_runs):\n",
    "    high_fidelity_data = high_fidelity_datasets[run]\n",
    "\n",
    "    inputs = benchmark.domain.inputs\n",
    "    outputs = benchmark.domain.outputs\n",
    "\n",
    "    surrogate_data = SingleTaskGPSurrogate(inputs=inputs, outputs=outputs)\n",
    "    surrogate_specs = BotorchSurrogates(surrogates=[surrogate_data])\n",
    "\n",
    "    acquisition = qLogEI()\n",
    "\n",
    "    sobo_strategy_data_model = SoboStrategy(\n",
    "        domain=Domain(\n",
    "            inputs=inputs,\n",
    "            outputs=outputs,\n",
    "        ),\n",
    "        acquisition_function=acquisition,\n",
    "        surrogate_specs=surrogate_specs,\n",
    "    )\n",
    "\n",
    "    sobo_strategy = strategies.map(sobo_strategy_data_model)\n",
    "\n",
    "    dataset = high_fidelity_data.drop(columns=[\"task\"])\n",
    "\n",
    "    sobo_strategy.tell(dataset)\n",
    "\n",
    "    regrets_single_task = []\n",
    "\n",
    "    init_regret = (\n",
    "        sobo_strategy.experiments[\"y\"][sobo_strategy.experiments[\"y\"].argmin()]\n",
    "        - benchmark.get_optima()[\"y\"][0].item()\n",
    "    )\n",
    "    regrets_single_task.append(init_regret)\n",
    "\n",
    "    pbar = tqdm(range(num_iters), desc=\"Optimizing\")\n",
    "    for _iter in pbar:\n",
    "        candidate = sobo_strategy.ask(1)\n",
    "        y = benchmark.f(candidate, return_complete=True)\n",
    "        sobo_strategy.tell(y)\n",
    "\n",
    "        regret = (\n",
    "            sobo_strategy.experiments[\"y\"][sobo_strategy.experiments[\"y\"].argmin()]\n",
    "            - benchmark.get_optima()[\"y\"][0].item()\n",
    "        )\n",
    "        regrets_single_task.append(regret)\n",
    "\n",
    "        pbar.set_postfix({\"Regret\": f\"{regret:.4f}\"})\n",
    "\n",
    "    single_task_all_regrets.append(regrets_single_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We now repeat the experiment but using transfer learning BO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "multitask_all_regrets = []\n",
    "\n",
    "for run in range(num_runs):\n",
    "    experiments_joint = experiments_joint_datasets[run]\n",
    "\n",
    "    input_features = benchmark.domain.inputs.features + [\n",
    "        TaskInput(key=\"task\", categories=[\"task_1\", \"task_2\"], allowed=[True, False]),\n",
    "    ]\n",
    "    inputs = Inputs(features=input_features)\n",
    "    outputs = benchmark.domain.outputs\n",
    "\n",
    "    surrogate_data = MultiTaskGPSurrogate(inputs=inputs, outputs=outputs)\n",
    "    surrogate_specs = BotorchSurrogates(surrogates=[surrogate_data])\n",
    "\n",
    "    acquisition = qLogEI()\n",
    "\n",
    "    sobo_strategy_data_model = SoboStrategy(\n",
    "        domain=Domain(\n",
    "            inputs=inputs,\n",
    "            outputs=outputs,\n",
    "        ),\n",
    "        acquisition_function=acquisition,\n",
    "        surrogate_specs=surrogate_specs,\n",
    "    )\n",
    "\n",
    "    sobo_strategy = strategies.map(sobo_strategy_data_model)\n",
    "\n",
    "    dataset = experiments_joint.copy()\n",
    "\n",
    "    sobo_strategy.tell(dataset)\n",
    "\n",
    "    regrets_transfer_learning = []\n",
    "\n",
    "    # obtain experiments at the highest fidelity\n",
    "    experiments = sobo_strategy.experiments[\n",
    "        sobo_strategy.experiments[\"task\"] == \"task_1\"\n",
    "    ][\"y\"]\n",
    "    init_regret = (\n",
    "        experiments[experiments.argmin()] - benchmark.get_optima()[\"y\"][0].item()\n",
    "    )\n",
    "    regrets_transfer_learning.append(init_regret)\n",
    "\n",
    "    pbar = tqdm(range(num_iters), desc=\"Optimizing\")\n",
    "    for _iter in pbar:\n",
    "        candidate = sobo_strategy.ask(1)\n",
    "        candidate = candidate.drop(columns=[\"task\"])\n",
    "        y = benchmark.f(candidate, return_complete=True)\n",
    "        y[\"task\"] = \"task_1\"\n",
    "        sobo_strategy.tell(y)\n",
    "\n",
    "        experiments = sobo_strategy.experiments[\n",
    "            sobo_strategy.experiments[\"task\"] == \"task_1\"\n",
    "        ][\"y\"].reset_index(drop=True)\n",
    "        regret = (\n",
    "            experiments[experiments.argmin()] - benchmark.get_optima()[\"y\"][0].item()\n",
    "        )\n",
    "        regrets_transfer_learning.append(regret)\n",
    "\n",
    "        pbar.set_postfix({\"Regret\": f\"{regret:.4f}\"})\n",
    "\n",
    "    multitask_all_regrets.append(regrets_transfer_learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We now plot the quantiles and median simple regret against iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the results\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "regrets_single_task_median = np.median(np.array(single_task_all_regrets), axis=0)\n",
    "regrets_transfer_learning_median = np.median(np.array(multitask_all_regrets), axis=0)\n",
    "\n",
    "# get the 25 and 75 percentiles\n",
    "regrets_single_task_upper_quantile = np.quantile(\n",
    "    np.array(single_task_all_regrets),\n",
    "    0.75,\n",
    "    axis=0,\n",
    ")\n",
    "regrets_single_task_lower_quantile = np.quantile(\n",
    "    np.array(single_task_all_regrets),\n",
    "    0.25,\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "regrets_transfer_learning_upper_quantile = np.quantile(\n",
    "    np.array(multitask_all_regrets),\n",
    "    0.75,\n",
    "    axis=0,\n",
    ")\n",
    "regrets_transfer_learning_lower_quantile = np.quantile(\n",
    "    np.array(multitask_all_regrets),\n",
    "    0.25,\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "plt.plot(regrets_single_task_median, label=\"Single task\", color=\"red\")\n",
    "plt.plot(regrets_transfer_learning_median, label=\"Transfer learning\", color=\"blue\")\n",
    "\n",
    "plt.fill_between(\n",
    "    np.arange(num_iters + 1),\n",
    "    regrets_single_task_upper_quantile,\n",
    "    regrets_single_task_lower_quantile,\n",
    "    color=\"red\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.fill_between(\n",
    "    np.arange(num_iters + 1),\n",
    "    regrets_transfer_learning_upper_quantile,\n",
    "    regrets_transfer_learning_lower_quantile,\n",
    "    color=\"blue\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Regret\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We can see that using transfer learning leads to significant improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.535794,
   "end_time": "2024-10-10T20:34:20.632563",
   "environment_variables": {},
   "exception": true,
   "parameters": {},
   "start_time": "2024-10-10T20:34:15.096769",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
